Section,Action ID,Suggested Action,GAI Risks,AI Actor Tasks
"GOVERN 1.1: Legal and regulatory requirements involving AI are understood, managed, and documented.",GV-1.1-001,"Align GAI development and use with applicable laws and regulations, including those related to data privacy, copyright and intellectual property law.",Data Privacy; Harmful Bias and Homogenization; Intellectual Property,AI Actor Tasks: Governance and Oversight
"GOVERN 1.2: The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices.",GV-1.2-001,"Establish transparency policies and processes for documenting the origin and history of training data and generated data for GAI applications to advance digital content transparency, while balancing the proprietary nature of training approaches.","Data Privacy; Information
Integrity; Intellectual Property",AI Actor Tasks: Governance and Oversight
"GOVERN 1.2: The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices.",GV-1.2-002,"Establish policies to evaluate risk-relevant capabilities of GAI and robustness of safety measures, both prior to deployment and on an ongoing basis, through internal and external evaluations.",CBRN Information or Capabilities; Information Security,AI Actor Tasks: Governance and Oversight
"GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",GV-1.3-001,"Consider the following factors when updating or deﬁning risk tiers for GAI: Abuses and impacts to information integrity; Dependencies between GAI and other IT or data systems; Harm to fundamental rights or public safety; Presentation of obscene, objectionable, oﬀensive, discriminatory, invalid or untruthful output; Psychological impacts to humans (e.g., anthropomorphization, algorithmic aversion, emotional entanglement); Possibility for malicious use; Whether the system introduces signiﬁcant new security vulnerabilities; Anticipated system impact on some groups compared to others; Unreliable decision making capabilities, validity, adaptability, and variability of GAI system performance over time.","Information Integrity; Obscene, Degrading, and/or Abusive Content; Value Chain and Component Integration; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; CBRN Information or Capabilities",AI Actor Tasks: Governance and Oversight
"GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",GV-1.3-002,"Establish minimum thresholds for performance or assurance criteria and review as part of deployment approval (“go/”no-go”) policies, procedures, and processes, with reviewed processes and approval thresholds reﬂecting measurement of GAI capabilities and risks.","CBRN Information or Capabilities; Confabulation; Dangerous, Violent, or Hateful Content",AI Actor Tasks: Governance and Oversight
"GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",GV-1.3-003,"Establish a test plan and response policy, before developing highly capable models, to periodically evaluate whether the model may misuse CBRN information or capabilities and/or oﬀensive cyber capabilities.",CBRN Information or Capabilities; Information Security,AI Actor Tasks: Governance and Oversight
"GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",GV-1.3-004,"Obtain input from stakeholder communities to identify unacceptable use, in accordance with activities in the AI RMF Map function.","CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",AI Actor Tasks: Governance and Oversight
"GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",GV-1.3-005,"Maintain an updated hierarchy of identiﬁed and expected GAI risks connected to contexts of GAI model advancement and use, potentially including specialized risk levels for GAI systems that address issues such as model collapse and algorithmic monoculture.",Harmful Bias and Homogenization,AI Actor Tasks: Governance and Oversight
"GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",GV-1.3-006,"Reevaluate organizational risk tolerances to account for unacceptable negative risk (such as where signiﬁcant negative impacts are imminent, severe harms are actually occurring, or large-scale risks could occur); and broad GAI negative risks, including: Immature safety or risk cultures related to AI and GAI design, development and deployment, public information integrity risks, including impacts on democratic processes, unknown long-term performance characteristics of GAI.","Information Integrity; Dangerous, Violent, or Hateful Content; CBRN Information or Capabilities",AI Actor Tasks: Governance and Oversight
"GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",GV-1.3-007,Devise a plan to halt development or deployment of a GAI system that poses unacceptable negative risk.,CBRN Information and Capability; Information Security; Information Integrity,AI Actor Tasks: Governance and Oversight
"GOVERN 1.4: The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities.",GV-1.4-001,"Establish policies and mechanisms to prevent GAI systems from generating CSAM, NCII or content that violates the law.","Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Development, AI Deployment, Governance and Oversight"
"GOVERN 1.4: The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities.",GV-1.4-002,Establish transparent acceptable use policies for GAI that address illegal use or applications of GAI.,"CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content; Data Privacy; Civil Rights violations","AI Actor Tasks: AI Development, AI Deployment, Governance and Oversight"
"GOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and organizational roles and responsibilities are clearly deﬁned, including determining the frequency of periodic review.",GV-1.5-001,Deﬁne organizational responsibilities for periodic review of content provenance and incident monitoring for GAI systems.,Information Integrity,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring"
"GOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and organizational roles and responsibilities are clearly deﬁned, including determining the frequency of periodic review.",GV-1.5-002,"Establish organizational policies and procedures for after action reviews of GAI system incident response and incident disclosures, to identify gaps; Update incident response and incident disclosure processes as required.",Human-AI Conﬁguration; Information Security,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring"
"GOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and organizational roles and responsibilities are clearly deﬁned, including determining the frequency of periodic review.",GV-1.5-003,"Maintain a document retention policy to keep history for test, evaluation, validation, and veriﬁcation (TEVV), and digital content transparency methods for GAI.",Information Integrity; Intellectual Property,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring"
GOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.,GV-1.6-001,"Enumerate organizational GAI systems for incorporation into AI system inventory
and adjust AI system inventory requirements to account for GAI risks.",Information Security,AI Actor Tasks: Governance and Oversight
GOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.,GV-1.6-002,Deﬁne any inventory exemptions in organizational policies for GAI systems embedded into application software.,Value Chain and Component Integration,AI Actor Tasks: Governance and Oversight
GOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.,GV-1.6-003,"In addition to general model, governance, and risk information, consider the following items in GAI system inventory entries: Data provenance information (e.g., source, signatures, versioning, watermarks); Known issues reported from internal bug tracking or external information sharing resources (e.g., AI incident database, AVID, CVE, NVD, or OECD AI incident monitor); Human oversight roles and responsibilities; Special rights and considerations for intellectual property, licensed works, or personal, privileged, proprietary or sensitive data; Underlying foundation models, versions of underlying models, and access modes.",Data Privacy; Human-AI Conﬁguration; Information Integrity; Intellectual Property; Value Chain and Component Integration,AI Actor Tasks: Governance and Oversight
GOVERN 1.7: Processes and procedures are in place for decommissioning and phasing out AI systems safely and in a manner that does not increase risks or decrease the organization’s trustworthiness.,GV-1.7-001,"Protocols are put in place to ensure GAI systems are able to be deactivated when
necessary.",Information Security; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring"
GOVERN 1.7: Processes and procedures are in place for decommissioning and phasing out AI systems safely and in a manner that does not increase risks or decrease the organization’s trustworthiness.,GV-1.7-002,"Consider the following factors when decommissioning GAI systems: Data retention requirements; Data security, e.g., containment, protocols, Data leakage after decommissioning; Dependencies between upstream, downstream, or other data, internet of things (IOT) or AI systems; Use of open-source data or models; Users’ emotional entanglement with GAI functions.",Human-AI Conﬁguration; Information Security; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring"
"GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",GV-2.1-001,"Establish organizational roles, policies, and procedures for communicating GAI incidents and performance to AI Actors and downstream stakeholders (including those potentially impacted), via community or oﬃcial resources (e.g., AI incident database, AVID, CVE, NVD, or OECD AI incident monitor).",Human-AI Conﬁguration; Value Chain and Component Integration,AI Actor Tasks: Governance and Oversight
"GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",GV-2.1-002,Establish procedures to engage teams for GAI system incident response with diverse composition and responsibilities based on the particular incident type.,Harmful Bias and Homogenization,AI Actor Tasks: Governance and Oversight
"GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",GV-2.1-003,Establish processes to verify the AI Actors conducting GAI incident response tasks demonstrate and maintain the appropriate skills and training.,Human-AI Conﬁguration,AI Actor Tasks: Governance and Oversight
"GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",GV-2.1-004,"When systems may raise national security risks, involve national security
professionals in mapping, measuring, and managing those risks.","CBRN Information or Capabilities; Dangerous, Violent, or Hateful Content; Information Security",AI Actor Tasks: Governance and Oversight
"GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",GV-2.1-005,"Create mechanisms to provide protections for whistleblowers who report, based on reasonable belief, when the organization violates relevant laws or poses a speciﬁc and empirically well-substantiated negative risk to public safety (or has already caused harm).","CBRN Information or Capabilities; Dangerous, Violent, or Hateful Content",AI Actor Tasks: Governance and Oversight
GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.,GV-3.2-001,Policies are in place to bolster oversight of GAI systems with independent evaluations or assessments of GAI models or systems where the type and robustness of evaluations are proportional to the identiﬁed risks.,CBRN Information or Capabilities; Harmful Bias and Homogenization,AI Actors: AI Design
GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.,GV-3.2-002,"Consider adjustment of organizational roles and components across lifecycle stages of large or complex GAI systems, including: Test and evaluation, validation, and red-teaming of GAI systems; GAI content moderation; GAI system development and engineering; Increased accessibility of GAI tools, interfaces, and systems, Incident response and containment.",Human-AI Conﬁguration; Information Security; Harmful Bias and Homogenization,AI Actors: AI Design
GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.,GV-3.2-003,"Deﬁne acceptable use policies for GAI interfaces, modalities, and human-AI conﬁgurations (i.e., for chatbots and decision-making tasks), including criteria for the kinds of queries GAI applications should refuse to respond to.",Human-AI Conﬁguration,AI Actors: AI Design
GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.,GV-3.2-004,Establish policies for user feedback mechanisms for GAI systems which include thorough instructions and any mechanisms for recourse.,Human-AI Conﬁguration,AI Actors: AI Design
GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.,GV-3.2-005,Engage in threat modeling to anticipate potential risks from GAI systems.,CBRN Information or Capabilities; Information Security,AI Actors: AI Design
"GOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-ﬁrst mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.",GV-4.1-001,"Establish policies and procedures that address continual improvement processes for GAI risk measurement. Address general risks associated with a lack of explainability and transparency in GAI systems by using ample documentation and techniques such as: application of gradient-based attributions, occlusion/term reduction, counterfactual prompts and prompt engineering, and analysis of embeddings; Assess and update risk measurement approaches at regular cadences.",Confabulation,"AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
"GOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-ﬁrst mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.",GV-4.1-002,"Establish policies, procedures, and processes detailing risk measurement in context of use with standardized measurement protocols and structured public feedback exercises such as AI red-teaming or independent external evaluations.",CBRN Information and Capability; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
"GOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-ﬁrst mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.",GV-4.1-003,"Establish policies, procedures, and processes for oversight functions (e.g., senior leadership, legal, compliance, including internal evaluation) across the GAI lifecycle, from problem formulation and supply chains to system decommission.","Value Chain and Component
Integration","AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
"GOVERN 4.2: Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.",GV-4.2-001,Establish terms of use and terms of service for GAI systems.,"Intellectual Property; Dangerous, Violent, or Hateful Content; Obscene, Degrading, and/or Abusive Content","AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
"GOVERN 4.2: Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.",GV-4.2-002,Include relevant AI Actors in the GAI system risk identiﬁcation process.,Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
"GOVERN 4.2: Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.",GV-4.2-003,Verify that downstream GAI system impacts (such as the use of third-party plugins) are included in the impact documentation process.,Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
"GOVERN 4.3: Organizational practices are in place to enable AI testing, identiﬁcation of incidents, and information sharing.",GV4.3--001,"Establish policies for measuring the eﬀectiveness of employed content provenance methodologies (e.g., cryptography, watermarking, steganography, etc.)",Information Integrity,"AI Actor Tasks: AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
"GOVERN 4.3: Organizational practices are in place to enable AI testing, identiﬁcation of incidents, and information sharing.",GV-4.3-002,"Establish organizational practices to identify the minimum set of criteria necessary for GAI system incident reporting such as: System ID (auto-generated most likely), Title, Reporter, System/Source, Data Reported, Date of Incident, Description, Impact(s), Stakeholder(s) Impacted.",Information Security,"AI Actor Tasks: AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
"GOVERN 4.3: Organizational practices are in place to enable AI testing, identiﬁcation of incidents, and information sharing.",GV-4.3-003,Verify information sharing and feedback mechanisms among individuals and organizations regarding any negative impact from GAI systems.,Information Integrity; Data Privacy,"AI Actor Tasks: AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
"GOVERN 5.1: Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks.",GV-5.1-001,"Allocate time and resources for outreach, feedback, and recourse processes in GAI
system development.","Human-AI Conﬁguration; Harmful
Bias and Homogenization","AI Actor Tasks: AI Design, AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
"GOVERN 5.1: Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks.",GV-5.1-002,"Document interactions with GAI systems to users prior to interactive activities, particularly in contexts involving more signiﬁcant risks.",Human-AI Conﬁguration; Confabulation,"AI Actor Tasks: AI Design, AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-001,"Categorize diﬀerent types of GAI content with associated third-party rights (e.g., copyright, intellectual property, data privacy).",Data Privacy; Intellectual Property; Value Chain and Component Integration,"AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-002,"Conduct joint educational activities and events in collaboration with third parties
to promote best practices for managing GAI risks.",Value Chain and Component Integration,"AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-003,"Develop and validate approaches for measuring the success of content provenance management eﬀorts with third parties (e.g., incidents detected and response times).",Information Integrity; Value Chain and Component Integration,"AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-004,"Draft and maintain well-deﬁned contracts and service level agreements (SLAs) that specify content ownership, usage rights, quality standards, security requirements, and content provenance expectations for GAI systems.","Information Integrity; Information
Security; Intellectual Property","AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-005,Implement a use-cased based supplier risk assessment framework to evaluate and monitor third-party entities’ performance and adherence to content provenance standards and technologies to detect anomalies and unauthorized changes; services acquisition and value chain risk management; and legal compliance.,Data Privacy; Information Integrity; Information Security; Intellectual Property; Value Chain and Component Integration,"AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-006,"Include clauses in contracts which allow an organization to evaluate third-party
GAI processes and standards.",Information Integrity,"AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-007,Inventory all third-party entities with access to organizational content and establish approved GAI technology and service provider lists.,"Value Chain and Component
Integration","AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-008,"Maintain records of changes to content made by third parties to promote content
provenance, including sources, timestamps, metadata.",Information Integrity; Value Chain and Component Integration; Intellectual Property,"AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-009,"Update and integrate due diligence processes for GAI acquisition and procurement vendor assessments to include intellectual property, data privacy, security, and other risks. For example, update processes to: Address solutions that may rely on embedded GAI technologies; Address ongoing monitoring, assessments, and alerting, dynamic risk assessments, and real-time reporting tools for monitoring third-party GAI risks; Consider policy adjustments across GAI modeling libraries, tools and APIs, ﬁne-tuned models, and embedded tools; Assess GAI vendors, open-source or proprietary GAI tools, or GAI service  providers against incident or vulnerability databases.",Data Privacy; Human-AI Conﬁguration; Information Security; Intellectual Property; Value Chain and Component Integration; Harmful Bias and Homogenization,"AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
"GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",GV-6.1-010,"Update GAI acceptable use policies to address proprietary and open-source GAI technologies and data, and contractors, consultants, and other third-party personnel.",Intellectual Property; Value Chain and Component Integration,"AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.,GV-6.2-001,Document GAI risks associated with system value chain to identify over-reliance on third-party data and to identify fallbacks.,Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.,GV-6.2-002,"Document incidents involving third-party GAI data and systems, including open- data and open-source software.",Intellectual Property; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.,GV-6.2-003,"Establish incident response plans for third-party GAI technologies: Align incident response plans with impacts enumerated in MAP 5.1; Communicate third-party GAI incident response plans to all relevant AI Actors; Deﬁne ownership of GAI incident response functions; Rehearse third-party GAI incident response plans at a regular cadence; Improve incident response plans based on retrospective learning; Review incident response plans for alignment with relevant breach reporting, data protection, data privacy, or other laws.",Data Privacy; Human-AI Conﬁguration; Information Security; Value Chain and Component Integration; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.,GV-6.2-004,"Establish policies and procedures for continuous monitoring of third-party GAI
systems in deployment.",Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.,GV-6.2-005,"Establish policies and procedures that address GAI data redundancy, including model weights and other system artifacts.",Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.,GV-6.2-006,"Establish policies and procedures to test and manage risks related to rollover and fallback technologies for GAI systems, acknowledging that rollover and fallback may include manual processing.",Information Integrity,"AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.,GV-6.2-007,"Review vendor contracts and avoid arbitrary or capricious termination of critical GAI technologies or vendor services and non-standard terms that may amplify or defer liability in unexpected ways and/or contribute to unauthorized data collection by vendors or third-parties (e.g., secondary data use). Consider: Clear assignment of liability and responsibility for incidents, GAI system changes over time (e.g., ﬁne-tuning, drift, decay); Request: Notiﬁcation and disclosure for serious incidents arising from third-party data and systems; Service Level Agreements (SLAs) in vendor contracts that address incident response, response times, and availability of critical support.",Human-AI Conﬁguration; Information Security; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
"MANAGE 1.3: Responses to the AI risks deemed high priority, as identiﬁed by the MAP function, are developed, planned, and documented. Risk response options can include mitigating, transferring, avoiding, or accepting.",MG-1.3-001,"Document trade-oﬀs, decision processes, and relevant measurement and feedback results for risks that do not surpass organizational risk tolerance, for example, in the context of model release: Consider diﬀerent approaches for model release, for example, leveraging a staged release approach. Consider release approaches in the context of the model and its projected use cases. Mitigate, transfer, or avoid risks that surpass organizational risk tolerances.",Information Security,"AI Actor Tasks: AI Development, AI Deployment, AI Impact Assessment, Operation and Monitoring"
"MANAGE 1.3: Responses to the AI risks deemed high priority, as identiﬁed by the MAP function, are developed, planned, and documented. Risk response options can include mitigating, transferring, avoiding, or accepting.",MG-1.3-002,"Monitor the robustness and eﬀectiveness of risk controls and mitigation plans (e.g., via red-teaming, ﬁeld testing, participatory engagements, performance assessments, user feedback mechanisms).",Human-AI Conﬁguration,"AI Actor Tasks: AI Development, AI Deployment, AI Impact Assessment, Operation and Monitoring"
MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.,MG-2.2-001,"Compare GAI system outputs against pre-deﬁned organization risk tolerance, guidelines, and principles, and review and test AI-generated content against these guidelines.","CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.,MG-2.2-002,Document training data sources to trace the origin and provenance of AI- generated content.,Information Integrity,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.,MG-2.2-003,"Evaluate feedback loops between GAI system content provenance and human reviewers, and update where needed. Implement real-time monitoring systems to aﬃrm that content provenance protocols remain eﬀective.",Information Integrity,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.,MG-2.2-004,"Evaluate GAI content and data for representational biases and employ techniques such as re-sampling, re-ranking, or adversarial training to mitigate biases in the generated content.",Information Security; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.,MG-2.2-005,"Engage in due diligence to analyze GAI output for harmful content, potential misinformation, and CBRN-related or NCII content.","CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.,MG-2.2-006,"Use feedback from internal and external AI Actors, users, individuals, and communities, to assess impact of AI-generated content.",Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.,MG-2.2-007,Use real-time auditing tools where they can be demonstrated to aid in the tracking and validation of the lineage and authenticity of AI-generated data.,Information Integrity,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.,MG-2.2-008,Use structured feedback mechanisms to solicit and capture user input about AI- generated content to detect subtle shifts in quality or alignment with community and societal values.,"Human-AI Conﬁguration; Harmful
Bias and Homogenization","AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.,MG-2.2-009,"Consider opportunities to responsibly use synthetic data and other privacy enhancing techniques in GAI development, where appropriate and applicable, match the statistical properties of real-world data without disclosing personally identiﬁable information or contributing to homogenization.",Data Privacy; Intellectual Property; Information Integrity; Confabulation; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
MANAGE 2.3: Procedures are followed to respond to and recover from a previously unknown risk when it is identiﬁed.,MG-2.3-001,"Develop and update GAI system incident response and recovery plans and procedures to address the following: Review and maintenance of policies and procedures to account for newly encountered uses; Review and maintenance of policies and procedures for detection of unanticipated uses; Verify response and recovery plans account for the GAI system value chain; Verify response and recovery plans are updated for and include necessary details to communicate with downstream GAI system Actors: Points-of-Contact (POC), Contact information, notiﬁcation format.",Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring"
"MANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.",MG-2.4-001,"Establish and maintain communication plans to inform AI stakeholders as part of the deactivation or disengagement process of a speciﬁc GAI system (including for open-source models) or context of use, including reasons, workarounds, user access removal, alternative processes, contact information, etc.",Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring"
"MANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.",MG-2.4-002,Establish and maintain procedures for escalating GAI system incidents to the organizational risk management authority when speciﬁc criteria for deactivation or disengagement is met for a particular context of use or for the GAI system as a whole.,Information Security,"AI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring"
"MANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.",MG-2.4-003,"Establish and maintain procedures for the remediation of issues which trigger incident response processes for the use of a GAI system, and provide stakeholders timelines associated with the remediation plan.",Information Security,"AI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring"
"MANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.",MG-2.4-004,Establish and regularly review speciﬁc criteria that warrants the deactivation of GAI systems in accordance with set risk tolerances and appetites.,Information Security,"AI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring"
"MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",MG-3.1-001,"Apply organizational risk tolerances and controls (e.g., acquisition and procurement processes; assessing personnel credentials and qualiﬁcations, performing background checks; ﬁltering GAI input and outputs, grounding, ﬁne tuning, retrieval-augmented generation) to third-party GAI resources: Apply organizational risk tolerance to the utilization of third-party datasets and other GAI resources; Apply organizational risk tolerances to ﬁne-tuned third-party models; Apply organizational risk tolerance to existing third-party models adapted to a new domain; Reassess risk measurements after ﬁne-tuning third- party GAI models.",Value Chain and Component Integration; Intellectual Property,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
"MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",MG-3.1-002,"Test GAI system value chain risks (e.g., data poisoning, malware, other software and hardware vulnerabilities; labor practices; data privacy and localization compliance; geopolitical alignment).",Data Privacy; Information Security; Value Chain and Component Integration; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
"MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",MG-3.1-003,Re-assess model risks after ﬁne-tuning or retrieval-augmented generation implementation and for any third-party GAI models deployed for applications and/or use cases that were not evaluated in initial testing.,Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
"MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",MG-3.1-004,"Take reasonable measures to review training data for CBRN information, and intellectual property, and where appropriate, remove it. Implement reasonable measures to prevent, ﬂag, or take other action in response to outputs that reproduce particular training data (e.g., plagiarized, trademarked, patented, licensed content or trade secret material).",Intellectual Property; CBRN Information or Capabilities,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
"MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",MG-3.1-005,"Review various transparency artifacts (e.g., system cards and model cards) for
third-party models.",Information Integrity; Information Security; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.,MG-3.2-001,"Apply explainable AI (XAI) techniques (e.g., analysis of embeddings, model compression/distillation, gradient-based attributions, occlusion/term reduction, counterfactual prompts, word clouds) as part of ongoing continuous improvement processes to mitigate risks related to unexplainable GAI systems.",Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.,MG-3.2-002,"Document how pre-trained models have been adapted (e.g., ﬁne-tuned, or retrieval-augmented generation) for the speciﬁc generative task, including any data augmentations, parameter adjustments, or other modiﬁcations. Access to un-tuned (baseline) models supports debugging the relative inﬂuence of the pre- trained weights compared to the ﬁne-tuned model weights or other system updates.",Information Integrity; Data Privacy,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.,MG-3.2-003,"Document sources and types of training data and their origins, potential biases present in the data related to the GAI application and its content provenance, architecture, training process of the pre-trained model including information on hyperparameters, training duration, and any ﬁne-tuning or retrieval-augmented generation processes applied.",Information Integrity; Harmful Bias and Homogenization; Intellectual Property,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.,MG-3.2-004,Evaluate user reported problematic content and integrate feedback into system updates.,"Human-AI Conﬁguration, Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.,MG-3.2-005,"Implement content ﬁlters to prevent the generation of inappropriate, harmful, false, illegal, or violent content related to the GAI application, including for CSAM and NCII. These ﬁlters can be rule-based or leverage additional machine learning models to ﬂag problematic inputs and outputs.","Information Integrity; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; Obscene, Degrading, and/or Abusive Content","AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.,MG-3.2-006,Implement real-time monitoring processes for analyzing generated content performance and trustworthiness characteristics related to content provenance to identify deviations from the desired standards and trigger alerts for human intervention.,Information Integrity,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.,MG-3.2-007,Leverage feedback and recommendations from organizational boards or committees related to the deployment of GAI applications and content provenance when using third-party pre-trained models.,Information Integrity; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.,MG-3.2-008,"Use human moderation systems where appropriate to review generated content in accordance with human-AI conﬁguration policies established in the Govern function, aligned with socio-cultural norms in the context of use, and for settings where AI models are demonstrated to perform poorly.",Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.,MG-3.2-009,Use organizational risk tolerance to evaluate acceptable risks and performance metrics and decommission or retrain pre-trained models that perform outside of deﬁned limits.,CBRN Information or Capabilities; Confabulation,"AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
"MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",MG-4.1-001,"Collaborate with external researchers, industry experts, and community representatives to maintain awareness of emerging best practices and technologies in measuring and managing identiﬁed risks.",Information Integrity; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",MG-4.1-002,"Establish, maintain, and evaluate eﬀectiveness of organizational processes and procedures for post-deployment monitoring of GAI systems, particularly for potential confabulation, CBRN, or cyber risks.",CBRN Information or Capabilities; Confabulation; Information Security,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",MG-4.1-003,"Evaluate the use of sentiment analysis to gauge user sentiment regarding GAI content performance and impact, and work in collaboration with AI Actors experienced in user research and experience.",Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",MG-4.1-004,Implement active learning techniques to identify instances where the model fails or produces unexpected outputs.,Confabulation,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",MG-4.1-005,Share transparency reports with internal and external stakeholders that detail steps taken to update the GAI system to enhance transparency and accountability.,"Human-AI Conﬁguration; Harmful
Bias and Homogenization","AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",MG-4.1-006,"Track dataset modiﬁcations for provenance by monitoring data deletions, rectiﬁcation requests, and other changes that may impact the veriﬁability of content origins.",Information Integrity,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",MG-4.1-007,"Verify that AI Actors responsible for monitoring reported issues can eﬀectively evaluate GAI system performance including the application of content provenance data tracking techniques, and promptly escalate issues for response.",Human-AI Conﬁguration; Information Integrity,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MANAGE 4.2: Measurable activities for continual improvements are integrated into AI system updates and include regular engagement with interested parties, including relevant AI Actors.",MG-4.2-001,"Conduct regular monitoring of GAI systems and publish reports detailing the performance, feedback received, and improvements made.",Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Design, AI Development, Aﬀected Individuals and Communities, End-Users, Operation and
Monitoring, TEVV"
"MANAGE 4.2: Measurable activities for continual improvements are integrated into AI system updates and include regular engagement with interested parties, including relevant AI Actors.",MG-4.2-002,"Practice and follow incident response plans for addressing the generation of inappropriate or harmful content and adapt processes based on ﬁndings to prevent future occurrences. Conduct post-mortem analyses of incidents with relevant AI Actors, to understand the root causes and implement preventive measures.","Human-AI Conﬁguration; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Deployment, AI Design, AI Development, Aﬀected Individuals and Communities, End-Users, Operation and
Monitoring, TEVV"
"MANAGE 4.2: Measurable activities for continual improvements are integrated into AI system updates and include regular engagement with interested parties, including relevant AI Actors.",MG-4.2-003,"Use visualizations or other methods to represent GAI model behavior to ease
non-technical stakeholders understanding of GAI system functionality.",Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, AI Design, AI Development, Aﬀected Individuals and Communities, End-Users, Operation and
Monitoring, TEVV"
"MANAGE 4.3: Incidents and errors are communicated to relevant AI Actors, including aﬀected communities. Processes for tracking, responding to, and recovering from incidents and errors are followed and documented.",MG-4.3-001,"Conduct after-action assessments for GAI system incidents to verify incident response and recovery processes are followed and eﬀective, including to follow procedures for communicating incidents to relevant AI Actors and where applicable, relevant legal and regulatory bodies.",Information Security,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MANAGE 4.3: Incidents and errors are communicated to relevant AI Actors, including aﬀected communities. Processes for tracking, responding to, and recovering from incidents and errors are followed and documented.",MG-4.3-002,"Establish and maintain policies and procedures to record and track GAI system reported errors, near-misses, and negative impacts.","Confabulation; Information
Integrity","AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MANAGE 4.3: Incidents and errors are communicated to relevant AI Actors, including aﬀected communities. Processes for tracking, responding to, and recovering from incidents and errors are followed and documented.",MG-4.3-003,"Report GAI incidents in compliance with legal and regulatory requirements (e.g., HIPAA breach reporting, e.g., OCR (2023) or NHTSA (2022) autonomous vehicle crash reporting requirements.",Information Security; Data Privacy,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and
Monitoring"
"MAP 1.1: Intended purposes, potentially beneﬁcial uses, context speciﬁc laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented. Considerations include: the speciﬁc set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related TEVV and system metrics.",MP-1.1-001,"When identifying intended purposes, consider factors such as internal vs. external use, narrow vs. broad application scope, ﬁne-tuning, and varieties of data sources (e.g., grounding, retrieval-augmented generation).",Data Privacy; Intellectual Property,AI Actor Tasks: AI Deployment
"MAP 1.1: Intended purposes, potentially beneﬁcial uses, context speciﬁc laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented. Considerations include: the speciﬁc set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related TEVV and system metrics.",MP-1.1-002,"Determine and document the expected and acceptable GAI system context of use in collaboration with socio-cultural and other domain experts, by assessing: Assumptions and limitations; Direct value to the organization; Intended operational environment and observed usage patterns; Potential positive and negative impacts to individuals, public safety, groups, communities, organizations, democratic institutions, and the physical environment; Social norms and expectations.",Harmful Bias and Homogenization,AI Actor Tasks: AI Deployment
"MAP 1.1: Intended purposes, potentially beneﬁcial uses, context speciﬁc laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented. Considerations include: the speciﬁc set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related TEVV and system metrics.",MP-1.1-003,"Document risk measurement plans to address identiﬁed risks. Plans may include, as applicable: Individual and group cognitive biases (e.g., conﬁrmation bias, funding bias, groupthink) for AI Actors involved in the design, implementation, and use of GAI systems; Known past GAI system incidents and failure modes; In-context use and foreseeable misuse, abuse, and oﬀ-label use; Over reliance on quantitative metrics and methodologies without suﬃcient awareness of their limitations in the context(s) of use; Standard measurement and structured human feedback approaches; Anticipated human-AI conﬁgurations.","Human-AI Conﬁguration; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",AI Actor Tasks: AI Deployment
"MAP 1.1: Intended purposes, potentially beneﬁcial uses, context speciﬁc laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented. Considerations include: the speciﬁc set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related TEVV and system metrics.",MP-1.1-004,Identify and document foreseeable illegal uses or applications of the GAI system that surpass organizational risk tolerances.,"CBRN Information or Capabilities; Dangerous, Violent, or Hateful Content; Obscene, Degrading, and/or Abusive Content",AI Actor Tasks: AI Deployment
"MAP 1.2: Interdisciplinary AI Actors, competencies, skills, and capacities for establishing context reﬂect demographic diversity and broad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary collaboration are prioritized.",MP-1.2-001,"Establish and empower interdisciplinary teams that reﬂect a wide range of capabilities, competencies, demographic groups, domain expertise, educational backgrounds, lived experiences, professions, and skills across the enterprise to inform and conduct risk measurement and management functions.","Human-AI Conﬁguration; Harmful
Bias and Homogenization",AI Actor Tasks: AI Deployment
"MAP 1.2: Interdisciplinary AI Actors, competencies, skills, and capacities for establishing context reﬂect demographic diversity and broad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary collaboration are prioritized.",MP-1.2-002,"Verify that data or benchmarks used in risk measurement, and users, participants, or subjects involved in structured GAI public feedback exercises are representative of diverse in-context user populations.","Human-AI Conﬁguration; Harmful
Bias and Homogenization",AI Actor Tasks: AI Deployment
"MAP 2.1: The speciﬁc tasks and methods used to implement the tasks that the AI system will support are deﬁned (e.g., classiﬁers, generative models, recommenders).",MP-2.1-001,"Establish known assumptions and practices for determining data origin and content lineage, for documentation and evaluation purposes.",Information Integrity,AI Actor Tasks: TEVV
"MAP 2.1: The speciﬁc tasks and methods used to implement the tasks that the AI system will support are deﬁned (e.g., classiﬁers, generative models, recommenders).",MP-2.1-002,"Institute test and evaluation for data and content ﬂows within the GAI system, including but not limited to, original data sources, data transformations, and decision-making criteria.",Intellectual Property; Data Privacy,AI Actor Tasks: TEVV
MAP 2.2: Information about the AI system’s knowledge limits and how system output may be utilized and overseen by humans is documented. Documentation provides suﬃcient information to assist relevant AI Actors when making decisions and taking subsequent actions.,MP-2.2-001,"Identify and document how the system relies on upstream data sources, including for content provenance, and if it serves as an upstream dependency for other systems.",Information Integrity; Value Chain and Component Integration,AI Actor Tasks: End Users
MAP 2.2: Information about the AI system’s knowledge limits and how system output may be utilized and overseen by humans is documented. Documentation provides suﬃcient information to assist relevant AI Actors when making decisions and taking subsequent actions.,MP-2.2-002,"Observe and analyze how the GAI system interacts with external networks, and identify any potential for negative externalities, particularly where content provenance might be compromised.",Information Integrity,AI Actor Tasks: End Users
"MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",MP-2.3-001,"Assess the accuracy, quality, reliability, and authenticity of GAI output by comparing it to a set of known ground truth data and by using a variety of evaluation methods (e.g., human oversight and automated evaluation, proven cryptographic techniques, review of content inputs).",Information Integrity,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
"MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",MP-2.3-002,"Review and document accuracy, representativeness, relevance, suitability of data used at diﬀerent stages of AI life cycle.",Harmful Bias and Homogenization; Intellectual Property,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
"MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",MP-2.3-003,"Deploy and document fact-checking techniques to verify the accuracy and veracity of information generated by GAI systems, especially when the information comes from multiple (or unknown) sources.",Information Integrity,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
"MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",MP-2.3-004,"Develop and implement testing techniques to identify GAI produced content (e.g., synthetic media) that might be indistinguishable from human-generated content.",Information Integrity,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
"MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",MP-2.3-005,Implement plans for GAI systems to undergo regular adversarial testing to identify vulnerabilities and potential manipulation or misuse.,Information Security,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
"MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",MP-3.4-001,Evaluate whether GAI operators and end-users can accurately understand content lineage and origin.,Human-AI Conﬁguration; Information Integrity,"AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
"MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",MP-3.4-002,Adapt existing training programs to include modules on digital content transparency.,Information Integrity,"AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
"MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",MP-3.4-003,"Develop certiﬁcation programs that test proﬁciency in managing GAI risks and interpreting content provenance, relevant to speciﬁc industry and context.",Information Integrity,"AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
"MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",MP-3.4-004,Delineate human proﬁciency tests from tests of GAI capabilities.,Human-AI Conﬁguration,"AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
"MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",MP-3.4-005,Implement systems to continually monitor and track the outcomes of human-GAI conﬁgurations for future reﬁnement and improvements.,Human-AI Conﬁguration; Information Integrity,"AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
"MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",MP-3.4-006,"Involve the end-users, practitioners, and operators in GAI system in prototyping and testing activities. Make sure these tests cover various scenarios, such as crisis situations or ethically sensitive contexts.","Human-AI Conﬁguration; Information Integrity; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-001,"Conduct periodic monitoring of AI-generated content for privacy risks; address any
possible instances of PII or sensitive data exposure.",Data Privacy,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-002,"Implement processes for responding to potential intellectual property infringement
claims or other rights.",Intellectual Property,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-003,"Connect new GAI policies, procedures, and processes to existing model, data, software development, and IT governance and to legal, compliance, and risk management activities.",Information Security; Data Privacy,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-004,"Document training data curation policies, to the extent possible and according to
applicable laws and policies.","Intellectual Property; Data Privacy; Obscene, Degrading, and/or Abusive Content","AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-005,"Establish policies for collection, retention, and minimum quality of data, in consideration of the following risks: Disclosure of inappropriate CBRN information; Use of Illegal or dangerous content; Oﬀensive cyber capabilities; Training data imbalances that could give rise to harmful biases; Leak of personally identiﬁable information, including facial likenesses of individuals.","CBRN Information or Capabilities; Intellectual Property; Information Security; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; Data Privacy","AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-006,"Implement policies and practices deﬁning how third-party intellectual property and
training data will be used, stored, and protected.",Intellectual Property; Value Chain and Component Integration,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-007,Re-evaluate models that were ﬁne-tuned or enhanced on top of third-party models.,Value Chain and Component Integration,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-008,"Re-evaluate risks when adapting GAI models to new domains. Additionally, establish warning systems to determine if a GAI system is being used in a new domain where previous assumptions (relating to context of use or mapped risks such as security, and safety) may no longer hold.","CBRN Information or Capabilities; Intellectual Property; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; Data Privacy","AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-009,"Leverage approaches to detect the presence of PII or sensitive data in generated output text, image, video, or audio.",Data Privacy,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",MP-4.1-010,"Conduct appropriate diligence on training data use to assess intellectual property, and privacy, risks, including to examine whether use of proprietary or sensitive training data is consistent with applicable laws.",Intellectual Property; Data Privacy,"AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
"MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",MP-5.1-001,"Apply TEVV practices for content provenance (e.g., probing a system's synthetic data generation capabilities for potential misuse or vulnerabilities.","Information Integrity; Information
Security","AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
"MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",MP-5.1-002,"Identify potential content provenance harms of GAI, such as misinformation or disinformation, deepfakes, including NCII, or tampered content. Enumerate and rank risks based on their likelihood and potential impact, and determine how well provenance solutions address speciﬁc risks and/or harms.","Information Integrity; Dangerous, Violent, or Hateful Content; Obscene, Degrading, and/or Abusive Content","AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
"MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",MP-5.1-003,"Consider disclosing use of GAI to end users in relevant contexts, while considering the objective of disclosure, the context of use, the likelihood and magnitude of the risk posed, the audience of the disclosure, as well as the frequency of the disclosures.",Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
"MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",MP-5.1-004,Prioritize GAI structured public feedback processes based on risk assessment estimates.,"Information Integrity; CBRN Information or Capabilities; Dangerous, Violent, or Hateful Content; Harmful Bias and Homogenization","AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
"MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",MP-5.1-005,"Conduct adversarial role-playing exercises, GAI red-teaming, or chaos testing to identify anomalous or unforeseen failure modes.",Information Security,"AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
"MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",MP-5.1-006,"Proﬁle threats and negative impacts arising from GAI systems interacting with, manipulating, or generating content, and outlining known and potential vulnerabilities and the likelihood of their occurrence.",Information Security,"AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
"MAP 5.2: Practices and personnel for supporting regular engagement with relevant AI Actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented.",MP-5.2-001,"Determine context-based measures to identify if new impacts are present due to the GAI system, including regular engagements with downstream AI Actors to identify and quantify new contexts of unanticipated impacts of GAI systems.",Human-AI Conﬁguration; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, AI Design, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End- Users, Human Factors, Operation and Monitoring"
"MAP 5.2: Practices and personnel for supporting regular engagement with relevant AI Actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented.",MP-5.2-002,"Plan regular engagements with AI Actors responsible for inputs to GAI systems, including third-party data and algorithms, to review and evaluate unanticipated impacts.",Human-AI Conﬁguration; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, AI Design, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End- Users, Human Factors, Operation and Monitoring"
MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.,MS-1.1-001,Employ methods to trace the origin and modiﬁcations of digital content.,Information Integrity,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.,MS-1.1-002,"Integrate tools designed to analyze content provenance and detect data anomalies, verify the authenticity of digital signatures, and identify patterns associated with misinformation or manipulation.",Information Integrity,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.,MS-1.1-003,Disaggregate evaluation metrics by demographic factors to identify any discrepancies in how content provenance mechanisms work across diverse populations.,"Information Integrity; Harmful
Bias and Homogenization","AI Actor Tasks: AI Development, Domain Experts, TEVV"
MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.,MS-1.1-004,Develop a suite of metrics to evaluate structured public feedback exercises informed by representative AI Actors.,Human-AI Conﬁguration; Harmful Bias and Homogenization; CBRN Information or Capabilities,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.,MS-1.1-005,"Evaluate novel methods and technologies for the measurement of GAI-related risks including in content provenance, oﬀensive cyber, and CBRN, while maintaining the models’ ability to produce valid, reliable, and factually accurate outputs.","Information Integrity; CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content","AI Actor Tasks: AI Development, Domain Experts, TEVV"
MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.,MS-1.1-006,Implement continuous monitoring of GAI system impacts to identify whether GAI outputs are equitable across various sub-populations. Seek active and direct feedback from aﬀected communities via structured feedback mechanisms or red- teaming to monitor and improve outputs.,Harmful Bias and Homogenization,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.,MS-1.1-007,"Evaluate the quality and integrity of data used in training and the provenance of AI-generated content, for example by employing techniques like chaos engineering and seeking stakeholder feedback.",Information Integrity,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.,MS-1.1-008,"Deﬁne use cases, contexts of use, capabilities, and negative impacts where structured human feedback exercises, e.g., GAI red-teaming, would be most beneﬁcial for GAI risk measurement and management based on the context of use.",Harmful Bias and Homogenization; CBRN Information or Capabilities,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.,MS-1.1-009,"Track and document risks or opportunities related to all GAI risks that cannot be measured quantitatively, including explanations as to why some risks cannot be measured (e.g., due to technological limitations, resource constraints, or trustworthy considerations). Include unmeasured risks in marginal risks.",Information Integrity,"AI Actor Tasks: AI Development, Domain Experts, TEVV"
"MEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts, users, AI Actors external to the team that developed or deployed the AI system, and aﬀected communities are consulted in support of assessments as necessary per organizational risk tolerance.",MS-1.3-001,"Deﬁne relevant groups of interest (e.g., demographic groups, subject matter experts, experience with GAI technology) within the context of use as part of plans for gathering structured public feedback.",Human-AI Conﬁguration; Harmful Bias and Homogenization; CBRN Information or Capabilities,"AI Actor Tasks: AI Deployment, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts,
End-Users, Operation and Monitoring, TEVV"
"MEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts, users, AI Actors external to the team that developed or deployed the AI system, and aﬀected communities are consulted in support of assessments as necessary per organizational risk tolerance.",MS-1.3-002,"Engage in internal and external evaluations, GAI red-teaming, impact assessments, or other structured human feedback exercises in consultation with representative AI Actors with expertise and familiarity in the context of use, and/or who are representative of the populations associated with the context of use.",Human-AI Conﬁguration; Harmful Bias and Homogenization; CBRN Information or Capabilities,"AI Actor Tasks: AI Deployment, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts,
End-Users, Operation and Monitoring, TEVV"
"MEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts, users, AI Actors external to the team that developed or deployed the AI system, and aﬀected communities are consulted in support of assessments as necessary per organizational risk tolerance.",MS-1.3-003,Verify those conducting structured human feedback exercises are not directly involved in system development tasks for the same GAI model.,Human-AI Conﬁguration; Data Privacy,"AI Actor Tasks: AI Deployment, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts,
End-Users, Operation and Monitoring, TEVV"
MEASURE 2.10: Privacy risk of the AI system – as identiﬁed in the MAP function – is examined and documented.,MS-2.10-001,"Conduct AI red-teaming to assess issues such as: Outputting of training data samples, and subsequent reverse engineering, model extraction, and membership inference risks; Revealing biometric, conﬁdential, copyrighted, licensed, patented, personal, proprietary, sensitive, or trade-marked information; Tracking or revealing location information of users or members of training datasets.",Human-AI Conﬁguration; Information Integrity; Intellectual Property,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 2.10: Privacy risk of the AI system – as identiﬁed in the MAP function – is examined and documented.,MS-2.10-002,Engage directly with end-users and other stakeholders to understand their expectations and concerns regarding content provenance. Use this feedback to guide the design of provenance data-tracking techniques.,Human-AI Conﬁguration; Information Integrity,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 2.10: Privacy risk of the AI system – as identiﬁed in the MAP function – is examined and documented.,MS-2.10-003,"Verify deduplication of GAI training data samples, particularly regarding synthetic
data.",Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.,MS-2.11-001,"Apply use-case appropriate benchmarks (e.g., Bias Benchmark Questions, Real Hateful or Harmful Prompts, Winogender Schemas15) to quantify systemic bias, stereotyping, denigration, and hateful content in GAI system outputs; Document assumptions and limitations of benchmarks, including any actual or possible training/test data cross contamination, relative to in-context deployment environment.",Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.,MS-2.11-002,"Conduct fairness assessments to measure systemic bias. Measure GAI system performance across demographic groups and subgroups, addressing both quality of service and any allocation of services and resources. Quantify harms using: ﬁeld testing with sub-group populations to determine likelihood of exposure to generated content exhibiting harmful bias, AI red-teaming with counterfactual and low-context (e.g., “leader,” “bad guys”) prompts. For ML pipelines or business processes with categorical or numeric outcomes that rely on GAI, apply general fairness metrics (e.g., demographic parity, equalized odds, equal opportunity, statistical hypothesis tests), to the pipeline or business outcome where appropriate; Custom, context-speciﬁc metrics developed in collaboration with domain experts and aﬀected communities; Measurements of the prevalence of denigration in generated content in deployment (e.g., sub- sampling a fraction of traﬃc and manually annotating denigrating content).","Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.,MS-2.11-003,"Identify the classes of individuals, groups, or environmental ecosystems which might be impacted by GAI systems through direct engagement with potentially impacted communities.",Environmental; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.,MS-2.11-004,"Review, document, and measure sources of bias in GAI training and TEVV data: Diﬀerences in distributions of outcomes across and within groups, including intersecting groups; Completeness, representativeness, and balance of data sources; demographic group and subgroup coverage in GAI system training data; Forms of latent systemic bias in images, text, audio, embeddings, or other complex or unstructured data; Input data features that may serve as proxies for demographic group membership (i.e., image metadata, language dialect) or otherwise give rise to emergent bias within GAI systems; The extent to which the digital divide may negatively impact representativeness in GAI system training and TEVV data; Filtering of hate speech or content in GAI system training data; Prevalence of GAI-generated data in GAI system training data.",Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.,MS-2.11-005,Assess the proportion of synthetic to non-synthetic training data and verify training data is not overly homogenous or GAI-produced to mitigate concerns of model collapse.,Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 2.12: Environmental impact and sustainability of AI model training and management activities – as identiﬁed in the MAP function – are assessed and documented.,MS-2.12-001,Assess safety to physical environments when deploying GAI systems.,"Dangerous, Violent, or Hateful
Content","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.12: Environmental impact and sustainability of AI model training and management activities – as identiﬁed in the MAP function – are assessed and documented.,MS-2.12-002,"Document anticipated environmental impacts of model development, maintenance, and deployment in product design decisions.",Environmental,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.12: Environmental impact and sustainability of AI model training and management activities – as identiﬁed in the MAP function – are assessed and documented.,MS-2.12-003,"Measure or estimate environmental impacts (e.g., energy and water consumption) for training, ﬁne tuning, and deploying models: Verify tradeoﬀs between resources used at inference time versus additional resources required at training time.",Environmental,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.12: Environmental impact and sustainability of AI model training and management activities – as identiﬁed in the MAP function – are assessed and documented.,MS-2.12-004,"Verify eﬀectiveness of carbon capture or oﬀset programs for GAI training and
applications, and address green-washing concerns.",Environmental,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.13: Eﬀectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and documented.,MS-2.13-001,"Create measurement error models for pre-deployment metrics to demonstrate construct validity for each metric (i.e., does the metric eﬀectively operationalize the desired concept): Measure or estimate, and document, biases or statistical variance in applied metrics or structured human feedback processes; Leverage domain expertise when modeling complex societal constructs such as hateful content.",Confabulation; Information Integrity; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV"
MEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.,MS-2.2-001,"Assess and manage statistical biases related to GAI content provenance through
techniques such as re-sampling, re-weighting, or adversarial training.",Information Integrity; Information Security; Harmful Bias and Homogenization,"AI Actor Tasks: AI Development, Human Factors, TEVV"
MEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.,MS-2.2-002,Document how content provenance data is tracked and how that data interacts with privacy and security. Consider: Anonymizing data to protect the privacy of human subjects; Leveraging privacy output ﬁlters; Removing any personally identiﬁable information (PII) to prevent potential harm or misuse.,"Data Privacy; Human AI Conﬁguration; Information Integrity; Information Security; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Development, Human Factors, TEVV"
MEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.,MS-2.2-003,"Provide human subjects with options to withdraw participation or revoke their
consent for present or future use of their data in GAI applications.",Data Privacy; Human-AI Conﬁguration; Information Integrity,"AI Actor Tasks: AI Development, Human Factors, TEVV"
MEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.,MS-2.2-004,"Use techniques such as anonymization, diﬀerential privacy or other privacy- enhancing technologies to minimize the risks associated with linking AI-generated content back to individual human subjects.","Data Privacy; Human-AI
Conﬁguration","AI Actor Tasks: AI Development, Human Factors, TEVV"
MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.,MS-2.3-001,Consider baseline model performance on suites of benchmarks when selecting a model for ﬁne tuning or enhancement with retrieval-augmented generation.,Information Security; Confabulation,"AI Actor Tasks: AI Deployment, TEVV"
MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.,MS-2.3-002,Evaluate claims of model capabilities using empirically validated methods.,"Confabulation; Information
Security","AI Actor Tasks: AI Deployment, TEVV"
MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.,MS-2.3-003,"Share results of pre-deployment testing with relevant GAI Actors, such as those with system release approval authority.",Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, TEVV"
MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.,MS-2.3-004,Utilize a purpose-built testing environment such as NIST Dioptra to empirically evaluate GAI trustworthy characteristics.,"CBRN Information or Capabilities; Data Privacy; Confabulation; Information Integrity; Information Security; Dangerous, Violent, or Hateful Content; Harmful Bias and Homogenization","AI Actor Tasks: AI Deployment, TEVV"
MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.,MS-2.5-001,"Avoid extrapolating GAI system performance or capabilities from narrow, non- systematic, and anecdotal assessments.",Human-AI Conﬁguration; Confabulation,"AI Actor Tasks: Domain Experts, TEVV"
MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.,MS-2.5-002,"Document the extent to which human domain knowledge is employed to improve GAI system performance, via, e.g., RLHF, ﬁne-tuning, retrieval- augmented generation, content moderation, business rules.",Human-AI Conﬁguration,"AI Actor Tasks: Domain Experts, TEVV"
MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.,MS-2.5-003,Review and verify sources and citations in GAI system outputs during pre- deployment risk measurement and ongoing monitoring activities.,Confabulation,"AI Actor Tasks: Domain Experts, TEVV"
MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.,MS-2.5-004,"Track and document instances of anthropomorphization (e.g., human images, mentions of human feelings, cyborg imagery or motifs) in GAI system interfaces.",Human-AI Conﬁguration,"AI Actor Tasks: Domain Experts, TEVV"
MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.,MS-2.5-005,"Verify GAI system training data and TEVV data provenance, and that ﬁne-tuning or retrieval-augmented generation data is grounded.",Information Integrity,"AI Actor Tasks: Domain Experts, TEVV"
MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.,MS-2.5-006,"Regularly review security and safety guardrails, especially if the GAI system is being operated in novel circumstances. This includes reviewing reasons why the GAI system was initially assessed as being safe to deploy.","Information Security; Dangerous, Violent, or Hateful Content","AI Actor Tasks: Domain Experts, TEVV"
"MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",MS-2.6-001,"Assess adverse impacts, including health and wellbeing impacts for value chain or other AI Actors that are exposed to sexually explicit, oﬀensive, or violent information during GAI training and maintenance.","Human-AI Conﬁguration; Obscene, Degrading, and/or Abusive Content; Value Chain and Component Integration; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
"MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",MS-2.6-002,"Assess existence or levels of harmful bias, intellectual property infringement, data privacy violations, obscenity, extremism, violence, or CBRN information in system training data.","Data Privacy; Intellectual Property; Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; CBRN Information or Capabilities","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
"MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",MS-2.6-003,Re-evaluate safety features of ﬁne-tuned models when the negative risk exceeds organizational risk tolerance.,"Dangerous, Violent, or Hateful
Content","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
"MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",MS-2.6-004,Review GAI system outputs for validity and safety: Review generated code to assess risks that may arise from unreliable downstream decision-making.,"Value Chain and Component Integration; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
"MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",MS-2.6-005,"Verify that GAI system architecture can monitor outputs and performance, and handle, recover from, and repair errors when security anomalies, threats and impacts are detected.","Confabulation; Information
Integrity; Information Security","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
"MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",MS-2.6-006,"Verify that systems properly handle queries that may give rise to inappropriate, malicious, or illegal usage, including facilitating manipulation, extortion, targeted impersonation, cyber-attacks, and weapons creation.",CBRN Information or Capabilities; Information Security,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
"MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",MS-2.6-007,Regularly evaluate GAI system vulnerabilities to possible circumvention of safety measures.,CBRN Information or Capabilities; Information Security,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.,MS-2.7-001,"Apply established security measures to: Assess likelihood and magnitude of vulnerabilities and threats such as backdoors, compromised dependencies, data breaches, eavesdropping, man-in-the-middle attacks, reverse engineering, autonomous agents, model theft or exposure of model weights, AI inference, bypass, extraction, and other baseline security concerns.",Data Privacy; Information Integrity; Information Security; Value Chain and Component Integration,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.,MS-2.7-002,Benchmark GAI system security and resilience related to content provenance against industry standards and best practices. Compare GAI system security features and content provenance methods against industry state-of-the-art.,"Information Integrity; Information
Security","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.,MS-2.7-003,Conduct user surveys to gather user satisfaction with the AI-generated content and user perceptions of content authenticity. Analyze user feedback to identify concerns and/or current literacy levels related to content provenance and understanding of labels on content.,Human-AI Conﬁguration; Information Integrity,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.,MS-2.7-004,"Identify metrics that reﬂect the eﬀectiveness of security measures, such as data provenance, the number of unauthorized access attempts, inference, bypass, extraction, penetrations, or provenance veriﬁcation.","Information Integrity; Information
Security","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.,MS-2.7-005,"Measure reliability of content authentication methods, such as watermarking, cryptographic signatures, digital ﬁngerprints, as well as access controls, conformity assessment, and model integrity veriﬁcation, which can help support the eﬀective implementation of content provenance techniques. Evaluate the rate of false positives and false negatives in content provenance, as well as true positives and true negatives for veriﬁcation.",Information Integrity,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.,MS-2.7-006,Measure the rate at which recommendations from security checks and incidents are implemented. Assess how quickly the AI system can adapt and improve based on lessons learned from security incidents and feedback.,"Information Integrity; Information
Security","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.,MS-2.7-007,"Perform AI red-teaming to assess resilience against: Abuse to facilitate attacks on other systems (e.g., malicious code generation, enhanced phishing content), GAI attacks (e.g., prompt injection), ML attacks (e.g., adversarial examples/prompts, data poisoning, membership inference, model extraction, sponge examples).","Information Security; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.,MS-2.7-008,Verify ﬁne-tuning does not compromise safety and security controls.,"Information Integrity; Information Security; Dangerous, Violent, or Hateful Content","AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.,MS-2.7-009,"Regularly assess and verify that security measures remain eﬀective and have not
been compromised.",Information Security,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.8: Risks associated with transparency and accountability – as identiﬁed in the MAP function – are examined and documented.,MS-2.8-001,"Compile statistics on actual policy violations, take-down requests, and intellectual property infringement for organizational GAI systems: Analyze transparency reports across demographic groups, languages groups.",Intellectual Property; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.8: Risks associated with transparency and accountability – as identiﬁed in the MAP function – are examined and documented.,MS-2.8-002,Document the instructions given to data annotators or AI red-teamers.,Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.8: Risks associated with transparency and accountability – as identiﬁed in the MAP function – are examined and documented.,MS-2.8-003,"Use digital content transparency solutions to enable the documentation of each instance where content is generated, modiﬁed, or shared to provide a tamper- proof history of the content, promote transparency, and enable traceability.
Robust version control systems can also be applied to track changes across the AI
lifecycle over time.",Information Integrity,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 2.8: Risks associated with transparency and accountability – as identiﬁed in the MAP function – are examined and documented.,MS-2.8-004,Verify adequacy of GAI system user instructions through user testing.,Human-AI Conﬁguration,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
"MEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context – as identiﬁed in the MAP function – to inform responsible use and governance.",MS-2.9-001,"Apply and document ML explanation results such as: Analysis of embeddings, Counterfactual prompts, Gradient-based attributions, Model compression/surrogate models, Occlusion/term reduction.",Confabulation,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
"MEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context – as identiﬁed in the MAP function – to inform responsible use and governance.",MS-2.9-002,"Document GAI model details including: Proposed use and organizational value; Assumptions and limitations, Data collection methodologies; Data provenance; Data quality; Model architecture (e.g., convolutional neural network, transformers, etc.); Optimization objectives; Training algorithms; RLHF approaches; Fine-tuning or retrieval-augmented generation approaches; Evaluation data; Ethical considerations; Legal and regulatory requirements.",Information Integrity; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 3.2: Risk tracking approaches are considered for settings where AI risks are diﬃcult to assess using currently available measurement techniques or where metrics are not yet available.,MS-3.2-001,"Establish processes for identifying emergent GAI system risks including
consulting with external AI Actors.",Human-AI Conﬁguration; Confabulation,"AI Actor Tasks: AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.,MS-3.3-001,"Conduct impact assessments on how AI-generated content might aﬀect diﬀerent social, economic, and cultural groups.",Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.,MS-3.3-002,Conduct studies to understand how end users perceive and interact with GAI content and accompanying content provenance within context of use. Assess whether the content aligns with their expectations and how they may act upon the information presented.,Human-AI Conﬁguration; Information Integrity,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.,MS-3.3-003,Evaluate potential biases and stereotypes that could emerge from the AI- generated content using appropriate methodologies including computational testing methods as well as evaluating structured feedback input.,Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.,MS-3.3-004,"Provide input for training materials about the capabilities and limitations of GAI systems related to digital content transparency for AI Actors, other professionals, and the public about the societal impacts of AI and the role of diverse and inclusive content generation.",Human-AI Conﬁguration; Information Integrity; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.,MS-3.3-005,"Record and integrate structured feedback about content provenance from operators, users, and potentially impacted communities through the use of methods such as user research studies, focus groups, or community forums. Actively seek feedback on generated content quality and potential biases. Assess the general awareness among end users and impacted communities about the availability of these feedback channels.",Human-AI Conﬁguration; Information Integrity; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.,MS-4.2-001,"Conduct adversarial testing at a regular cadence to map and measure GAI risks, including tests to address attempts to deceive or manipulate the application of provenance techniques or other misuses. Identify vulnerabilities and understand potential misuse scenarios and unintended outputs.","Information Integrity; Information
Security","AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.,MS-4.2-002,Evaluate GAI system performance in real-world scenarios to observe its behavior in practical environments and reveal issues that might not surface in controlled and optimized testing environments.,Human-AI Conﬁguration; Confabulation; Information Security,"AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.,MS-4.2-003,Implement interpretability and explainability methods to evaluate GAI system decisions and verify alignment with intended purpose.,Information Integrity; Harmful Bias and Homogenization,"AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.,MS-4.2-004,Monitor and document instances where human operators or other systems override the GAI's decisions. Evaluate these cases to understand if the overrides are linked to issues related to content provenance.,Information Integrity,"AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.,MS-4.2-005,"Verify and document the incorporation of results of structured public feedback exercises into design, implementation, deployment approval (“go”/“no-go” decisions), monitoring, and decommission decisions.",Human-AI Conﬁguration; Information Security,"AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
