{
  "data_source_name": "AICM",
  "data_source_version": "0.0.2",
  "data_source_origin": "Cloud Security Alliance",
  "data_source_description": "AI Control Matrix - Asset Categories",
  "data_source_url": "https://docs.google.com/spreadsheets/d/1oR570DXujS8ITvzF2PGIFy1PkGu4VqUjyPyt14mMUmg/",
  "section_title": "Asset Categories",
  "id": "CSA-AICM-AC",
  "asset_categories": [
      {
          "name": "Data",
          "display_name": "Data",
          "id": "CSA-AICM-AC-Data",
          "asset_subcategories": [
              {
                  "name": "General Purpose Data (used for training, benchmarking, testing, and validation)",
                  "id": "CSA-AICM-AC-Data-GeneralPurpose",
                  "description": "Training data: This encompasses the dataset utilized to train the model, comprising various text sources from which the model derives insights into language patterns and semantics, crucial for its understanding and proficiency. **************"
              },
              {
                  "name": "Data used for fine-tune training",
                  "id": "CSA-AICM-AC-Data-FineTune",
                  "description": "Fine-tune training data: Additional data that is employed to fine-tune the model post-initial training, facilitating adjustments to its parameters to align more closely with specific use cases or domains, thereby enhancing its adaptability and accuracy."
              },
              {
                  "name": "Data used for Retrieval-Augmented Generation (RAG)",
                  "id": "CSA-AICM-AC-Data-RAG",
                  "description": "Data for retrieval to add to prompt: Supplementary data that is retrieved to enrich the input prompts provided to the model, thereby augmenting its contextual comprehension and refining the quality of generated responses."
              },
              {
                  "name": "Data cards (that define the metadata of the data in use)",
                  "id": "CSA-AICM-AC-Data-DataCards",
                  "description": ""
              },
              {
                  "name": "Input data",
                  "id": "CSA-AICM-AC-Data-Input",
                  "description": "Model input data (prompt): The input furnished to the model to elicit responses, typically manifesting as text prompts or queries that prompt the model to generate pertinent outputs tailored to user inquiries or directives."
              },
              {
                  "name": "User session data",
                  "id": "CSA-AICM-AC-Data-UserSession",
                  "description": "User session data: Information amassed during user interactions with the model, encompassing input queries, model-generated responses, and any supplementary context provided by users, facilitating personalized and responsive interactions."
              },
              {
                  "name": "Model output data",
                  "id": "CSA-AICM-AC-Data-ModelOutput",
                  "description": "Model output data: The resultant output generated by the model in response to input prompts, encompassing text responses, predictions, or other forms of processed data, reflective of the model's comprehension and inference capabilities."
              },
              {
                  "name": "Model parameters (weights)",
                  "id": "CSA-AICM-AC-Data-ModelParameters",
                  "description": "Model parameters (weights): Internal parameters or weights acquired by the model during training, delineating its behavior and exerting a profound influence on its capacity to generate accurate and contextually relevant responses."
              },
              {
                  "name": "Model hyperparameters",
                  "id": "CSA-AICM-AC-Data-ModelHyperparameters",
                  "description": "Model hyperparameters: Configurations or settings specified during model training, including parameters such as learning rate, batch size, or architecture choices, these are pivotal in shaping the model's overall performance and behavior."
              },
              {
                  "name": "Log data from LLM systems",
                  "id": "CSA-AICM-AC-Data-LogData",
                  "description": "Log data: Recorded data encapsulating various events and interactions during the model's operation, including input prompts, model responses, performance metrics, and any encountered errors or anomalies, instrumental for monitoring and refining the model's functionality and performance."
              }
          ]
      },
      {
          "name": "LLM/GenAI Ops",
          "display_name": "LLM/GenAI Ops",
          "id": "CSA-AICM-AC-LLMGenAIOps",
          "asset_subcategories": [
              {
                  "name": "Cloud environment",
                  "id": "CSA-AICM-AC-LLMGenAIOps-CloudEnvironment",
                  "description": "1. Cloud running the Training Environment: This denotes the cloud platform or service provider entrusted with hosting and managing the computational resources, storage facilities, and ancillary infrastructure pivotal for training large language models. It serves as the breeding ground where models undergo iterative refinement and enhancement. 2. Cloud running the model Inference point: This encapsulates the cloud platform or service provider tasked with hosting and administering the computational resources, storage solutions, and associated infrastructure indispensable for deploying trained language models and facilitating inference processes. It enables the model to swiftly generate responses based on user inputs, ensuring seamless interaction and responsiveness. 3. Cloud running the AI applications: This refers to the cloud platform or service provider entrusted with hosting and overseeing the infrastructure essential for running applications or services that harness the capabilities of trained language models. It serves as the operational hub where AI-driven applications leverage the inference prowess of models to deliver value-added functionalities and services to end-users. ****************************"
              },
              {
                  "name": "Hybrid and multi-cloud infrastructure",
                  "id": "CSA-AICM-AC-LLMGenAIOps-HybridMultiCloud",
                  "description": "Hybrid and multi-cloud infrastructure: This entails an approach that amalgamates the utilization of multiple cloud platforms or service providers alongside on-premises resources to distribute the various components of the LLM-Ops Environment across diverse environments. This strategy facilitates objectives such as cost optimization, performance enhancement, regulatory compliance, or redundancy, bolstering the resilience and flexibility of the operational setup."
              },
              {
                  "name": "Security of the deployment environment",
                  "id": "CSA-AICM-AC-LLMGenAIOps-SecurityDeployment",
                  "description": "Access control (IAM, Network): This encompasses the array of mechanisms and policies implemented to govern and fortify access to the assorted components of the LLM-Ops Environment. It encompasses Identity and Access Management (IAM) protocols and network security measures, safeguarding the integrity and confidentiality of critical assets and functionalities."
              },
              {
                  "name": "Continuous monitoring",
                  "id": "CSA-AICM-AC-LLMGenAIOps-ContinuousMonitoring",
                  "description": "Continuous monitoring: This denotes the ongoing process of vigilantly scrutinizing the performance, security posture, and overall well-being of the LLM-Ops Environment. It encompasses the vigilant surveillance of training, inference, and application components, ensuring optimal functionality while promptly identifying and remedying any anomalies or issues that may arise."
              },
              {
                  "name": "Storage",
                  "id": "CSA-AICM-AC-LLMGenAIOps-Storage",
                  "description": "Cloud to host training data: This signifies the cloud platform or service provider tasked with securely housing and managing the extensive datasets requisite for training language models. It entails robust storage and data management capabilities to accommodate the voluminous and diverse datasets fundamental for nurturing and refining language models. ****************************"
              }
          ]
      },
      {
          "name": "Model",
          "display_name": "Model",
          "id": "CSA-AICM-AC-Model",
          "asset_subcategories": [
              {
                  "name": "Foundation Model",
                  "id": "CSA-AICM-AC-Model-Foundation",
                  "description": "A foundational component in the model asset repertoire, the Foundation Model serves as the bedrock upon which further advancements are built. These models are typically large, pre-trained language models that encapsulate a broad understanding of language gleaned from extensive exposure to unlabeled text data via self-supervised learning techniques. Foundation models provide a starting point for subsequent fine-tuning and specialization to cater to specific tasks or domains. For some advanced and most innovative foundation models, another term “Frontier Model” can be used to represent a brand new foundation model in AI Marketplace. Or from an AI perspective, sometimes, the term “Base Model” is used to represent foundation models in the application technology stacks."
              },
              {
                  "name": "Fine-Tuned Model",
                  "id": "CSA-AICM-AC-Model-FineTuned",
                  "description": "Derived from the Foundation Model, the Fine-Tuned Model undergoes further refinement and adaptation to cater to specific tasks or domains. Through the process of fine-tuning, parameters of the foundation model are updated utilizing supervised learning techniques and task-specific labeled data. This iterative process enables the model to enhance its performance on target tasks or domains while retaining the foundational knowledge and capabilities inherited from the Foundation Model."
              },
              {
                  "name": "Open Source vs. Closed Source Models",
                  "id": "CSA-AICM-AC-Model-OpenClosedSource",
                  "description": "This dichotomy pertains to the accessibility and licensing of a model's source code, weights, and associated artifacts. Open source models may release some or all of their training source code, model architecture, weights, and tools to the public under open source licenses, granting free usage with specific terms and conditions. However, closed source models maintain proprietary status, withholding their source code, weights, and implementation details from the public domain, often motivated by intellectual property protection or commercial interests. These model assets collectively form the backbone of model development, fostering innovation, adaptability, and accessibility within the realm of GenAI."
              },
              {
                  "name": "Domain-Specific Models",
                  "id": "CSA-AICM-AC-Model-DomainSpecific",
                  "description": "****************************"
              },
              {
                  "name": "Model cards",
                  "id": "CSA-AICM-AC-Model-ModelCards",
                  "description": "****************************"
              }
          ]
      },
      {
          "name": "Orchestrated Services",
          "display_name": "Orchestrated Services",
          "id": "CSA-AICM-AC-OrchestratedServices",
          "asset_subcategories": [
              {
                  "name": "Caching Services",
                  "id": "CSA-AICM-AC-OrchestratedServices-Caching",
                  "description": "Caching Services refer to systems or components that facilitate the caching of model predictions, inputs, or other data to enhance performance by reducing redundant computations. By storing frequently accessed data temporarily, caching services help minimize response times and alleviate computational strain on LLMs."
              },
              {
                  "name": "Security Gateways (LLM Gateways)",
                  "id": "CSA-AICM-AC-OrchestratedServices-SecurityGateways",
                  "description": "Security Gateways, also known as LLM Gateways, are specialized components that serve as intermediaries between LLMs and external systems. These gateways bolster security by implementing access control measures, input validation, and safeguards against potential threats or misuse, ensuring the integrity and confidentiality of data processed by LLMs."
              },
              {
                  "name": "Deployment Services",
                  "id": "CSA-AICM-AC-OrchestratedServices-Deployment",
                  "description": "Deployment Services streamline the deployment and scaling of LLMs across diverse environments, including cloud platforms and on-premises infrastructure. These services automate deployment processes, facilitate version management, and optimize resource allocation to ensure efficient and seamless LLM deployment across various deployment scenarios."
              },
              {
                  "name": "Monitoring Services",
                  "id": "CSA-AICM-AC-OrchestratedServices-Monitoring",
                  "description": "Monitoring Services play a pivotal role in overseeing the security, performance, health, and usage of LLMs. These services employ monitoring tools and techniques to gather real-time insights, detect anomalies, and issue alerts, which enables proactive maintenance and timely intervention to uphold the optimal operation of LLMs."
              },
              {
                  "name": "Optimization Services",
                  "id": "CSA-AICM-AC-OrchestratedServices-Optimization",
                  "description": "Optimization Services are geared towards optimizing the performance and resource utilization of LLMs. These services employ a range of techniques such as model quantization, pruning, or efficient inference strategies to enhance LLM efficiency, reduce computational overhead, and improve overall performance across diverse deployment scenarios."
              },
              {
                  "name": "Plug-ins for Security",
                  "id": "CSA-AICM-AC-OrchestratedServices-SecurityPlugins",
                  "description": "Plug-ins for Security encompass extensions or add-ons designed to bolster the security posture of LLM deployments. These plug-ins may offer features such as data encryption, access control mechanisms, threat detection capabilities, and compliance enforcement measures, augmenting the resilience of LLM systems against security threats and vulnerabilities."
              },
              {
                  "name": "Plug-ins for Customization and Integration",
                  "id": "CSA-AICM-AC-OrchestratedServices-CustomizationPlugins",
                  "description": "Plug-ins for Customization and Integration enable the customization of LLM behavior and seamless integration with other systems, applications, or data sources. These plug-ins provide flexibility in tailoring LLM functionalities to specific use cases or domains and facilitate interoperability with existing infrastructure, fostering enhanced versatility and utility of LLM deployments."
              },
              {
                  "name": "LLM/GenAI General Agents",
                  "id": "CSA-AICM-AC-OrchestratedServices-GeneralAgents",
                  "description": "LLM General Agents are intelligent agents or components that collaborate with LLMs to augment their functionalities and capabilities. These agents may perform various tasks such as planning, reflection, function calling, monitoring, data processing, explainability, optimization, scaling, and collaboration, enhancing the versatility and adaptability of LLM deployments in diverse operational contexts."
              }
          ]
      },
      {
          "name": "AI Applications",
          "display_name": "AI Applications",
          "id": "CSA-AICM-AC-AIApplications",
          "asset_subcategories": [
              {
                  "name": "User Interfaces",
                  "id": "CSA-AICM-AC-AIApplications-UserInterfaces",
                  "description": "****************************"
              },
              {
                  "name": "Application-specific Models",
                  "id": "CSA-AICM-AC-AIApplications-ApplicationModels",
                  "description": "****************************"
              },
              {
                  "name": "Integration Tools",
                  "id": "CSA-AICM-AC-AIApplications-IntegrationTools",
                  "description": "****************************"
              },
              {
                  "name": "Decision Support Systems",
                  "id": "CSA-AICM-AC-AIApplications-DecisionSupport",
                  "description": "****************************"
              },
              {
                  "name": "Content Generation Tools",
                  "id": "CSA-AICM-AC-AIApplications-ContentGeneration",
                  "description": "****************************"
              },
              {
                  "name": "Accessibility Tools",
                  "id": "CSA-AICM-AC-AIApplications-Accessibility",
                  "description": "****************************"
              }
          ]
      }
  ]
}
