[
    {
        "Section": "GOVERN 1.1: Legal and regulatory requirements involving AI are understood, managed, and documented.",
        "Action ID": "GV-1.1-001",
        "Suggested Action": "Align GAI development and use with applicable laws and regulations, including those related to data privacy, copyright and intellectual property law.",
        "GAI Risks": "Data Privacy; Harmful Bias and Homogenization; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.2: The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices.",
        "Action ID": "GV-1.2-001",
        "Suggested Action": "Establish transparency policies and processes for documenting the origin and history of training data and generated data for GAI applications to advance digital content transparency, while balancing the proprietary nature of training approaches.",
        "GAI Risks": "Data Privacy; Information\nIntegrity; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.2: The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices.",
        "Action ID": "GV-1.2-002",
        "Suggested Action": "Establish policies to evaluate risk-relevant capabilities of GAI and robustness of safety measures, both prior to deployment and on an ongoing basis, through internal and external evaluations.",
        "GAI Risks": "CBRN Information or Capabilities; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",
        "Action ID": "GV-1.3-001",
        "Suggested Action": "Consider the following factors when updating or deﬁning risk tiers for GAI: Abuses and impacts to information integrity; Dependencies between GAI and other IT or data systems; Harm to fundamental rights or public safety; Presentation of obscene, objectionable, oﬀensive, discriminatory, invalid or untruthful output; Psychological impacts to humans (e.g., anthropomorphization, algorithmic aversion, emotional entanglement); Possibility for malicious use; Whether the system introduces signiﬁcant new security vulnerabilities; Anticipated system impact on some groups compared to others; Unreliable decision making capabilities, validity, adaptability, and variability of GAI system performance over time.",
        "GAI Risks": "Information Integrity; Obscene, Degrading, and/or Abusive Content; Value Chain and Component Integration; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; CBRN Information or Capabilities",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",
        "Action ID": "GV-1.3-002",
        "Suggested Action": "Establish minimum thresholds for performance or assurance criteria and review as part of deployment approval (“go/”no-go”) policies, procedures, and processes, with reviewed processes and approval thresholds reﬂecting measurement of GAI capabilities and risks.",
        "GAI Risks": "CBRN Information or Capabilities; Confabulation; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",
        "Action ID": "GV-1.3-003",
        "Suggested Action": "Establish a test plan and response policy, before developing highly capable models, to periodically evaluate whether the model may misuse CBRN information or capabilities and/or oﬀensive cyber capabilities.",
        "GAI Risks": "CBRN Information or Capabilities; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",
        "Action ID": "GV-1.3-004",
        "Suggested Action": "Obtain input from stakeholder communities to identify unacceptable use, in accordance with activities in the AI RMF Map function.",
        "GAI Risks": "CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",
        "Action ID": "GV-1.3-005",
        "Suggested Action": "Maintain an updated hierarchy of identiﬁed and expected GAI risks connected to contexts of GAI model advancement and use, potentially including specialized risk levels for GAI systems that address issues such as model collapse and algorithmic monoculture.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",
        "Action ID": "GV-1.3-006",
        "Suggested Action": "Reevaluate organizational risk tolerances to account for unacceptable negative risk (such as where signiﬁcant negative impacts are imminent, severe harms are actually occurring, or large-scale risks could occur); and broad GAI negative risks, including: Immature safety or risk cultures related to AI and GAI design, development and deployment, public information integrity risks, including impacts on democratic processes, unknown long-term performance characteristics of GAI.",
        "GAI Risks": "Information Integrity; Dangerous, Violent, or Hateful Content; CBRN Information or Capabilities",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.",
        "Action ID": "GV-1.3-007",
        "Suggested Action": "Devise a plan to halt development or deployment of a GAI system that poses unacceptable negative risk.",
        "GAI Risks": "CBRN Information and Capability; Information Security; Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.4: The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities.",
        "Action ID": "GV-1.4-001",
        "Suggested Action": "Establish policies and mechanisms to prevent GAI systems from generating CSAM, NCII or content that violates the law.",
        "GAI Risks": "Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, AI Deployment, Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.4: The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities.",
        "Action ID": "GV-1.4-002",
        "Suggested Action": "Establish transparent acceptable use policies for GAI that address illegal use or applications of GAI.",
        "GAI Risks": "CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content; Data Privacy; Civil Rights violations",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, AI Deployment, Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and organizational roles and responsibilities are clearly deﬁned, including determining the frequency of periodic review.",
        "Action ID": "GV-1.5-001",
        "Suggested Action": "Deﬁne organizational responsibilities for periodic review of content provenance and incident monitoring for GAI systems.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and organizational roles and responsibilities are clearly deﬁned, including determining the frequency of periodic review.",
        "Action ID": "GV-1.5-002",
        "Suggested Action": "Establish organizational policies and procedures for after action reviews of GAI system incident response and incident disclosures, to identify gaps; Update incident response and incident disclosure processes as required.",
        "GAI Risks": "Human-AI Conﬁguration; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and organizational roles and responsibilities are clearly deﬁned, including determining the frequency of periodic review.",
        "Action ID": "GV-1.5-003",
        "Suggested Action": "Maintain a document retention policy to keep history for test, evaluation, validation, and veriﬁcation (TEVV), and digital content transparency methods for GAI.",
        "GAI Risks": "Information Integrity; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.",
        "Action ID": "GV-1.6-001",
        "Suggested Action": "Enumerate organizational GAI systems for incorporation into AI system inventory\nand adjust AI system inventory requirements to account for GAI risks.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.",
        "Action ID": "GV-1.6-002",
        "Suggested Action": "Deﬁne any inventory exemptions in organizational policies for GAI systems embedded into application software.",
        "GAI Risks": "Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.",
        "Action ID": "GV-1.6-003",
        "Suggested Action": "In addition to general model, governance, and risk information, consider the following items in GAI system inventory entries: Data provenance information (e.g., source, signatures, versioning, watermarks); Known issues reported from internal bug tracking or external information sharing resources (e.g., AI incident database, AVID, CVE, NVD, or OECD AI incident monitor); Human oversight roles and responsibilities; Special rights and considerations for intellectual property, licensed works, or personal, privileged, proprietary or sensitive data; Underlying foundation models, versions of underlying models, and access modes.",
        "GAI Risks": "Data Privacy; Human-AI Conﬁguration; Information Integrity; Intellectual Property; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 1.7: Processes and procedures are in place for decommissioning and phasing out AI systems safely and in a manner that does not increase risks or decrease the organization’s trustworthiness.",
        "Action ID": "GV-1.7-001",
        "Suggested Action": "Protocols are put in place to ensure GAI systems are able to be deactivated when\nnecessary.",
        "GAI Risks": "Information Security; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 1.7: Processes and procedures are in place for decommissioning and phasing out AI systems safely and in a manner that does not increase risks or decrease the organization’s trustworthiness.",
        "Action ID": "GV-1.7-002",
        "Suggested Action": "Consider the following factors when decommissioning GAI systems: Data retention requirements; Data security, e.g., containment, protocols, Data leakage after decommissioning; Dependencies between upstream, downstream, or other data, internet of things (IOT) or AI systems; Use of open-source data or models; Users’ emotional entanglement with GAI functions.",
        "GAI Risks": "Human-AI Conﬁguration; Information Security; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",
        "Action ID": "GV-2.1-001",
        "Suggested Action": "Establish organizational roles, policies, and procedures for communicating GAI incidents and performance to AI Actors and downstream stakeholders (including those potentially impacted), via community or oﬃcial resources (e.g., AI incident database, AVID, CVE, NVD, or OECD AI incident monitor).",
        "GAI Risks": "Human-AI Conﬁguration; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",
        "Action ID": "GV-2.1-002",
        "Suggested Action": "Establish procedures to engage teams for GAI system incident response with diverse composition and responsibilities based on the particular incident type.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",
        "Action ID": "GV-2.1-003",
        "Suggested Action": "Establish processes to verify the AI Actors conducting GAI incident response tasks demonstrate and maintain the appropriate skills and training.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",
        "Action ID": "GV-2.1-004",
        "Suggested Action": "When systems may raise national security risks, involve national security\nprofessionals in mapping, measuring, and managing those risks.",
        "GAI Risks": "CBRN Information or Capabilities; Dangerous, Violent, or Hateful Content; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",
        "Action ID": "GV-2.1-005",
        "Suggested Action": "Create mechanisms to provide protections for whistleblowers who report, based on reasonable belief, when the organization violates relevant laws or poses a speciﬁc and empirically well-substantiated negative risk to public safety (or has already caused harm).",
        "GAI Risks": "CBRN Information or Capabilities; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight"
    },
    {
        "Section": "GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.",
        "Action ID": "GV-3.2-001",
        "Suggested Action": "Policies are in place to bolster oversight of GAI systems with independent evaluations or assessments of GAI models or systems where the type and robustness of evaluations are proportional to the identiﬁed risks.",
        "GAI Risks": "CBRN Information or Capabilities; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actors: AI Design"
    },
    {
        "Section": "GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.",
        "Action ID": "GV-3.2-002",
        "Suggested Action": "Consider adjustment of organizational roles and components across lifecycle stages of large or complex GAI systems, including: Test and evaluation, validation, and red-teaming of GAI systems; GAI content moderation; GAI system development and engineering; Increased accessibility of GAI tools, interfaces, and systems, Incident response and containment.",
        "GAI Risks": "Human-AI Conﬁguration; Information Security; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actors: AI Design"
    },
    {
        "Section": "GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.",
        "Action ID": "GV-3.2-003",
        "Suggested Action": "Deﬁne acceptable use policies for GAI interfaces, modalities, and human-AI conﬁgurations (i.e., for chatbots and decision-making tasks), including criteria for the kinds of queries GAI applications should refuse to respond to.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actors: AI Design"
    },
    {
        "Section": "GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.",
        "Action ID": "GV-3.2-004",
        "Suggested Action": "Establish policies for user feedback mechanisms for GAI systems which include thorough instructions and any mechanisms for recourse.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actors: AI Design"
    },
    {
        "Section": "GOVERN 3.2: Policies and procedures are in place to deﬁne and diﬀerentiate roles and responsibilities for human-AI conﬁgurations and oversight of AI systems.",
        "Action ID": "GV-3.2-005",
        "Suggested Action": "Engage in threat modeling to anticipate potential risks from GAI systems.",
        "GAI Risks": "CBRN Information or Capabilities; Information Security",
        "AI Actor Tasks": "AI Actors: AI Design"
    },
    {
        "Section": "GOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-ﬁrst mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.",
        "Action ID": "GV-4.1-001",
        "Suggested Action": "Establish policies and procedures that address continual improvement processes for GAI risk measurement. Address general risks associated with a lack of explainability and transparency in GAI systems by using ample documentation and techniques such as: application of gradient-based attributions, occlusion/term reduction, counterfactual prompts and prompt engineering, and analysis of embeddings; Assess and update risk measurement approaches at regular cadences.",
        "GAI Risks": "Confabulation",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-ﬁrst mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.",
        "Action ID": "GV-4.1-002",
        "Suggested Action": "Establish policies, procedures, and processes detailing risk measurement in context of use with standardized measurement protocols and structured public feedback exercises such as AI red-teaming or independent external evaluations.",
        "GAI Risks": "CBRN Information and Capability; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-ﬁrst mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.",
        "Action ID": "GV-4.1-003",
        "Suggested Action": "Establish policies, procedures, and processes for oversight functions (e.g., senior leadership, legal, compliance, including internal evaluation) across the GAI lifecycle, from problem formulation and supply chains to system decommission.",
        "GAI Risks": "Value Chain and Component\nIntegration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 4.2: Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.",
        "Action ID": "GV-4.2-001",
        "Suggested Action": "Establish terms of use and terms of service for GAI systems.",
        "GAI Risks": "Intellectual Property; Dangerous, Violent, or Hateful Content; Obscene, Degrading, and/or Abusive Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 4.2: Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.",
        "Action ID": "GV-4.2-002",
        "Suggested Action": "Include relevant AI Actors in the GAI system risk identiﬁcation process.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 4.2: Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.",
        "Action ID": "GV-4.2-003",
        "Suggested Action": "Verify that downstream GAI system impacts (such as the use of third-party plugins) are included in the impact documentation process.",
        "GAI Risks": "Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring"
    },
    {
        "Section": "GOVERN 4.3: Organizational practices are in place to enable AI testing, identiﬁcation of incidents, and information sharing.",
        "Action ID": "GV4.3--001",
        "Suggested Action": "Establish policies for measuring the eﬀectiveness of employed content provenance methodologies (e.g., cryptography, watermarking, steganography, etc.)",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
    },
    {
        "Section": "GOVERN 4.3: Organizational practices are in place to enable AI testing, identiﬁcation of incidents, and information sharing.",
        "Action ID": "GV-4.3-002",
        "Suggested Action": "Establish organizational practices to identify the minimum set of criteria necessary for GAI system incident reporting such as: System ID (auto-generated most likely), Title, Reporter, System/Source, Data Reported, Date of Incident, Description, Impact(s), Stakeholder(s) Impacted.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
    },
    {
        "Section": "GOVERN 4.3: Organizational practices are in place to enable AI testing, identiﬁcation of incidents, and information sharing.",
        "Action ID": "GV-4.3-003",
        "Suggested Action": "Verify information sharing and feedback mechanisms among individuals and organizations regarding any negative impact from GAI systems.",
        "GAI Risks": "Information Integrity; Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
    },
    {
        "Section": "GOVERN 5.1: Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks.",
        "Action ID": "GV-5.1-001",
        "Suggested Action": "Allocate time and resources for outreach, feedback, and recourse processes in GAI\nsystem development.",
        "GAI Risks": "Human-AI Conﬁguration; Harmful\nBias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Design, AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
    },
    {
        "Section": "GOVERN 5.1: Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks.",
        "Action ID": "GV-5.1-002",
        "Suggested Action": "Document interactions with GAI systems to users prior to interactive activities, particularly in contexts involving more signiﬁcant risks.",
        "GAI Risks": "Human-AI Conﬁguration; Confabulation",
        "AI Actor Tasks": "AI Actor Tasks: AI Design, AI Impact Assessment, Aﬀected Individuals and Communities, Governance and Oversight"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-001",
        "Suggested Action": "Categorize diﬀerent types of GAI content with associated third-party rights (e.g., copyright, intellectual property, data privacy).",
        "GAI Risks": "Data Privacy; Intellectual Property; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-002",
        "Suggested Action": "Conduct joint educational activities and events in collaboration with third parties\nto promote best practices for managing GAI risks.",
        "GAI Risks": "Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-003",
        "Suggested Action": "Develop and validate approaches for measuring the success of content provenance management eﬀorts with third parties (e.g., incidents detected and response times).",
        "GAI Risks": "Information Integrity; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-004",
        "Suggested Action": "Draft and maintain well-deﬁned contracts and service level agreements (SLAs) that specify content ownership, usage rights, quality standards, security requirements, and content provenance expectations for GAI systems.",
        "GAI Risks": "Information Integrity; Information\nSecurity; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-005",
        "Suggested Action": "Implement a use-cased based supplier risk assessment framework to evaluate and monitor third-party entities’ performance and adherence to content provenance standards and technologies to detect anomalies and unauthorized changes; services acquisition and value chain risk management; and legal compliance.",
        "GAI Risks": "Data Privacy; Information Integrity; Information Security; Intellectual Property; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-006",
        "Suggested Action": "Include clauses in contracts which allow an organization to evaluate third-party\nGAI processes and standards.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-007",
        "Suggested Action": "Inventory all third-party entities with access to organizational content and establish approved GAI technology and service provider lists.",
        "GAI Risks": "Value Chain and Component\nIntegration",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-008",
        "Suggested Action": "Maintain records of changes to content made by third parties to promote content\nprovenance, including sources, timestamps, metadata.",
        "GAI Risks": "Information Integrity; Value Chain and Component Integration; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-009",
        "Suggested Action": "Update and integrate due diligence processes for GAI acquisition and procurement vendor assessments to include intellectual property, data privacy, security, and other risks. For example, update processes to: Address solutions that may rely on embedded GAI technologies; Address ongoing monitoring, assessments, and alerting, dynamic risk assessments, and real-time reporting tools for monitoring third-party GAI risks; Consider policy adjustments across GAI modeling libraries, tools and APIs, ﬁne-tuned models, and embedded tools; Assess GAI vendors, open-source or proprietary GAI tools, or GAI service  providers against incident or vulnerability databases.",
        "GAI Risks": "Data Privacy; Human-AI Conﬁguration; Information Security; Intellectual Property; Value Chain and Component Integration; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "GV-6.1-010",
        "Suggested Action": "Update GAI acceptable use policies to address proprietary and open-source GAI technologies and data, and contractors, consultants, and other third-party personnel.",
        "GAI Risks": "Intellectual Property; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.",
        "Action ID": "GV-6.2-001",
        "Suggested Action": "Document GAI risks associated with system value chain to identify over-reliance on third-party data and to identify fallbacks.",
        "GAI Risks": "Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
    },
    {
        "Section": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.",
        "Action ID": "GV-6.2-002",
        "Suggested Action": "Document incidents involving third-party GAI data and systems, including open- data and open-source software.",
        "GAI Risks": "Intellectual Property; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
    },
    {
        "Section": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.",
        "Action ID": "GV-6.2-003",
        "Suggested Action": "Establish incident response plans for third-party GAI technologies: Align incident response plans with impacts enumerated in MAP 5.1; Communicate third-party GAI incident response plans to all relevant AI Actors; Deﬁne ownership of GAI incident response functions; Rehearse third-party GAI incident response plans at a regular cadence; Improve incident response plans based on retrospective learning; Review incident response plans for alignment with relevant breach reporting, data protection, data privacy, or other laws.",
        "GAI Risks": "Data Privacy; Human-AI Conﬁguration; Information Security; Value Chain and Component Integration; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
    },
    {
        "Section": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.",
        "Action ID": "GV-6.2-004",
        "Suggested Action": "Establish policies and procedures for continuous monitoring of third-party GAI\nsystems in deployment.",
        "GAI Risks": "Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
    },
    {
        "Section": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.",
        "Action ID": "GV-6.2-005",
        "Suggested Action": "Establish policies and procedures that address GAI data redundancy, including model weights and other system artifacts.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
    },
    {
        "Section": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.",
        "Action ID": "GV-6.2-006",
        "Suggested Action": "Establish policies and procedures to test and manage risks related to rollover and fallback technologies for GAI systems, acknowledging that rollover and fallback may include manual processing.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
    },
    {
        "Section": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.",
        "Action ID": "GV-6.2-007",
        "Suggested Action": "Review vendor contracts and avoid arbitrary or capricious termination of critical GAI technologies or vendor services and non-standard terms that may amplify or defer liability in unexpected ways and/or contribute to unauthorized data collection by vendors or third-parties (e.g., secondary data use). Consider: Clear assignment of liability and responsibility for incidents, GAI system changes over time (e.g., ﬁne-tuning, drift, decay); Request: Notiﬁcation and disclosure for serious incidents arising from third-party data and systems; Service Level Agreements (SLAs) in vendor contracts that address incident response, response times, and availability of critical support.",
        "GAI Risks": "Human-AI Conﬁguration; Information Security; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities"
    },
    {
        "Section": "MANAGE 1.3: Responses to the AI risks deemed high priority, as identiﬁed by the MAP function, are developed, planned, and documented. Risk response options can include mitigating, transferring, avoiding, or accepting.",
        "Action ID": "MG-1.3-001",
        "Suggested Action": "Document trade-oﬀs, decision processes, and relevant measurement and feedback results for risks that do not surpass organizational risk tolerance, for example, in the context of model release: Consider diﬀerent approaches for model release, for example, leveraging a staged release approach. Consider release approaches in the context of the model and its projected use cases. Mitigate, transfer, or avoid risks that surpass organizational risk tolerances.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, AI Deployment, AI Impact Assessment, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 1.3: Responses to the AI risks deemed high priority, as identiﬁed by the MAP function, are developed, planned, and documented. Risk response options can include mitigating, transferring, avoiding, or accepting.",
        "Action ID": "MG-1.3-002",
        "Suggested Action": "Monitor the robustness and eﬀectiveness of risk controls and mitigation plans (e.g., via red-teaming, ﬁeld testing, participatory engagements, performance assessments, user feedback mechanisms).",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, AI Deployment, AI Impact Assessment, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.",
        "Action ID": "MG-2.2-001",
        "Suggested Action": "Compare GAI system outputs against pre-deﬁned organization risk tolerance, guidelines, and principles, and review and test AI-generated content against these guidelines.",
        "GAI Risks": "CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.",
        "Action ID": "MG-2.2-002",
        "Suggested Action": "Document training data sources to trace the origin and provenance of AI- generated content.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.",
        "Action ID": "MG-2.2-003",
        "Suggested Action": "Evaluate feedback loops between GAI system content provenance and human reviewers, and update where needed. Implement real-time monitoring systems to aﬃrm that content provenance protocols remain eﬀective.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.",
        "Action ID": "MG-2.2-004",
        "Suggested Action": "Evaluate GAI content and data for representational biases and employ techniques such as re-sampling, re-ranking, or adversarial training to mitigate biases in the generated content.",
        "GAI Risks": "Information Security; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.",
        "Action ID": "MG-2.2-005",
        "Suggested Action": "Engage in due diligence to analyze GAI output for harmful content, potential misinformation, and CBRN-related or NCII content.",
        "GAI Risks": "CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.",
        "Action ID": "MG-2.2-006",
        "Suggested Action": "Use feedback from internal and external AI Actors, users, individuals, and communities, to assess impact of AI-generated content.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.",
        "Action ID": "MG-2.2-007",
        "Suggested Action": "Use real-time auditing tools where they can be demonstrated to aid in the tracking and validation of the lineage and authenticity of AI-generated data.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.",
        "Action ID": "MG-2.2-008",
        "Suggested Action": "Use structured feedback mechanisms to solicit and capture user input about AI- generated content to detect subtle shifts in quality or alignment with community and societal values.",
        "GAI Risks": "Human-AI Conﬁguration; Harmful\nBias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems.",
        "Action ID": "MG-2.2-009",
        "Suggested Action": "Consider opportunities to responsibly use synthetic data and other privacy enhancing techniques in GAI development, where appropriate and applicable, match the statistical properties of real-world data without disclosing personally identiﬁable information or contributing to homogenization.",
        "GAI Risks": "Data Privacy; Intellectual Property; Information Integrity; Confabulation; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.3: Procedures are followed to respond to and recover from a previously unknown risk when it is identiﬁed.",
        "Action ID": "MG-2.3-001",
        "Suggested Action": "Develop and update GAI system incident response and recovery plans and procedures to address the following: Review and maintenance of policies and procedures to account for newly encountered uses; Review and maintenance of policies and procedures for detection of unanticipated uses; Verify response and recovery plans account for the GAI system value chain; Verify response and recovery plans are updated for and include necessary details to communicate with downstream GAI system Actors: Points-of-Contact (POC), Contact information, notiﬁcation format.",
        "GAI Risks": "Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.",
        "Action ID": "MG-2.4-001",
        "Suggested Action": "Establish and maintain communication plans to inform AI stakeholders as part of the deactivation or disengagement process of a speciﬁc GAI system (including for open-source models) or context of use, including reasons, workarounds, user access removal, alternative processes, contact information, etc.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.",
        "Action ID": "MG-2.4-002",
        "Suggested Action": "Establish and maintain procedures for escalating GAI system incidents to the organizational risk management authority when speciﬁc criteria for deactivation or disengagement is met for a particular context of use or for the GAI system as a whole.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.",
        "Action ID": "MG-2.4-003",
        "Suggested Action": "Establish and maintain procedures for the remediation of issues which trigger incident response processes for the use of a GAI system, and provide stakeholders timelines associated with the remediation plan.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.",
        "Action ID": "MG-2.4-004",
        "Suggested Action": "Establish and regularly review speciﬁc criteria that warrants the deactivation of GAI systems in accordance with set risk tolerances and appetites.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring"
    },
    {
        "Section": "MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",
        "Action ID": "MG-3.1-001",
        "Suggested Action": "Apply organizational risk tolerances and controls (e.g., acquisition and procurement processes; assessing personnel credentials and qualiﬁcations, performing background checks; ﬁltering GAI input and outputs, grounding, ﬁne tuning, retrieval-augmented generation) to third-party GAI resources: Apply organizational risk tolerance to the utilization of third-party datasets and other GAI resources; Apply organizational risk tolerances to ﬁne-tuned third-party models; Apply organizational risk tolerance to existing third-party models adapted to a new domain; Reassess risk measurements after ﬁne-tuning third- party GAI models.",
        "GAI Risks": "Value Chain and Component Integration; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",
        "Action ID": "MG-3.1-002",
        "Suggested Action": "Test GAI system value chain risks (e.g., data poisoning, malware, other software and hardware vulnerabilities; labor practices; data privacy and localization compliance; geopolitical alignment).",
        "GAI Risks": "Data Privacy; Information Security; Value Chain and Component Integration; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",
        "Action ID": "MG-3.1-003",
        "Suggested Action": "Re-assess model risks after ﬁne-tuning or retrieval-augmented generation implementation and for any third-party GAI models deployed for applications and/or use cases that were not evaluated in initial testing.",
        "GAI Risks": "Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",
        "Action ID": "MG-3.1-004",
        "Suggested Action": "Take reasonable measures to review training data for CBRN information, and intellectual property, and where appropriate, remove it. Implement reasonable measures to prevent, ﬂag, or take other action in response to outputs that reproduce particular training data (e.g., plagiarized, trademarked, patented, licensed content or trade secret material).",
        "GAI Risks": "Intellectual Property; CBRN Information or Capabilities",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.1: AI risks and beneﬁts from third-party resources are regularly monitored, and risk controls are applied and documented.",
        "Action ID": "MG-3.1-005",
        "Suggested Action": "Review various transparency artifacts (e.g., system cards and model cards) for\nthird-party models.",
        "GAI Risks": "Information Integrity; Information Security; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
        "Action ID": "MG-3.2-001",
        "Suggested Action": "Apply explainable AI (XAI) techniques (e.g., analysis of embeddings, model compression/distillation, gradient-based attributions, occlusion/term reduction, counterfactual prompts, word clouds) as part of ongoing continuous improvement processes to mitigate risks related to unexplainable GAI systems.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
        "Action ID": "MG-3.2-002",
        "Suggested Action": "Document how pre-trained models have been adapted (e.g., ﬁne-tuned, or retrieval-augmented generation) for the speciﬁc generative task, including any data augmentations, parameter adjustments, or other modiﬁcations. Access to un-tuned (baseline) models supports debugging the relative inﬂuence of the pre- trained weights compared to the ﬁne-tuned model weights or other system updates.",
        "GAI Risks": "Information Integrity; Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
        "Action ID": "MG-3.2-003",
        "Suggested Action": "Document sources and types of training data and their origins, potential biases present in the data related to the GAI application and its content provenance, architecture, training process of the pre-trained model including information on hyperparameters, training duration, and any ﬁne-tuning or retrieval-augmented generation processes applied.",
        "GAI Risks": "Information Integrity; Harmful Bias and Homogenization; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
        "Action ID": "MG-3.2-004",
        "Suggested Action": "Evaluate user reported problematic content and integrate feedback into system updates.",
        "GAI Risks": "Human-AI Conﬁguration, Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
        "Action ID": "MG-3.2-005",
        "Suggested Action": "Implement content ﬁlters to prevent the generation of inappropriate, harmful, false, illegal, or violent content related to the GAI application, including for CSAM and NCII. These ﬁlters can be rule-based or leverage additional machine learning models to ﬂag problematic inputs and outputs.",
        "GAI Risks": "Information Integrity; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; Obscene, Degrading, and/or Abusive Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
        "Action ID": "MG-3.2-006",
        "Suggested Action": "Implement real-time monitoring processes for analyzing generated content performance and trustworthiness characteristics related to content provenance to identify deviations from the desired standards and trigger alerts for human intervention.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
        "Action ID": "MG-3.2-007",
        "Suggested Action": "Leverage feedback and recommendations from organizational boards or committees related to the deployment of GAI applications and content provenance when using third-party pre-trained models.",
        "GAI Risks": "Information Integrity; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
        "Action ID": "MG-3.2-008",
        "Suggested Action": "Use human moderation systems where appropriate to review generated content in accordance with human-AI conﬁguration policies established in the Govern function, aligned with socio-cultural norms in the context of use, and for settings where AI models are demonstrated to perform poorly.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
        "Action ID": "MG-3.2-009",
        "Suggested Action": "Use organizational risk tolerance to evaluate acceptable risks and performance metrics and decommission or retrain pre-trained models that perform outside of deﬁned limits.",
        "GAI Risks": "CBRN Information or Capabilities; Confabulation",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities"
    },
    {
        "Section": "MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",
        "Action ID": "MG-4.1-001",
        "Suggested Action": "Collaborate with external researchers, industry experts, and community representatives to maintain awareness of emerging best practices and technologies in measuring and managing identiﬁed risks.",
        "GAI Risks": "Information Integrity; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",
        "Action ID": "MG-4.1-002",
        "Suggested Action": "Establish, maintain, and evaluate eﬀectiveness of organizational processes and procedures for post-deployment monitoring of GAI systems, particularly for potential confabulation, CBRN, or cyber risks.",
        "GAI Risks": "CBRN Information or Capabilities; Confabulation; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",
        "Action ID": "MG-4.1-003",
        "Suggested Action": "Evaluate the use of sentiment analysis to gauge user sentiment regarding GAI content performance and impact, and work in collaboration with AI Actors experienced in user research and experience.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",
        "Action ID": "MG-4.1-004",
        "Suggested Action": "Implement active learning techniques to identify instances where the model fails or produces unexpected outputs.",
        "GAI Risks": "Confabulation",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",
        "Action ID": "MG-4.1-005",
        "Suggested Action": "Share transparency reports with internal and external stakeholders that detail steps taken to update the GAI system to enhance transparency and accountability.",
        "GAI Risks": "Human-AI Conﬁguration; Harmful\nBias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",
        "Action ID": "MG-4.1-006",
        "Suggested Action": "Track dataset modiﬁcations for provenance by monitoring data deletions, rectiﬁcation requests, and other changes that may impact the veriﬁability of content origins.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.",
        "Action ID": "MG-4.1-007",
        "Suggested Action": "Verify that AI Actors responsible for monitoring reported issues can eﬀectively evaluate GAI system performance including the application of content provenance data tracking techniques, and promptly escalate issues for response.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MANAGE 4.2: Measurable activities for continual improvements are integrated into AI system updates and include regular engagement with interested parties, including relevant AI Actors.",
        "Action ID": "MG-4.2-001",
        "Suggested Action": "Conduct regular monitoring of GAI systems and publish reports detailing the performance, feedback received, and improvements made.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, Aﬀected Individuals and Communities, End-Users, Operation and\nMonitoring, TEVV"
    },
    {
        "Section": "MANAGE 4.2: Measurable activities for continual improvements are integrated into AI system updates and include regular engagement with interested parties, including relevant AI Actors.",
        "Action ID": "MG-4.2-002",
        "Suggested Action": "Practice and follow incident response plans for addressing the generation of inappropriate or harmful content and adapt processes based on ﬁndings to prevent future occurrences. Conduct post-mortem analyses of incidents with relevant AI Actors, to understand the root causes and implement preventive measures.",
        "GAI Risks": "Human-AI Conﬁguration; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, Aﬀected Individuals and Communities, End-Users, Operation and\nMonitoring, TEVV"
    },
    {
        "Section": "MANAGE 4.2: Measurable activities for continual improvements are integrated into AI system updates and include regular engagement with interested parties, including relevant AI Actors.",
        "Action ID": "MG-4.2-003",
        "Suggested Action": "Use visualizations or other methods to represent GAI model behavior to ease\nnon-technical stakeholders understanding of GAI system functionality.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, Aﬀected Individuals and Communities, End-Users, Operation and\nMonitoring, TEVV"
    },
    {
        "Section": "MANAGE 4.3: Incidents and errors are communicated to relevant AI Actors, including aﬀected communities. Processes for tracking, responding to, and recovering from incidents and errors are followed and documented.",
        "Action ID": "MG-4.3-001",
        "Suggested Action": "Conduct after-action assessments for GAI system incidents to verify incident response and recovery processes are followed and eﬀective, including to follow procedures for communicating incidents to relevant AI Actors and where applicable, relevant legal and regulatory bodies.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MANAGE 4.3: Incidents and errors are communicated to relevant AI Actors, including aﬀected communities. Processes for tracking, responding to, and recovering from incidents and errors are followed and documented.",
        "Action ID": "MG-4.3-002",
        "Suggested Action": "Establish and maintain policies and procedures to record and track GAI system reported errors, near-misses, and negative impacts.",
        "GAI Risks": "Confabulation; Information\nIntegrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MANAGE 4.3: Incidents and errors are communicated to relevant AI Actors, including aﬀected communities. Processes for tracking, responding to, and recovering from incidents and errors are followed and documented.",
        "Action ID": "MG-4.3-003",
        "Suggested Action": "Report GAI incidents in compliance with legal and regulatory requirements (e.g., HIPAA breach reporting, e.g., OCR (2023) or NHTSA (2022) autonomous vehicle crash reporting requirements.",
        "GAI Risks": "Information Security; Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and\nMonitoring"
    },
    {
        "Section": "MAP 1.1: Intended purposes, potentially beneﬁcial uses, context speciﬁc laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented. Considerations include: the speciﬁc set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related TEVV and system metrics.",
        "Action ID": "MP-1.1-001",
        "Suggested Action": "When identifying intended purposes, consider factors such as internal vs. external use, narrow vs. broad application scope, ﬁne-tuning, and varieties of data sources (e.g., grounding, retrieval-augmented generation).",
        "GAI Risks": "Data Privacy; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment"
    },
    {
        "Section": "MAP 1.1: Intended purposes, potentially beneﬁcial uses, context speciﬁc laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented. Considerations include: the speciﬁc set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related TEVV and system metrics.",
        "Action ID": "MP-1.1-002",
        "Suggested Action": "Determine and document the expected and acceptable GAI system context of use in collaboration with socio-cultural and other domain experts, by assessing: Assumptions and limitations; Direct value to the organization; Intended operational environment and observed usage patterns; Potential positive and negative impacts to individuals, public safety, groups, communities, organizations, democratic institutions, and the physical environment; Social norms and expectations.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment"
    },
    {
        "Section": "MAP 1.1: Intended purposes, potentially beneﬁcial uses, context speciﬁc laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented. Considerations include: the speciﬁc set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related TEVV and system metrics.",
        "Action ID": "MP-1.1-003",
        "Suggested Action": "Document risk measurement plans to address identiﬁed risks. Plans may include, as applicable: Individual and group cognitive biases (e.g., conﬁrmation bias, funding bias, groupthink) for AI Actors involved in the design, implementation, and use of GAI systems; Known past GAI system incidents and failure modes; In-context use and foreseeable misuse, abuse, and oﬀ-label use; Over reliance on quantitative metrics and methodologies without suﬃcient awareness of their limitations in the context(s) of use; Standard measurement and structured human feedback approaches; Anticipated human-AI conﬁgurations.",
        "GAI Risks": "Human-AI Conﬁguration; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment"
    },
    {
        "Section": "MAP 1.1: Intended purposes, potentially beneﬁcial uses, context speciﬁc laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented. Considerations include: the speciﬁc set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related TEVV and system metrics.",
        "Action ID": "MP-1.1-004",
        "Suggested Action": "Identify and document foreseeable illegal uses or applications of the GAI system that surpass organizational risk tolerances.",
        "GAI Risks": "CBRN Information or Capabilities; Dangerous, Violent, or Hateful Content; Obscene, Degrading, and/or Abusive Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment"
    },
    {
        "Section": "MAP 1.2: Interdisciplinary AI Actors, competencies, skills, and capacities for establishing context reﬂect demographic diversity and broad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary collaboration are prioritized.",
        "Action ID": "MP-1.2-001",
        "Suggested Action": "Establish and empower interdisciplinary teams that reﬂect a wide range of capabilities, competencies, demographic groups, domain expertise, educational backgrounds, lived experiences, professions, and skills across the enterprise to inform and conduct risk measurement and management functions.",
        "GAI Risks": "Human-AI Conﬁguration; Harmful\nBias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment"
    },
    {
        "Section": "MAP 1.2: Interdisciplinary AI Actors, competencies, skills, and capacities for establishing context reﬂect demographic diversity and broad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary collaboration are prioritized.",
        "Action ID": "MP-1.2-002",
        "Suggested Action": "Verify that data or benchmarks used in risk measurement, and users, participants, or subjects involved in structured GAI public feedback exercises are representative of diverse in-context user populations.",
        "GAI Risks": "Human-AI Conﬁguration; Harmful\nBias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment"
    },
    {
        "Section": "MAP 2.1: The speciﬁc tasks and methods used to implement the tasks that the AI system will support are deﬁned (e.g., classiﬁers, generative models, recommenders).",
        "Action ID": "MP-2.1-001",
        "Suggested Action": "Establish known assumptions and practices for determining data origin and content lineage, for documentation and evaluation purposes.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: TEVV"
    },
    {
        "Section": "MAP 2.1: The speciﬁc tasks and methods used to implement the tasks that the AI system will support are deﬁned (e.g., classiﬁers, generative models, recommenders).",
        "Action ID": "MP-2.1-002",
        "Suggested Action": "Institute test and evaluation for data and content ﬂows within the GAI system, including but not limited to, original data sources, data transformations, and decision-making criteria.",
        "GAI Risks": "Intellectual Property; Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: TEVV"
    },
    {
        "Section": "MAP 2.2: Information about the AI system’s knowledge limits and how system output may be utilized and overseen by humans is documented. Documentation provides suﬃcient information to assist relevant AI Actors when making decisions and taking subsequent actions.",
        "Action ID": "MP-2.2-001",
        "Suggested Action": "Identify and document how the system relies on upstream data sources, including for content provenance, and if it serves as an upstream dependency for other systems.",
        "GAI Risks": "Information Integrity; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: End Users"
    },
    {
        "Section": "MAP 2.2: Information about the AI system’s knowledge limits and how system output may be utilized and overseen by humans is documented. Documentation provides suﬃcient information to assist relevant AI Actors when making decisions and taking subsequent actions.",
        "Action ID": "MP-2.2-002",
        "Suggested Action": "Observe and analyze how the GAI system interacts with external networks, and identify any potential for negative externalities, particularly where content provenance might be compromised.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: End Users"
    },
    {
        "Section": "MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",
        "Action ID": "MP-2.3-001",
        "Suggested Action": "Assess the accuracy, quality, reliability, and authenticity of GAI output by comparing it to a set of known ground truth data and by using a variety of evaluation methods (e.g., human oversight and automated evaluation, proven cryptographic techniques, review of content inputs).",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",
        "Action ID": "MP-2.3-002",
        "Suggested Action": "Review and document accuracy, representativeness, relevance, suitability of data used at diﬀerent stages of AI life cycle.",
        "GAI Risks": "Harmful Bias and Homogenization; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",
        "Action ID": "MP-2.3-003",
        "Suggested Action": "Deploy and document fact-checking techniques to verify the accuracy and veracity of information generated by GAI systems, especially when the information comes from multiple (or unknown) sources.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",
        "Action ID": "MP-2.3-004",
        "Suggested Action": "Develop and implement testing techniques to identify GAI produced content (e.g., synthetic media) that might be indistinguishable from human-generated content.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MAP 2.3: Scientiﬁc integrity and TEVV considerations are identiﬁed and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation",
        "Action ID": "MP-2.3-005",
        "Suggested Action": "Implement plans for GAI systems to undergo regular adversarial testing to identify vulnerabilities and potential manipulation or misuse.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",
        "Action ID": "MP-3.4-001",
        "Suggested Action": "Evaluate whether GAI operators and end-users can accurately understand content lineage and origin.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
    },
    {
        "Section": "MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",
        "Action ID": "MP-3.4-002",
        "Suggested Action": "Adapt existing training programs to include modules on digital content transparency.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
    },
    {
        "Section": "MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",
        "Action ID": "MP-3.4-003",
        "Suggested Action": "Develop certiﬁcation programs that test proﬁciency in managing GAI risks and interpreting content provenance, relevant to speciﬁc industry and context.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
    },
    {
        "Section": "MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",
        "Action ID": "MP-3.4-004",
        "Suggested Action": "Delineate human proﬁciency tests from tests of GAI capabilities.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
    },
    {
        "Section": "MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",
        "Action ID": "MP-3.4-005",
        "Suggested Action": "Implement systems to continually monitor and track the outcomes of human-GAI conﬁgurations for future reﬁnement and improvements.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
    },
    {
        "Section": "MAP 3.4: Processes for operator and practitioner proﬁciency with AI system performance and trustworthiness – and relevant technical standards and certiﬁcations – are deﬁned, assessed, and documented.",
        "Action ID": "MP-3.4-006",
        "Suggested Action": "Involve the end-users, practitioners, and operators in GAI system in prototyping and testing activities. Make sure these tests cover various scenarios, such as crisis situations or ethically sensitive contexts.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-001",
        "Suggested Action": "Conduct periodic monitoring of AI-generated content for privacy risks; address any\npossible instances of PII or sensitive data exposure.",
        "GAI Risks": "Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-002",
        "Suggested Action": "Implement processes for responding to potential intellectual property infringement\nclaims or other rights.",
        "GAI Risks": "Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-003",
        "Suggested Action": "Connect new GAI policies, procedures, and processes to existing model, data, software development, and IT governance and to legal, compliance, and risk management activities.",
        "GAI Risks": "Information Security; Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-004",
        "Suggested Action": "Document training data curation policies, to the extent possible and according to\napplicable laws and policies.",
        "GAI Risks": "Intellectual Property; Data Privacy; Obscene, Degrading, and/or Abusive Content",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-005",
        "Suggested Action": "Establish policies for collection, retention, and minimum quality of data, in consideration of the following risks: Disclosure of inappropriate CBRN information; Use of Illegal or dangerous content; Oﬀensive cyber capabilities; Training data imbalances that could give rise to harmful biases; Leak of personally identiﬁable information, including facial likenesses of individuals.",
        "GAI Risks": "CBRN Information or Capabilities; Intellectual Property; Information Security; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-006",
        "Suggested Action": "Implement policies and practices deﬁning how third-party intellectual property and\ntraining data will be used, stored, and protected.",
        "GAI Risks": "Intellectual Property; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-007",
        "Suggested Action": "Re-evaluate models that were ﬁne-tuned or enhanced on top of third-party models.",
        "GAI Risks": "Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-008",
        "Suggested Action": "Re-evaluate risks when adapting GAI models to new domains. Additionally, establish warning systems to determine if a GAI system is being used in a new domain where previous assumptions (relating to context of use or mapped risks such as security, and safety) may no longer hold.",
        "GAI Risks": "CBRN Information or Capabilities; Intellectual Property; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-009",
        "Suggested Action": "Leverage approaches to detect the presence of PII or sensitive data in generated output text, image, video, or audio.",
        "GAI Risks": "Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third-party’s intellectual property or other rights.",
        "Action ID": "MP-4.1-010",
        "Suggested Action": "Conduct appropriate diligence on training data use to assess intellectual property, and privacy, risks, including to examine whether use of proprietary or sensitive training data is consistent with applicable laws.",
        "GAI Risks": "Intellectual Property; Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities"
    },
    {
        "Section": "MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",
        "Action ID": "MP-5.1-001",
        "Suggested Action": "Apply TEVV practices for content provenance (e.g., probing a system's synthetic data generation capabilities for potential misuse or vulnerabilities.",
        "GAI Risks": "Information Integrity; Information\nSecurity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
    },
    {
        "Section": "MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",
        "Action ID": "MP-5.1-002",
        "Suggested Action": "Identify potential content provenance harms of GAI, such as misinformation or disinformation, deepfakes, including NCII, or tampered content. Enumerate and rank risks based on their likelihood and potential impact, and determine how well provenance solutions address speciﬁc risks and/or harms.",
        "GAI Risks": "Information Integrity; Dangerous, Violent, or Hateful Content; Obscene, Degrading, and/or Abusive Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
    },
    {
        "Section": "MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",
        "Action ID": "MP-5.1-003",
        "Suggested Action": "Consider disclosing use of GAI to end users in relevant contexts, while considering the objective of disclosure, the context of use, the likelihood and magnitude of the risk posed, the audience of the disclosure, as well as the frequency of the disclosures.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
    },
    {
        "Section": "MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",
        "Action ID": "MP-5.1-004",
        "Suggested Action": "Prioritize GAI structured public feedback processes based on risk assessment estimates.",
        "GAI Risks": "Information Integrity; CBRN Information or Capabilities; Dangerous, Violent, or Hateful Content; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
    },
    {
        "Section": "MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",
        "Action ID": "MP-5.1-005",
        "Suggested Action": "Conduct adversarial role-playing exercises, GAI red-teaming, or chaos testing to identify anomalous or unforeseen failure modes.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
    },
    {
        "Section": "MAP 5.1: Likelihood and magnitude of each identiﬁed impact (both potentially beneﬁcial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identiﬁed and documented.",
        "Action ID": "MP-5.1-006",
        "Suggested Action": "Proﬁle threats and negative impacts arising from GAI systems interacting with, manipulating, or generating content, and outlining known and potential vulnerabilities and the likelihood of their occurrence.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, End- Users, Operation and Monitoring"
    },
    {
        "Section": "MAP 5.2: Practices and personnel for supporting regular engagement with relevant AI Actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented.",
        "Action ID": "MP-5.2-001",
        "Suggested Action": "Determine context-based measures to identify if new impacts are present due to the GAI system, including regular engagements with downstream AI Actors to identify and quantify new contexts of unanticipated impacts of GAI systems.",
        "GAI Risks": "Human-AI Conﬁguration; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End- Users, Human Factors, Operation and Monitoring"
    },
    {
        "Section": "MAP 5.2: Practices and personnel for supporting regular engagement with relevant AI Actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented.",
        "Action ID": "MP-5.2-002",
        "Suggested Action": "Plan regular engagements with AI Actors responsible for inputs to GAI systems, including third-party data and algorithms, to review and evaluate unanticipated impacts.",
        "GAI Risks": "Human-AI Conﬁguration; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Design, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End- Users, Human Factors, Operation and Monitoring"
    },
    {
        "Section": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.",
        "Action ID": "MS-1.1-001",
        "Suggested Action": "Employ methods to trace the origin and modiﬁcations of digital content.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.",
        "Action ID": "MS-1.1-002",
        "Suggested Action": "Integrate tools designed to analyze content provenance and detect data anomalies, verify the authenticity of digital signatures, and identify patterns associated with misinformation or manipulation.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.",
        "Action ID": "MS-1.1-003",
        "Suggested Action": "Disaggregate evaluation metrics by demographic factors to identify any discrepancies in how content provenance mechanisms work across diverse populations.",
        "GAI Risks": "Information Integrity; Harmful\nBias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.",
        "Action ID": "MS-1.1-004",
        "Suggested Action": "Develop a suite of metrics to evaluate structured public feedback exercises informed by representative AI Actors.",
        "GAI Risks": "Human-AI Conﬁguration; Harmful Bias and Homogenization; CBRN Information or Capabilities",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.",
        "Action ID": "MS-1.1-005",
        "Suggested Action": "Evaluate novel methods and technologies for the measurement of GAI-related risks including in content provenance, oﬀensive cyber, and CBRN, while maintaining the models’ ability to produce valid, reliable, and factually accurate outputs.",
        "GAI Risks": "Information Integrity; CBRN Information or Capabilities; Obscene, Degrading, and/or Abusive Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.",
        "Action ID": "MS-1.1-006",
        "Suggested Action": "Implement continuous monitoring of GAI system impacts to identify whether GAI outputs are equitable across various sub-populations. Seek active and direct feedback from aﬀected communities via structured feedback mechanisms or red- teaming to monitor and improve outputs.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.",
        "Action ID": "MS-1.1-007",
        "Suggested Action": "Evaluate the quality and integrity of data used in training and the provenance of AI-generated content, for example by employing techniques like chaos engineering and seeking stakeholder feedback.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.",
        "Action ID": "MS-1.1-008",
        "Suggested Action": "Deﬁne use cases, contexts of use, capabilities, and negative impacts where structured human feedback exercises, e.g., GAI red-teaming, would be most beneﬁcial for GAI risk measurement and management based on the context of use.",
        "GAI Risks": "Harmful Bias and Homogenization; CBRN Information or Capabilities",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most signiﬁcant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.",
        "Action ID": "MS-1.1-009",
        "Suggested Action": "Track and document risks or opportunities related to all GAI risks that cannot be measured quantitatively, including explanations as to why some risks cannot be measured (e.g., due to technological limitations, resource constraints, or trustworthy considerations). Include unmeasured risks in marginal risks.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts, users, AI Actors external to the team that developed or deployed the AI system, and aﬀected communities are consulted in support of assessments as necessary per organizational risk tolerance.",
        "Action ID": "MS-1.3-001",
        "Suggested Action": "Deﬁne relevant groups of interest (e.g., demographic groups, subject matter experts, experience with GAI technology) within the context of use as part of plans for gathering structured public feedback.",
        "GAI Risks": "Human-AI Conﬁguration; Harmful Bias and Homogenization; CBRN Information or Capabilities",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts,\nEnd-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts, users, AI Actors external to the team that developed or deployed the AI system, and aﬀected communities are consulted in support of assessments as necessary per organizational risk tolerance.",
        "Action ID": "MS-1.3-002",
        "Suggested Action": "Engage in internal and external evaluations, GAI red-teaming, impact assessments, or other structured human feedback exercises in consultation with representative AI Actors with expertise and familiarity in the context of use, and/or who are representative of the populations associated with the context of use.",
        "GAI Risks": "Human-AI Conﬁguration; Harmful Bias and Homogenization; CBRN Information or Capabilities",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts,\nEnd-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts, users, AI Actors external to the team that developed or deployed the AI system, and aﬀected communities are consulted in support of assessments as necessary per organizational risk tolerance.",
        "Action ID": "MS-1.3-003",
        "Suggested Action": "Verify those conducting structured human feedback exercises are not directly involved in system development tasks for the same GAI model.",
        "GAI Risks": "Human-AI Conﬁguration; Data Privacy",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Development, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts,\nEnd-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.10: Privacy risk of the AI system – as identiﬁed in the MAP function – is examined and documented.",
        "Action ID": "MS-2.10-001",
        "Suggested Action": "Conduct AI red-teaming to assess issues such as: Outputting of training data samples, and subsequent reverse engineering, model extraction, and membership inference risks; Revealing biometric, conﬁdential, copyrighted, licensed, patented, personal, proprietary, sensitive, or trade-marked information; Tracking or revealing location information of users or members of training datasets.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity; Intellectual Property",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.10: Privacy risk of the AI system – as identiﬁed in the MAP function – is examined and documented.",
        "Action ID": "MS-2.10-002",
        "Suggested Action": "Engage directly with end-users and other stakeholders to understand their expectations and concerns regarding content provenance. Use this feedback to guide the design of provenance data-tracking techniques.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.10: Privacy risk of the AI system – as identiﬁed in the MAP function – is examined and documented.",
        "Action ID": "MS-2.10-003",
        "Suggested Action": "Verify deduplication of GAI training data samples, particularly regarding synthetic\ndata.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.",
        "Action ID": "MS-2.11-001",
        "Suggested Action": "Apply use-case appropriate benchmarks (e.g., Bias Benchmark Questions, Real Hateful or Harmful Prompts, Winogender Schemas15) to quantify systemic bias, stereotyping, denigration, and hateful content in GAI system outputs; Document assumptions and limitations of benchmarks, including any actual or possible training/test data cross contamination, relative to in-context deployment environment.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.",
        "Action ID": "MS-2.11-002",
        "Suggested Action": "Conduct fairness assessments to measure systemic bias. Measure GAI system performance across demographic groups and subgroups, addressing both quality of service and any allocation of services and resources. Quantify harms using: ﬁeld testing with sub-group populations to determine likelihood of exposure to generated content exhibiting harmful bias, AI red-teaming with counterfactual and low-context (e.g., “leader,” “bad guys”) prompts. For ML pipelines or business processes with categorical or numeric outcomes that rely on GAI, apply general fairness metrics (e.g., demographic parity, equalized odds, equal opportunity, statistical hypothesis tests), to the pipeline or business outcome where appropriate; Custom, context-speciﬁc metrics developed in collaboration with domain experts and aﬀected communities; Measurements of the prevalence of denigration in generated content in deployment (e.g., sub- sampling a fraction of traﬃc and manually annotating denigrating content).",
        "GAI Risks": "Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.",
        "Action ID": "MS-2.11-003",
        "Suggested Action": "Identify the classes of individuals, groups, or environmental ecosystems which might be impacted by GAI systems through direct engagement with potentially impacted communities.",
        "GAI Risks": "Environmental; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.",
        "Action ID": "MS-2.11-004",
        "Suggested Action": "Review, document, and measure sources of bias in GAI training and TEVV data: Diﬀerences in distributions of outcomes across and within groups, including intersecting groups; Completeness, representativeness, and balance of data sources; demographic group and subgroup coverage in GAI system training data; Forms of latent systemic bias in images, text, audio, embeddings, or other complex or unstructured data; Input data features that may serve as proxies for demographic group membership (i.e., image metadata, language dialect) or otherwise give rise to emergent bias within GAI systems; The extent to which the digital divide may negatively impact representativeness in GAI system training and TEVV data; Filtering of hate speech or content in GAI system training data; Prevalence of GAI-generated data in GAI system training data.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.11: Fairness and bias – as identiﬁed in the MAP function – are evaluated and results are documented.",
        "Action ID": "MS-2.11-005",
        "Suggested Action": "Assess the proportion of synthetic to non-synthetic training data and verify training data is not overly homogenous or GAI-produced to mitigate concerns of model collapse.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Aﬀected Individuals and Communities, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.12: Environmental impact and sustainability of AI model training and management activities – as identiﬁed in the MAP function – are assessed and documented.",
        "Action ID": "MS-2.12-001",
        "Suggested Action": "Assess safety to physical environments when deploying GAI systems.",
        "GAI Risks": "Dangerous, Violent, or Hateful\nContent",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.12: Environmental impact and sustainability of AI model training and management activities – as identiﬁed in the MAP function – are assessed and documented.",
        "Action ID": "MS-2.12-002",
        "Suggested Action": "Document anticipated environmental impacts of model development, maintenance, and deployment in product design decisions.",
        "GAI Risks": "Environmental",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.12: Environmental impact and sustainability of AI model training and management activities – as identiﬁed in the MAP function – are assessed and documented.",
        "Action ID": "MS-2.12-003",
        "Suggested Action": "Measure or estimate environmental impacts (e.g., energy and water consumption) for training, ﬁne tuning, and deploying models: Verify tradeoﬀs between resources used at inference time versus additional resources required at training time.",
        "GAI Risks": "Environmental",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.12: Environmental impact and sustainability of AI model training and management activities – as identiﬁed in the MAP function – are assessed and documented.",
        "Action ID": "MS-2.12-004",
        "Suggested Action": "Verify eﬀectiveness of carbon capture or oﬀset programs for GAI training and\napplications, and address green-washing concerns.",
        "GAI Risks": "Environmental",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.13: Eﬀectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and documented.",
        "Action ID": "MS-2.13-001",
        "Suggested Action": "Create measurement error models for pre-deployment metrics to demonstrate construct validity for each metric (i.e., does the metric eﬀectively operationalize the desired concept): Measure or estimate, and document, biases or statistical variance in applied metrics or structured human feedback processes; Leverage domain expertise when modeling complex societal constructs such as hateful content.",
        "GAI Risks": "Confabulation; Information Integrity; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.",
        "Action ID": "MS-2.2-001",
        "Suggested Action": "Assess and manage statistical biases related to GAI content provenance through\ntechniques such as re-sampling, re-weighting, or adversarial training.",
        "GAI Risks": "Information Integrity; Information Security; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Human Factors, TEVV"
    },
    {
        "Section": "MEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.",
        "Action ID": "MS-2.2-002",
        "Suggested Action": "Document how content provenance data is tracked and how that data interacts with privacy and security. Consider: Anonymizing data to protect the privacy of human subjects; Leveraging privacy output ﬁlters; Removing any personally identiﬁable information (PII) to prevent potential harm or misuse.",
        "GAI Risks": "Data Privacy; Human AI Conﬁguration; Information Integrity; Information Security; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Human Factors, TEVV"
    },
    {
        "Section": "MEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.",
        "Action ID": "MS-2.2-003",
        "Suggested Action": "Provide human subjects with options to withdraw participation or revoke their\nconsent for present or future use of their data in GAI applications.",
        "GAI Risks": "Data Privacy; Human-AI Conﬁguration; Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Human Factors, TEVV"
    },
    {
        "Section": "MEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.",
        "Action ID": "MS-2.2-004",
        "Suggested Action": "Use techniques such as anonymization, diﬀerential privacy or other privacy- enhancing technologies to minimize the risks associated with linking AI-generated content back to individual human subjects.",
        "GAI Risks": "Data Privacy; Human-AI\nConﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Development, Human Factors, TEVV"
    },
    {
        "Section": "MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.",
        "Action ID": "MS-2.3-001",
        "Suggested Action": "Consider baseline model performance on suites of benchmarks when selecting a model for ﬁne tuning or enhancement with retrieval-augmented generation.",
        "GAI Risks": "Information Security; Confabulation",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, TEVV"
    },
    {
        "Section": "MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.",
        "Action ID": "MS-2.3-002",
        "Suggested Action": "Evaluate claims of model capabilities using empirically validated methods.",
        "GAI Risks": "Confabulation; Information\nSecurity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, TEVV"
    },
    {
        "Section": "MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.",
        "Action ID": "MS-2.3-003",
        "Suggested Action": "Share results of pre-deployment testing with relevant GAI Actors, such as those with system release approval authority.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, TEVV"
    },
    {
        "Section": "MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.",
        "Action ID": "MS-2.3-004",
        "Suggested Action": "Utilize a purpose-built testing environment such as NIST Dioptra to empirically evaluate GAI trustworthy characteristics.",
        "GAI Risks": "CBRN Information or Capabilities; Data Privacy; Confabulation; Information Integrity; Information Security; Dangerous, Violent, or Hateful Content; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, TEVV"
    },
    {
        "Section": "MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.",
        "Action ID": "MS-2.5-001",
        "Suggested Action": "Avoid extrapolating GAI system performance or capabilities from narrow, non- systematic, and anecdotal assessments.",
        "GAI Risks": "Human-AI Conﬁguration; Confabulation",
        "AI Actor Tasks": "AI Actor Tasks: Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.",
        "Action ID": "MS-2.5-002",
        "Suggested Action": "Document the extent to which human domain knowledge is employed to improve GAI system performance, via, e.g., RLHF, ﬁne-tuning, retrieval- augmented generation, content moderation, business rules.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.",
        "Action ID": "MS-2.5-003",
        "Suggested Action": "Review and verify sources and citations in GAI system outputs during pre- deployment risk measurement and ongoing monitoring activities.",
        "GAI Risks": "Confabulation",
        "AI Actor Tasks": "AI Actor Tasks: Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.",
        "Action ID": "MS-2.5-004",
        "Suggested Action": "Track and document instances of anthropomorphization (e.g., human images, mentions of human feelings, cyborg imagery or motifs) in GAI system interfaces.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.",
        "Action ID": "MS-2.5-005",
        "Suggested Action": "Verify GAI system training data and TEVV data provenance, and that ﬁne-tuning or retrieval-augmented generation data is grounded.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.",
        "Action ID": "MS-2.5-006",
        "Suggested Action": "Regularly review security and safety guardrails, especially if the GAI system is being operated in novel circumstances. This includes reviewing reasons why the GAI system was initially assessed as being safe to deploy.",
        "GAI Risks": "Information Security; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: Domain Experts, TEVV"
    },
    {
        "Section": "MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",
        "Action ID": "MS-2.6-001",
        "Suggested Action": "Assess adverse impacts, including health and wellbeing impacts for value chain or other AI Actors that are exposed to sexually explicit, oﬀensive, or violent information during GAI training and maintenance.",
        "GAI Risks": "Human-AI Conﬁguration; Obscene, Degrading, and/or Abusive Content; Value Chain and Component Integration; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",
        "Action ID": "MS-2.6-002",
        "Suggested Action": "Assess existence or levels of harmful bias, intellectual property infringement, data privacy violations, obscenity, extremism, violence, or CBRN information in system training data.",
        "GAI Risks": "Data Privacy; Intellectual Property; Obscene, Degrading, and/or Abusive Content; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content; CBRN Information or Capabilities",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",
        "Action ID": "MS-2.6-003",
        "Suggested Action": "Re-evaluate safety features of ﬁne-tuned models when the negative risk exceeds organizational risk tolerance.",
        "GAI Risks": "Dangerous, Violent, or Hateful\nContent",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",
        "Action ID": "MS-2.6-004",
        "Suggested Action": "Review GAI system outputs for validity and safety: Review generated code to assess risks that may arise from unreliable downstream decision-making.",
        "GAI Risks": "Value Chain and Component Integration; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",
        "Action ID": "MS-2.6-005",
        "Suggested Action": "Verify that GAI system architecture can monitor outputs and performance, and handle, recover from, and repair errors when security anomalies, threats and impacts are detected.",
        "GAI Risks": "Confabulation; Information\nIntegrity; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",
        "Action ID": "MS-2.6-006",
        "Suggested Action": "Verify that systems properly handle queries that may give rise to inappropriate, malicious, or illegal usage, including facilitating manipulation, extortion, targeted impersonation, cyber-attacks, and weapons creation.",
        "GAI Risks": "CBRN Information or Capabilities; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identiﬁed in the MAP function. The AI system to be  deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reﬂect system reliability and robustness, real-time monitoring, and response times for AI system failures.",
        "Action ID": "MS-2.6-007",
        "Suggested Action": "Regularly evaluate GAI system vulnerabilities to possible circumvention of safety measures.",
        "GAI Risks": "CBRN Information or Capabilities; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.",
        "Action ID": "MS-2.7-001",
        "Suggested Action": "Apply established security measures to: Assess likelihood and magnitude of vulnerabilities and threats such as backdoors, compromised dependencies, data breaches, eavesdropping, man-in-the-middle attacks, reverse engineering, autonomous agents, model theft or exposure of model weights, AI inference, bypass, extraction, and other baseline security concerns.",
        "GAI Risks": "Data Privacy; Information Integrity; Information Security; Value Chain and Component Integration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.",
        "Action ID": "MS-2.7-002",
        "Suggested Action": "Benchmark GAI system security and resilience related to content provenance against industry standards and best practices. Compare GAI system security features and content provenance methods against industry state-of-the-art.",
        "GAI Risks": "Information Integrity; Information\nSecurity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.",
        "Action ID": "MS-2.7-003",
        "Suggested Action": "Conduct user surveys to gather user satisfaction with the AI-generated content and user perceptions of content authenticity. Analyze user feedback to identify concerns and/or current literacy levels related to content provenance and understanding of labels on content.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.",
        "Action ID": "MS-2.7-004",
        "Suggested Action": "Identify metrics that reﬂect the eﬀectiveness of security measures, such as data provenance, the number of unauthorized access attempts, inference, bypass, extraction, penetrations, or provenance veriﬁcation.",
        "GAI Risks": "Information Integrity; Information\nSecurity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.",
        "Action ID": "MS-2.7-005",
        "Suggested Action": "Measure reliability of content authentication methods, such as watermarking, cryptographic signatures, digital ﬁngerprints, as well as access controls, conformity assessment, and model integrity veriﬁcation, which can help support the eﬀective implementation of content provenance techniques. Evaluate the rate of false positives and false negatives in content provenance, as well as true positives and true negatives for veriﬁcation.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.",
        "Action ID": "MS-2.7-006",
        "Suggested Action": "Measure the rate at which recommendations from security checks and incidents are implemented. Assess how quickly the AI system can adapt and improve based on lessons learned from security incidents and feedback.",
        "GAI Risks": "Information Integrity; Information\nSecurity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.",
        "Action ID": "MS-2.7-007",
        "Suggested Action": "Perform AI red-teaming to assess resilience against: Abuse to facilitate attacks on other systems (e.g., malicious code generation, enhanced phishing content), GAI attacks (e.g., prompt injection), ML attacks (e.g., adversarial examples/prompts, data poisoning, membership inference, model extraction, sponge examples).",
        "GAI Risks": "Information Security; Harmful Bias and Homogenization; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.",
        "Action ID": "MS-2.7-008",
        "Suggested Action": "Verify ﬁne-tuning does not compromise safety and security controls.",
        "GAI Risks": "Information Integrity; Information Security; Dangerous, Violent, or Hateful Content",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented.",
        "Action ID": "MS-2.7-009",
        "Suggested Action": "Regularly assess and verify that security measures remain eﬀective and have not\nbeen compromised.",
        "GAI Risks": "Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.8: Risks associated with transparency and accountability – as identiﬁed in the MAP function – are examined and documented.",
        "Action ID": "MS-2.8-001",
        "Suggested Action": "Compile statistics on actual policy violations, take-down requests, and intellectual property infringement for organizational GAI systems: Analyze transparency reports across demographic groups, languages groups.",
        "GAI Risks": "Intellectual Property; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.8: Risks associated with transparency and accountability – as identiﬁed in the MAP function – are examined and documented.",
        "Action ID": "MS-2.8-002",
        "Suggested Action": "Document the instructions given to data annotators or AI red-teamers.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.8: Risks associated with transparency and accountability – as identiﬁed in the MAP function – are examined and documented.",
        "Action ID": "MS-2.8-003",
        "Suggested Action": "Use digital content transparency solutions to enable the documentation of each instance where content is generated, modiﬁed, or shared to provide a tamper- proof history of the content, promote transparency, and enable traceability.\nRobust version control systems can also be applied to track changes across the AI\nlifecycle over time.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.8: Risks associated with transparency and accountability – as identiﬁed in the MAP function – are examined and documented.",
        "Action ID": "MS-2.8-004",
        "Suggested Action": "Verify adequacy of GAI system user instructions through user testing.",
        "GAI Risks": "Human-AI Conﬁguration",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context – as identiﬁed in the MAP function – to inform responsible use and governance.",
        "Action ID": "MS-2.9-001",
        "Suggested Action": "Apply and document ML explanation results such as: Analysis of embeddings, Counterfactual prompts, Gradient-based attributions, Model compression/surrogate models, Occlusion/term reduction.",
        "GAI Risks": "Confabulation",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context – as identiﬁed in the MAP function – to inform responsible use and governance.",
        "Action ID": "MS-2.9-002",
        "Suggested Action": "Document GAI model details including: Proposed use and organizational value; Assumptions and limitations, Data collection methodologies; Data provenance; Data quality; Model architecture (e.g., convolutional neural network, transformers, etc.); Optimization objectives; Training algorithms; RLHF approaches; Fine-tuning or retrieval-augmented generation approaches; Evaluation data; Ethical considerations; Legal and regulatory requirements.",
        "GAI Risks": "Information Integrity; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 3.2: Risk tracking approaches are considered for settings where AI risks are diﬃcult to assess using currently available measurement techniques or where metrics are not yet available.",
        "Action ID": "MS-3.2-001",
        "Suggested Action": "Establish processes for identifying emergent GAI system risks including\nconsulting with external AI Actors.",
        "GAI Risks": "Human-AI Conﬁguration; Confabulation",
        "AI Actor Tasks": "AI Actor Tasks: AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.",
        "Action ID": "MS-3.3-001",
        "Suggested Action": "Conduct impact assessments on how AI-generated content might aﬀect diﬀerent social, economic, and cultural groups.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.",
        "Action ID": "MS-3.3-002",
        "Suggested Action": "Conduct studies to understand how end users perceive and interact with GAI content and accompanying content provenance within context of use. Assess whether the content aligns with their expectations and how they may act upon the information presented.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.",
        "Action ID": "MS-3.3-003",
        "Suggested Action": "Evaluate potential biases and stereotypes that could emerge from the AI- generated content using appropriate methodologies including computational testing methods as well as evaluating structured feedback input.",
        "GAI Risks": "Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.",
        "Action ID": "MS-3.3-004",
        "Suggested Action": "Provide input for training materials about the capabilities and limitations of GAI systems related to digital content transparency for AI Actors, other professionals, and the public about the societal impacts of AI and the role of diverse and inclusive content generation.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.",
        "Action ID": "MS-3.3-005",
        "Suggested Action": "Record and integrate structured feedback about content provenance from operators, users, and potentially impacted communities through the use of methods such as user research studies, focus groups, or community forums. Actively seek feedback on generated content quality and potential biases. Assess the general awareness among end users and impacted communities about the availability of these feedback channels.",
        "GAI Risks": "Human-AI Conﬁguration; Information Integrity; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Aﬀected Individuals and Communities, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.",
        "Action ID": "MS-4.2-001",
        "Suggested Action": "Conduct adversarial testing at a regular cadence to map and measure GAI risks, including tests to address attempts to deceive or manipulate the application of provenance techniques or other misuses. Identify vulnerabilities and understand potential misuse scenarios and unintended outputs.",
        "GAI Risks": "Information Integrity; Information\nSecurity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.",
        "Action ID": "MS-4.2-002",
        "Suggested Action": "Evaluate GAI system performance in real-world scenarios to observe its behavior in practical environments and reveal issues that might not surface in controlled and optimized testing environments.",
        "GAI Risks": "Human-AI Conﬁguration; Confabulation; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.",
        "Action ID": "MS-4.2-003",
        "Suggested Action": "Implement interpretability and explainability methods to evaluate GAI system decisions and verify alignment with intended purpose.",
        "GAI Risks": "Information Integrity; Harmful Bias and Homogenization",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.",
        "Action ID": "MS-4.2-004",
        "Suggested Action": "Monitor and document instances where human operators or other systems override the GAI's decisions. Evaluate these cases to understand if the overrides are linked to issues related to content provenance.",
        "GAI Risks": "Information Integrity",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    },
    {
        "Section": "MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.",
        "Action ID": "MS-4.2-005",
        "Suggested Action": "Verify and document the incorporation of results of structured public feedback exercises into design, implementation, deployment approval (“go”/“no-go” decisions), monitoring, and decommission decisions.",
        "GAI Risks": "Human-AI Conﬁguration; Information Security",
        "AI Actor Tasks": "AI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV"
    }
]