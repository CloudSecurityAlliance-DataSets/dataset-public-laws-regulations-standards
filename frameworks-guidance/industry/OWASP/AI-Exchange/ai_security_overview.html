<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><link rel="icon shortcut" href=/favicon.ico sizes=32x32><link rel=icon href=/favicon.svg type=image/svg+xml><link rel=icon href=/favicon-dark.svg type=image/svg+xml media="(prefers-color-scheme: dark)"><link rel=icon href=/favicon-16x16.png type=image/png sizes=16x16><link rel=icon href=/favicon-32x32.png type=image/png sizes=32x32><link rel=apple-touch-icon href=/apple-touch-icon.png sizes=180x180><link fetchpriority=low href=/site.webmanifest rel=manifest><title>0. AI Security Overview – AI Exchange</title><meta name=description content="Summary - How to address AI Security? See home for more information about this initiative, the OWASP AI Exchange, how to contribute or connect.
Category: discussion
Permalink: https://owaspai.org/goto/summary/
While AI offers tremendous opportunities, it also brings new risks including security threats. It is therefore imperative to approach AI applications with a clear understanding of potential threats and the controls against them. In a nutshell, the main steps to address AI security are:"><link rel=canonical href=https://owaspai.org/docs/ai_security_overview/ itemprop=url><meta property="og:title" content="0. AI Security Overview – AI Exchange"><meta property="og:description" content="Comprehensive guidance and alignment on how to protect AI against security threats - by professionals, for professionals."><meta property="og:type" content="article"><meta property="og:url" content="https://owaspai.org/docs/ai_security_overview/"><meta property="og:image" content="https://owaspai.org/images/aix-og-logo.jpg"><meta property="article:section" content="docs"><meta itemprop=name content="0. AI Security Overview"><meta itemprop=description content="Summary - How to address AI Security? See home for more information about this initiative, the OWASP AI Exchange, how to contribute or connect.
Category: discussion
Permalink: https://owaspai.org/goto/summary/
While AI offers tremendous opportunities, it also brings new risks including security threats. It is therefore imperative to approach AI applications with a clear understanding of potential threats and the controls against them. In a nutshell, the main steps to address AI security are:"><meta itemprop=wordCount content="8928"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="0. AI Security Overview"><meta name=twitter:description content="Summary - How to address AI Security? See home for more information about this initiative, the OWASP AI Exchange, how to contribute or connect.
Category: discussion
Permalink: https://owaspai.org/goto/summary/
While AI offers tremendous opportunities, it also brings new risks including security threats. It is therefore imperative to approach AI applications with a clear understanding of potential threats and the controls against them. In a nutshell, the main steps to address AI security are:"><link rel=preload href=/css/compiled/main.min.5a06ca26e024c4f511f45ee6c33a2a1faefaebe6be8a38d36e100f40a4c59c06.css as=style integrity="sha256-WgbKJuAkxPUR9F7mwzoqH6766+a+ijjTbhAPQKTFnAY="><link href=/css/compiled/main.min.5a06ca26e024c4f511f45ee6c33a2a1faefaebe6be8a38d36e100f40a4c59c06.css rel=stylesheet integrity="sha256-WgbKJuAkxPUR9F7mwzoqH6766+a+ijjTbhAPQKTFnAY="><link href=/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css rel=stylesheet integrity="sha256-47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU="><link rel=preconnect href=https://www.googletagmanager.com crossorigin><script async src="https://www.googletagmanager.com/gtag/js?id=G-QPGVTTDD3R"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QPGVTTDD3R")</script><script>const defaultTheme="system",setDarkTheme=()=>{document.documentElement.classList.add("dark"),document.documentElement.style.colorScheme="dark"},setLightTheme=()=>{document.documentElement.classList.remove("dark"),document.documentElement.style.colorScheme="light"};"color-theme"in localStorage?localStorage.getItem("color-theme")==="dark"?setDarkTheme():setLightTheme():(defaultTheme==="dark"?setDarkTheme():setLightTheme(),defaultTheme==="system"&&(window.matchMedia("(prefers-color-scheme: dark)").matches?setDarkTheme():setLightTheme()))</script></head><body dir=ltr><div class="nav-container sticky top-0 z-20 w-full bg-transparent print:hidden"><div class="nav-container-blur pointer-events-none absolute z-[-1] h-full w-full bg-white dark:bg-dark shadow-[0_2px_4px_rgba(0,0,0,.02),0_1px_0_rgba(0,0,0,.06)] contrast-more:shadow-[0_0_0_1px_#000] dark:shadow-[0_-1px_0_rgba(255,255,255,.1)_inset] contrast-more:dark:shadow-[0_0_0_1px_#fff]"></div><nav class="mx-auto flex items-center justify-end gap-2 h-16 px-6 max-w-[90rem]"><a class="flex items-center hover:opacity-75 ltr:mr-auto rtl:ml-auto" href=/><img class="block dark:hidden" src=/images/owasp-logo.svg alt="AI Exchange" height=30 width=30>
<img class="hidden dark:block" src=/images/owasp-logo-dark.svg alt="AI Exchange" height=30 width=30>
<span class="mx-2 font-extrabold inline select-none" title="AI Exchange">AI Exchange</span>
</a><a title=Home href=/ class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Home</span>
</a><a title=Overview href=/docs/ai_security_overview class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block font-medium"><span class=text-center>Overview</span>
</a><a title=Media href=/media class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Media</span>
</a><a title=Meetings href=/meetings class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Meetings</span>
</a><a title=Contribute href=/contribute class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Contribute</span>
</a><a title=Connect href=/connect class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Connect</span></a><div class="search-wrapper relative md:w-64"><div class="relative flex items-center text-gray-900 contrast-more:text-gray-800 dark:text-gray-300 contrast-more:dark:text-gray-300"><input placeholder=Search... class="search-input block w-full appearance-none rounded-lg px-3 py-2 transition-colors text-base leading-tight md:text-sm bg-black/[.05] dark:bg-gray-50/10 focus:bg-white dark:focus:bg-dark placeholder:text-gray-500 dark:placeholder:text-gray-400 contrast-more:border contrast-more:border-current" type=search spellcheck=false>
<kbd class="absolute my-1.5 select-none ltr:right-1.5 rtl:left-1.5 h-5 rounded bg-white px-1.5 font-mono text-[10px] font-medium text-gray-500 border dark:border-gray-100/20 dark:bg-dark/50 contrast-more:border-current contrast-more:text-current contrast-more:dark:border-current items-center gap-1 transition-opacity pointer-events-none hidden sm:flex">CTRL K</kbd></div><div><ul class="search-results hextra-scrollbar hidden border border-gray-200 bg-white text-gray-100 dark:border-neutral-800 dark:bg-neutral-900 absolute top-full z-20 mt-2 overflow-auto overscroll-contain rounded-xl py-2.5 shadow-xl max-h-[min(calc(50vh-11rem-env(safe-area-inset-bottom)),400px)] md:max-h-[min(calc(100vh-5rem-env(safe-area-inset-bottom)),400px)] inset-x-0 ltr:md:left-auto rtl:md:right-auto contrast-more:border contrast-more:border-gray-900 contrast-more:dark:border-gray-50 w-screen min-h-[100px] max-w-[min(calc(100vw-2rem),calc(100%+20rem))]" style="transition:max-height .2s ease 0s"></ul></div></div><a class="p-2 text-current" target=_blank rel=noreferer href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide title=GitHub><svg height="24" fill="currentcolor" viewBox="3 3 18 18"><path d="M12 3C7.0275 3 3 7.12937 3 12.2276c0 4.0833 2.57625 7.5321 6.15374 8.7548C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441 9.77249 20.3249 9.76125 19.5982 9.76125 18.8254 7.5 19.2522 6.915 18.2602 6.735 17.7412 6.63375 17.4759 6.19499 16.6569 5.8125 16.4378 5.4975 16.2647 5.0475 15.838 5.80124 15.8264 6.51 15.8149 7.01625 16.4954 7.18499 16.7723 7.99499 18.1679 9.28875 17.7758 9.80625 17.5335 9.885 16.9337 10.1212 16.53 10.38 16.2993 8.3775 16.0687 6.285 15.2728 6.285 11.7432c0-1.0035.34875-1.834.92249-2.47994C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794c0 0 .753749999999999-.24223 2.47499.94583.72001-.20762 1.48501-.31143 2.25001-.31143C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377c1.7212-1.19959 2.475-.94583 2.475-.94583C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326 17.4113 9.9092 17.76 10.7281 17.76 11.7432c0 3.5411-2.1037 4.3255-4.1063 4.5561C13.98 16.5877 14.2613 17.1414 14.2613 18.0065 14.2613 19.2407 14.25 20.2326 14.25 20.5441 14.25 20.7863 14.4188 21.0746 14.8688 20.9824 16.6554 20.364 18.2079 19.1866 19.3078 17.6162c1.0999-1.5705 1.6917-3.4551 1.6922-5.3886C21 7.12937 16.9725 3 12 3z"/></svg><span class=sr-only>GitHub</span>
</a><button type=button aria-label=Menu class="hamburger-menu -mr-2 rounded p-2 active:bg-gray-400/20 md:hidden"><svg height="24" fill="none" viewBox="0 0 24 24" stroke="currentcolor"><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 8H20"/></g><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16H20"/></g></svg></button></nav></div><div class='mx-auto flex max-w-[90rem]'><div class="mobile-menu-overlay [transition:background-color_1.5s_ease] fixed inset-0 z-10 bg-black/80 dark:bg-black/60 hidden"></div><aside class="sidebar-container flex flex-col print:hidden md:top-16 md:shrink-0 md:w-64 md:self-start max-md:[transform:translate3d(0,-100%,0)] md:sticky"><div class="px-4 pt-4 md:hidden"><div class="search-wrapper relative md:w-64"><div class="relative flex items-center text-gray-900 contrast-more:text-gray-800 dark:text-gray-300 contrast-more:dark:text-gray-300"><input placeholder=Search... class="search-input block w-full appearance-none rounded-lg px-3 py-2 transition-colors text-base leading-tight md:text-sm bg-black/[.05] dark:bg-gray-50/10 focus:bg-white dark:focus:bg-dark placeholder:text-gray-500 dark:placeholder:text-gray-400 contrast-more:border contrast-more:border-current" type=search spellcheck=false>
<kbd class="absolute my-1.5 select-none ltr:right-1.5 rtl:left-1.5 h-5 rounded bg-white px-1.5 font-mono text-[10px] font-medium text-gray-500 border dark:border-gray-100/20 dark:bg-dark/50 contrast-more:border-current contrast-more:text-current contrast-more:dark:border-current items-center gap-1 transition-opacity pointer-events-none hidden sm:flex">CTRL K</kbd></div><div><ul class="search-results hextra-scrollbar hidden border border-gray-200 bg-white text-gray-100 dark:border-neutral-800 dark:bg-neutral-900 absolute top-full z-20 mt-2 overflow-auto overscroll-contain rounded-xl py-2.5 shadow-xl max-h-[min(calc(50vh-11rem-env(safe-area-inset-bottom)),400px)] md:max-h-[min(calc(100vh-5rem-env(safe-area-inset-bottom)),400px)] inset-x-0 ltr:md:left-auto rtl:md:right-auto contrast-more:border contrast-more:border-gray-900 contrast-more:dark:border-gray-50 w-screen min-h-[100px] max-w-[min(calc(100vw-2rem),calc(100%+20rem))]" style="transition:max-height .2s ease 0s"></ul></div></div></div><div class="hextra-scrollbar overflow-y-auto overflow-x-hidden p-4 grow md:h-[calc(100vh-var(--navbar-height)-var(--menu-height))]"><ul class="flex flex-col gap-1 md:hidden"><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/meetings/></a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/charter/>AI Exchange Charter</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/connect/>Connect with us</a></li><li class=open><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/>Content
<span class=hextra-sidebar-collapsible-button><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class='relative flex flex-col gap-1 before:absolute before:inset-y-1 before:w-px before:bg-gray-200 before:content-[""] ltr:ml-3 ltr:pl-3 ltr:before:left-0 rtl:mr-3 rtl:pr-3 rtl:before:right-0 dark:before:bg-neutral-800'><li class="flex flex-col open"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
sidebar-active-item bg-primary-100 font-semibold text-primary-800 contrast-more:border contrast-more:border-primary-500 dark:bg-primary-400/10 dark:text-primary-600 contrast-more:dark:border-primary-500" href=/docs/ai_security_overview/>0. AI Security Overview</a><ul class='flex flex-col gap-1 relative before:absolute before:inset-y-1 before:w-px before:bg-gray-200 before:content-[""] dark:before:bg-neutral-800 ltr:pl-3 ltr:before:left-0 rtl:pr-3 rtl:before:right-0 ltr:ml-3 rtl:mr-3'><li><a href=#summary---how-to-address-ai-security class="flex rounded px-2 py-1.5 text-sm transition-colors [word-break:break-word] cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:border gap-2 before:opacity-25 before:content-['#'] text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:text-gray-900 contrast-more:dark:text-gray-50 contrast-more:border-transparent contrast-more:hover:border-gray-900 contrast-more:dark:hover:border-gray-50">Summary - How to address AI Security?</a></li><li><a href=#about-this-document class="flex rounded px-2 py-1.5 text-sm transition-colors [word-break:break-word] cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:border gap-2 before:opacity-25 before:content-['#'] text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:text-gray-900 contrast-more:dark:text-gray-50 contrast-more:border-transparent contrast-more:hover:border-gray-900 contrast-more:dark:hover:border-gray-50">About this Document</a></li><li><a href=#threats-overview class="flex rounded px-2 py-1.5 text-sm transition-colors [word-break:break-word] cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:border gap-2 before:opacity-25 before:content-['#'] text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:text-gray-900 contrast-more:dark:text-gray-50 contrast-more:border-transparent contrast-more:hover:border-gray-900 contrast-more:dark:hover:border-gray-50">Threats overview</a></li><li><a href=#controls-overview class="flex rounded px-2 py-1.5 text-sm transition-colors [word-break:break-word] cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:border gap-2 before:opacity-25 before:content-['#'] text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:text-gray-900 contrast-more:dark:text-gray-50 contrast-more:border-transparent contrast-more:hover:border-gray-900 contrast-more:dark:hover:border-gray-50">Controls overview</a></li><li><a href=#how-to-select-relevant-threats-and-controls-risk-analysis class="flex rounded px-2 py-1.5 text-sm transition-colors [word-break:break-word] cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:border gap-2 before:opacity-25 before:content-['#'] text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:text-gray-900 contrast-more:dark:text-gray-50 contrast-more:border-transparent contrast-more:hover:border-gray-900 contrast-more:dark:hover:border-gray-50">How to select relevant threats and controls? risk analysis</a></li><li><a href=#how-about- class="flex rounded px-2 py-1.5 text-sm transition-colors [word-break:break-word] cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:border gap-2 before:opacity-25 before:content-['#'] text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:text-gray-900 contrast-more:dark:text-gray-50 contrast-more:border-transparent contrast-more:hover:border-gray-900 contrast-more:dark:hover:border-gray-50">How about &amp;hellip;</a></li></ul></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/1_general_controls/>1. General controls</a></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/2_threats_through_use/>2. Threats through use</a></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/3_development_time_threats/>3. Development-time threats</a></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/4_runtime_application_security_threats/>4. Runtime application security threats</a></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/5_testing/>5. AI security testing</a></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/ai_security_references/>AI Security References</a></li></ul></div></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/contribute/>Contribute to the OWASP AI Exchange</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/media/>Media</a></li><li class="[word-break:break-word] mt-5 mb-2 px-2 py-1.5 text-sm font-semibold text-gray-900 first:mt-0 dark:text-gray-100"><span class=cursor-default>More</span></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/>Home</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/connect/>Connect with us</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/contribute/>Contribute</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/media/>Media</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/meetings/>Meetings</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=https://forms.gle/XwEEK52y4iZQChuJ6 target=_blank rel=noreferer>Register</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide/raw/main/assets/images/owaspaioverviewpdfv3.pdf target=_blank rel=noreferer>Navigator</a></li></ul><ul class="flex flex-col gap-1 max-md:hidden"><li class=open><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
sidebar-active-item bg-primary-100 font-semibold text-primary-800 contrast-more:border contrast-more:border-primary-500 dark:bg-primary-400/10 dark:text-primary-600 contrast-more:dark:border-primary-500" href=/docs/ai_security_overview/>0. AI Security Overview</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/1_general_controls/>1. General controls</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/2_threats_through_use/>2. Threats through use</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/3_development_time_threats/>3. Development-time threats</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/4_runtime_application_security_threats/>4. Runtime application security threats</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/5_testing/>5. AI security testing</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/ai_security_references/>AI Security References</a></li><li class="[word-break:break-word] mt-5 mb-2 px-2 py-1.5 text-sm font-semibold text-gray-900 first:mt-0 dark:text-gray-100"><span class=cursor-default>More</span></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/>Home</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/connect/>Connect with us</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/contribute/>Contribute</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/media/>Media</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/meetings/>Meetings</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=https://forms.gle/XwEEK52y4iZQChuJ6 target=_blank rel=noreferer>Register</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide/raw/main/assets/images/owaspaioverviewpdfv3.pdf target=_blank rel=noreferer>Navigator</a></li></ul></div><div class="sticky bottom-0 bg-white dark:bg-dark mx-4 py-4 shadow-[0_-12px_16px_#fff] flex items-center gap-2 dark:border-neutral-800 dark:shadow-[0_-12px_16px_#111] contrast-more:border-neutral-400 contrast-more:shadow-none contrast-more:dark:shadow-none border-t" data-toggle-animation=show><div class="flex grow flex-col"><button title="Change theme" data-theme=light class="theme-toggle group h-7 rounded-md px-2 text-left text-xs font-medium text-gray-600 transition-colors dark:text-gray-400 hover:bg-gray-100 hover:text-gray-900 dark:hover:bg-primary-100/5 dark:hover:text-gray-50" type=button aria-label="Change theme"><div class="flex items-center gap-2 capitalize"><svg height="12" class="group-data-[theme=light]:hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span class="group-data-[theme=light]:hidden">Light</span><svg height="12" class="group-data-[theme=dark]:hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg><span class="group-data-[theme=dark]:hidden">Dark</span></div></button></div></div></aside><nav class="hextra-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents"><div class="hextra-scrollbar sticky top-16 overflow-y-auto pr-4 pt-6 text-sm [hyphens:auto] max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] ltr:-mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">On this page</p><ul><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#summary---how-to-address-ai-security>Summary - How to address AI Security?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#about-this-document>About this Document</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#threats-overview>Threats overview</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#threat-model>Threat model</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#ai-security-matrix>AI Security Matrix</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#controls-overview>Controls overview</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#threat-model-with-controls---general>Threat model with controls - general</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#threat-model-with-controls---genai-trainedfine-tuned>Threat model with controls - GenAI trained/fine tuned</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#threat-model-with-controls---genai-as-is>Threat model with controls - GenAI as-is</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#periodic-table-of-ai-security>Periodic table of AI security</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#navigator-diagram>Navigator diagram</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#how-to-select-relevant-threats-and-controls-risk-analysis>How to select relevant threats and controls? risk analysis</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#1-identifying--risks>1. Identifying Risks</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#2-evaluating-risks-by-estimating-likelihood-and-impact>2. Evaluating Risks by Estimating Likelihood and Impact</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#3-risk-treatment>3. Risk Treatment</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#4-risk-communication--monitoring>4. Risk Communication & Monitoring</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#5-arrange-responsibility>5. Arrange responsibility</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#6-verify-external-responsibilities>6. Verify external responsibilities</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#7-select-controls>7. Select controls</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#8-residual-risk-acceptance>8. Residual risk acceptance</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#9-further-management-of-the-selected-controls>9. Further management of the selected controls</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#10-continuous-risk-assessment>10. Continuous risk assessment</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#how-about->How about …</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#how-about-ai-outside-of-machine-learning>How about AI outside of machine learning?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#how-about-responsible-or-trustworthy-ai>How about responsible or trustworthy AI?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#how-about-privacy>How about privacy?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#how-about-generative-ai-eg-llm>How about Generative AI (e.g. LLM)?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#how-about-the-ncsccisa-guidelines>How about the NCSC/CISA guidelines?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#how-about-copyright>How about copyright?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#introduction>Introduction</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#ai--copyright-security>AI & Copyright Security</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#lawsuits-related-to-ai--copyright>Lawsuits Related to AI & Copyright</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#copyright-of-ai-generated-source-code>Copyright of AI-generated source code</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#copyright-damages-indemnification>Copyright damages indemnification</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#do-generative-ai-models-really-copy-existing-work>Do generative AI models really copy existing work?</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#mitigating-risk>Mitigating Risk</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#helpful-resources-regarding-ai-and-copyright>Helpful resources regarding AI and copyright:</a></li></ul><div class="mt-8 border-t bg-white pt-8 shadow-[0_-12px_16px_white] dark:bg-dark dark:shadow-[0_-12px_16px_#111] sticky bottom-0 flex flex-col items-start gap-2 pb-8 dark:border-neutral-800 contrast-more:border-t contrast-more:border-neutral-400 contrast-more:shadow-none contrast-more:dark:border-neutral-400"><a class="text-xs font-medium text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-100 contrast-more:text-gray-800 contrast-more:dark:text-gray-50" href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide/blob/main/content/ai_exchange/content/docs/ai_security_overview.md target=_blank rel=noreferer>Edit this page on GitHub →</a>
<button aria-hidden=true id=backToTop onclick=scrollUp() class="transition-all transition duration-75 opacity-0 text-xs font-medium text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-100 contrast-more:text-gray-800 contrast-more:dark:text-gray-50">
<span>Scroll to top</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" class="inline ml-1 h-3.5 w-3.5 border rounded-full border-gray-500 hover:border-gray-900 dark:border-gray-400 dark:hover:border-gray-100 contrast-more:border-gray-800 contrast-more:dark:border-gray-50"><path stroke-linecap="round" stroke-linejoin="round" d="M4.5 15.75l7.5-7.5 7.5 7.5"/></svg></button></div></div></nav><article class="w-full break-words flex min-h-[calc(100vh-var(--navbar-height))] min-w-0 justify-center pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12"><div class="mt-1.5 flex items-center gap-1 overflow-hidden text-sm text-gray-500 dark:text-gray-400 contrast-more:text-current"><div class="whitespace-nowrap transition-colors min-w-[24px] overflow-hidden text-ellipsis hover:text-gray-900 dark:hover:text-gray-100"><a href=https://owaspai.org/docs/>Content</a></div><svg class="w-3.5 shrink-0" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/></svg><div class="whitespace-nowrap transition-colors font-medium text-gray-700 contrast-more:font-bold contrast-more:text-current dark:text-gray-100 contrast-more:dark:text-current">0. AI Security Overview</div></div><div class=content><h1>0. AI Security Overview</h1><h2>Summary - How to address AI Security?<span class="absolute -mt-20" id=summary---how-to-address-ai-security></span>
<a href=#summary---how-to-address-ai-security class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>See <a href=https://owaspai.org/ target=_blank rel=noopener>home</a> for more information about this initiative, the OWASP AI Exchange, how to contribute or connect.<br>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/summary/ target=_blank rel=noopener>https://owaspai.org/goto/summary/</a></p></blockquote><p>While AI offers tremendous opportunities, it also brings new risks including security threats. It is therefore imperative to approach AI applications with a clear understanding of potential threats and the controls against them. In a nutshell, the main steps to address AI security are:</p><ul><li>Implement <strong>AI governance</strong>.</li><li><strong>Extend your security practices</strong> with the AI security assets, threats and controls from this document.</li><li>If you develop AI systems (even if you don&rsquo;t train your own models):<ul><li>Involve your data and AI engineering into your traditional <strong>(secure) software development practices</strong>.</li><li>Apply appropriate process <strong>controls</strong> and technical controls through understanding of the threats as discussed in this document.</li></ul></li><li>Make sure your AI <strong>suppliers</strong> applied the appropriate controls.</li><li><strong>Limit the impact</strong> of AI by minimizing data and privileges, and by adding oversight, e.g. guardrails, human oversight.</li></ul><p>Note that an AI system can for example be a Large Language Model, a linear regression function, a rule-based system,or a lookup table based on statistics. Throughout this document it is made clear when which threats and controls play a role.</p><hr><h2>About this Document<span class="absolute -mt-20" id=about-this-document></span>
<a href=#about-this-document class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/about/ target=_blank rel=noopener>https://owaspai.org/goto/about/</a></p></blockquote><p>This page contains an overview of AI security and the next pages provide the main content about security threats to AI and controls against them, organized by attack surface:</p><ol><li><a href=/goto/generalcontrols/>General controls, such as AI governance</a></li><li><a href=/goto/threatsuse/>Threats through use, such as Evasion attacks</a></li><li><a href=/goto/developmenttime/>Development-time threats, such as data poisoning</a></li><li><a href=/goto/runtimeappsec/>Runtime security threats, such as insecure output</a></li></ol><p>You can navigate through pages at the bottom of every page, or in the left sidebar. The right sidebar shows the different sections on a page. On small screens you can navigate through the menu.</p><p>Security here means preventing unauthorized access, use, disclosure, disruption, modification, or destruction. Modification includes manipulating the behaviour of an AI model in unwanted ways.</p><p>The AI Exchange initiative was taken by OWASP, triggered by <a href=https://www.linkedin.com/in/robvanderveer/ target=_blank rel=noopener>Rob van der Veer</a> - bridge builder for security standards, senior director at <a href=https://www.softwareimprovementgroup.com target=_blank rel=noopener>Software Improvement Group</a>, with 31 years of experience in AI & security, lead author of ISO/IEC 5338 on AI lifecycle, founding father of OpenCRE, and currently working on security requirements concerning the EU AI act in CEN/CENELEC.</p><p>This material is evolving constantly through open source continuous delivery. The authors group consists of 50 experts (researchers, practitioners, vendors, data scientists, etc.) and other people in the community are welcome to provide input too. See the <a href=/contribute>contribute page</a>.
It serves as input to ongoing key initiatives such as the EU AI act, ISO/IEC 27090 on AI security, ISO/IEC 27091 on AI privacy, the <a href=https://mltop10.info/ target=_blank rel=noopener>OWASP ML top 10</a>, <a href=https://llmtop10.com/ target=_blank rel=noopener>OWASP LLM top 10</a>, and many more initiatives can benefit from consistent terminology and insights across the globe.</p><p>This page will continue about:</p><ul><li>Threats high-over</li><li>Various overviews of threats and controls: the matrix, the periodic table, and the navigator</li><li>Risk analysis to select relevant threats and controls</li><li>Discussion (how about &mldr;) of various topics: heuristic systems, responsible AI, privacy, generative AI, the NCSC/CISA guidelines,and copyright</li></ul><hr><h2>Threats overview<span class="absolute -mt-20" id=threats-overview></span>
<a href=#threats-overview class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/threatsoverview/ target=_blank rel=noopener>https://owaspai.org/goto/threatsoverview/</a></p></blockquote><h3>Threat model<span class="absolute -mt-20" id=threat-model></span>
<a href=#threat-model class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>We distinguish three types of threats:</p><ol><li>during development-time (when data is obtained and prepared, and the model is trained/obtained),</li><li>through using the model (providing input and reading the output), and</li><li>by attacking the system during runtime (in production).</li></ol><p>In AI we distinguish 6 types of impacts, for three types of attacker goals (disclose, deceive and disrupt):</p><ol><li>disclose: hurt confidentiality of train/test data</li><li>disclose: hurt confidentiality of model Intellectual property (the <em>model parameters</em> or the process and data that led to them)</li><li>disclose: hurt confidentiality of input data</li><li>deceive: hurt integrity of model behaviour (the model is manipulated to behave in an unwanted way to deceive)</li><li>disrupt: hurt availability of the model (the model either doesn&rsquo;t work or behaves in an unwanted way - not to deceive but to disrupt)</li><li>confidentiality, integrity, and availability of non AI-specific assets</li></ol><p>The threats that create these impacts use different attack surfaces. For example: the confidentiality of train data can be compromised by hacking into the database during development-time, but it can also leak by a <em>membership inference attack</em> that can find out whether a certain individual was in the train data, simply by feeding that person&rsquo;s data into the model and looking at the details of the model output.</p><p>The diagram shows the threats as arrows. Each threat has a specific impact, indicated by letters referring to the Impact legend. The control overview section contains this diagram with groups of controls added.
<a href=/images/threats.png><img src=/images/threats.png alt loading=lazy></a></p><h3>AI Security Matrix<span class="absolute -mt-20" id=ai-security-matrix></span>
<a href=#ai-security-matrix class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/aisecuritymatrix/ target=_blank rel=noopener>https://owaspai.org/goto/aisecuritymatrix/</a></p></blockquote><p>The AI security matrix below (click to enlarge) shows all threats and risks, ordered by type and impact.
<a href=/images/OwaspAIsecuritymatix.png><img src=/images/OwaspAIsecuritymatix.png alt loading=lazy></a></p><hr><h2>Controls overview<span class="absolute -mt-20" id=controls-overview></span>
<a href=#controls-overview class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/controlsoverview/ target=_blank rel=noopener>https://owaspai.org/goto/controlsoverview/</a></p></blockquote><h3>Threat model with controls - general<span class="absolute -mt-20" id=threat-model-with-controls---general></span>
<a href=#threat-model-with-controls---general class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>The below diagram puts the controls in the AI Exchange into groups and places these groups in the right lifecycle with the corresponding threats.
<a href=/images/threatscontrols.png><img src=/images/threatscontrols.png alt loading=lazy></a>
The groups of controls form a summary of how to address AI security (controls are in capitals):</p><ol><li><strong>AI Governance</strong>: implement governance processes for AI risk, and include AI into your processes for information security and software lifecycle:<blockquote><p>( <a href=/goto/aiprogram/>AIPROGRAM</a>, <a href=/goto/secprogram/>SECPROGRAM</a>, <a href=/goto/devprogram/>DEVPROGRAM</a>, <a href=/goto/secdevprogram/>SECDEVPROGRAM</a>, <a href=/goto/checkcompliance/>CHECKCOMPLIANCE</a>, <a href=/goto/seceducate/>SECEDUCATE</a>)</p></blockquote></li><li>Apply conventional <strong>technical IT security controls</strong> risk-based, since an AI system is an IT system:<ul><li>2a Apply <strong>standard</strong> conventional IT security controls (e.g. 15408, ASVS, OpenCRE, ISO 27001 Annex A, NIST SP800-53) to the complete AI system and don&rsquo;t forget the new AI-specific assets :<ul><li>Development-time: model & data storage, model & data supply chain, data science documentation:<blockquote><p>(<a href=/goto/devsecurity/>DEVSECURITY</a>, <a href=/goto/segregatedata/>SEGREGATEDATA</a>, <a href=/goto/supplychainmanage/>SUPPLYCHAINMANAGE</a>, <a href=/goto/discrete/>DISCRETE</a>)</p></blockquote></li><li>Runtime: model storage, model use, plug-ins, and model input/output:<blockquote><p>(<a href=/goto/runtimemodelintegrity/>RUNTIMEMODELINTEGRITY</a>, <a href=/goto/runtimemodeliointegrity/>RUNTIMEMODELIOINTEGRITY</a>, <a href=/goto/runtimemodelconfidentiality/>RUNTIMEMODELCONFIDENTIALITY</a>, <a href=/goto/modelinputconfidentiality/>MODELINPUTCONFIDENTIALITY</a>, <a href=/goto/encodemodeloutput/>ENCODEMODELOUTPUT</a>, <a href=/goto/limitresources/>LIMITRESOURCES</a>)</p></blockquote></li></ul></li><li>2b <strong>Adapt</strong> conventional IT security controls to make them more suitable for AI (e.g. which usage patterns to monitor for):<blockquote><p>(<a href=/goto/monitoruse/>MONITORUSE</a>, <a href=/goto/modelaccesscontrol/>MODELACCESSCONTROL</a>, <a href=/goto/ratelimit/>RATELIMIT</a>)</p></blockquote></li><li>2c Adopt <strong>new</strong> IT security controls:<blockquote><p>(<a href=/goto/confcompute/>CONFCOMPUTE</a>, <a href=/goto/modelobfuscation/>MODELOBFUSCATION</a>, <a href=/goto/promptinputvalidation/>PROMPTINPUTVALIDATION</a>, <a href=/goto/inputsegregation/>INPUTSEGREGATION</a>)</p></blockquote></li></ul></li><li>Data scientists apply <strong>data science security controls</strong> risk-based :<ul><li>3a Development-time controls when developing the model:<blockquote><p>(<a href=/goto/federatedlearning/>FEDERATEDLEARNING</a>, <a href=/goto/continuousvalidation/>CONTINUOUSVALIDATION</a>, <a href=/goto/unwantedbiastesting/>UNWANTEDBIASTESTING</a>, <a href=/goto/evasionrobustmodel/>EVASIONROBUSTMODEL</a>, <a href=/goto/poisonrobustmodel/>POISONROBUSTMODEL</a>, <a href=/goto/trainadversarial/>TRAINADVERSARIAL</a>, <a href=/goto/traindatadistortion/>TRAINDATADISTORTION</a>, <a href=/goto/adversarialrobustdistillation/>ADVERSARIALROBUSTDISTILLATION</a>, <a href=/goto/modelensemble/>MODELENSEMBLE</a>, <a href=/goto/moretraindata/>MORETRAINDATA</a>, <a href=/goto/smallmodel/>SMALLMODEL</a>, <a href=/goto/dataqualitycontrol/>DATAQUALITYCONTROL</a>)</p></blockquote></li><li>3b Runtime controls to filter and detect attacks:<blockquote><p>(<a href=/goto/detectoddinput/>DETECTODDINPUT</a>, <a href=/goto/detectadversarialinput/>DETECTADVERSARIALINPUT</a>, <a href=/goto/dosinputvalidation/>DOSINPUTVALIDATION</a>, <a href=/goto/inputdistortion/>INPUTDISTORTION</a>, <a href=/goto/filtersensitivemodeloutput/>FILTERSENSITIVEMODELOUTPUT</a>, <a href=/goto/obscureconfidence/>OBSCURECONFIDENCE</a>)</p></blockquote></li></ul></li><li><strong>Minimize data:</strong> Limit the amount of data in rest and in transit, and the time it is stored, development-time and runtime:<blockquote><p>(<a href=/goto/dataminimize/>DATAMINIMIZE</a>, <a href=/goto/alloweddata/>ALLOWEDDATA</a>, <a href=/goto/shortretain/>SHORTRETAIN</a>, <a href=/goto/obfuscatetrainingdata/>OBFUSCATETRAININGDATA</a>)</p></blockquote></li><li><strong>Control behaviour impact</strong> as the model can behave in unwanted ways - by mistake or by manipulation:<blockquote><p>(<a href=/goto/oversight/>OVERSIGHT</a>, <a href=/goto/leastmodelprivilege/>LEASTMODELPRIVILEGE</a>, <a href=/goto/aitransparency/>AITRANSPARENCY</a>, <a href=/goto/explainability/>EXPLAINABILITY</a>, <a href=/goto/continuousvalidation/>CONTINUOUSVALIDATION</a>, <a href=/goto/unwantedbiastesting/>UNWANTEDBIASTESTING</a>)</p></blockquote></li></ol><p>All threats and controls are discussed in the further content of the AI Exchange.</p><h3>Threat model with controls - GenAI trained/fine tuned<span class="absolute -mt-20" id=threat-model-with-controls---genai-trainedfine-tuned></span>
<a href=#threat-model-with-controls---genai-trainedfine-tuned class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>Below diagram restricts the threats and controls to Generative AI only, for situations in which <strong>training or fine tuning</strong> is done by the organization (note: this is not very common given the high cost and required expertise).</p><p><a href=/images/threatscontrols-genainotready.png><img src=/images/threatscontrols-genainotready.png alt="AI Security Threats and controls - GenAI trained or fine tuned" loading=lazy></a></p><h3>Threat model with controls - GenAI as-is<span class="absolute -mt-20" id=threat-model-with-controls---genai-as-is></span>
<a href=#threat-model-with-controls---genai-as-is class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>Below diagram restricts the threats and controls to Generative AI only where the model is used <strong>as-is</strong> by the organization. The provider (e.g. OpenAI) has done the training/fine tuning. Therefore, some threats are the responsibility of the model provider (sensitive/copyrighted data, manipulation at the provider). Nevertheless, the organization that uses the model should take these risks into account and gain assurance about them from the provider.</p><p>In many situation, the as-is model will be hosted externally and therefore security depends on how the supplier is handling the data, including the security configuration. How is the API protected? What is virtual private cloud? The entire external model, or just the API? Key management? Data retention? Logging? Does the model reach out to third party sources by sending out sensitive input data?</p><p><a href=/images/threatscontrols-readymodel.png><img src=/images/threatscontrols-readymodel.png alt="AI Security Threats and controls - GenAI as-is" loading=lazy></a></p><h3>Periodic table of AI security<span class="absolute -mt-20" id=periodic-table-of-ai-security></span>
<a href=#periodic-table-of-ai-security class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/periodictable/ target=_blank rel=noopener>https://owaspai.org/goto/periodictable/</a></p></blockquote><p>The table below, created by the OWASP AI Exchange, shows the various threats to AI and the controls you can use against them – all organized by asset, impact and attack surface, with deeplinks to comprehensive coverage here at the AI Exchange website.<br>Note that <a href=/goto/governancecontrols/>general governance controls</a> apply to all threats.</p><table><thead><tr><th>Asset & Impact</th><th>Attack surface with lifecycle</th><th>Threat/Risk category</th><th>Controls</th></tr></thead><tbody><tr><td rowspan=7>Model behaviour Integrity</td><td rowspan=3>Runtime -Model use (provide input/ read output)</td><td><a href=/goto/directpromptinjection/>Direct prompt injection</a></td><td><a href=/goto/limitunwanted/>Limit unwanted behavior</a>, <a href=/goto/promptinputvalidation/>Input validation</a>, further controls implemented in the model itself</td></tr><tr><td><a href=/goto/indirectpromptinjection/>Indirect prompt injection</a></td><td><a href=/goto/limitunwanted/>Limit unwanted behavior</a>, <a href=/goto/promptinputvalidation/>Input validation</a>, <a href=/goto/inputsegregation/>Input segregation</a></td></tr><tr><td><a href=/goto/evasion/>Evasion</a> (e.g. adversarial examples)</td><td><a href=/goto/limitunwanted/>Limit unwanted behavior</a>, <a href=/goto/monitoruse/>Monitor</a>, <a href=/goto/ratelimit/>rate limit</a>, <a href=/goto/modelaccesscontrol/>model access control</a> plus:<br><br><a href=/goto/detectoddinput/>Detect odd input</a>, <a href=/goto/detectadversarialinput/>detect adversarial input</a>, <a href=/goto/evasionrobustmodel/>evasion robust model</a>, <a href=/goto/trainadversarial/>train adversarial</a>, <a href=/goto/inputdistortion/>input distortion</a>, <a href=/goto/adversarialrobustdistillation/>adversarial robust distillation</a></td></tr><tr><td>Runtime - Break into deployed model</td><td><a href=/goto/runtimemodelpoison/>Model poisoning runtime</a> (reprogramming)</td><td><a href=/goto/limitunwanted/>Limit unwanted behavior</a>, <a href=/goto/runtimemodelintegrity/>Runtime model integrity</a>, <a href=/goto/runtimemodeliointegrity/>runtime model input/output integrity</a></td></tr><tr><td rowspan=2>Development -Engineering environment</td><td><a href=/goto/devmodelpoison/>Development-environment model poisoning</a></td><td><a href=/goto/limitunwanted/>Limit unwanted behavior</a>, <a href=/goto/devsecurity/>Development environment security</a>, <a href=/goto/segregatedata/>data segregation</a>, <a href=/goto/federatedlearning/>federated learning</a>, <a href=/goto/supplychainmanage/>supply chain management</a> plus:<br><br><a href=/goto/modelensemble/>model ensemble</a></td></tr><tr><td><a href=/goto/datapoison/>Data poisoning of train/finetune data</a></td><td><a href=/goto/limitunwanted/>Limit unwanted behavior</a>, <a href=/goto/devsecurity/>Development environment security</a>, <a href=/goto/segregatedata/>data segregation</a>, <a href=/goto/federatedlearning/>federated learning</a>, <a href=/goto/supplychainmanage/>supply chain management</a> plus:<br><br><a href=/goto/modelensemble/>model ensemble</a> plus:<br><br><a href=/goto/moretraindata/>More training data</a>, <a href=/goto/dataqualitycontrol/>data quality control</a>, <a href=/goto/traindatadistortion/>train data distortion</a>, <a href=/goto/poisonrobustmodel/>poison robust model</a>, <a href=/goto/trainadversarial/>train adversarial</a></td></tr><tr><td>Development - Supply chain</td><td><a href=/goto/supplymodelpoison/>Supply-chain model poisoning</a></td><td><a href=/goto/limitunwanted/>Limit unwanted behavior</a>,<br>Supplier: <a href=/goto/devsecurity/>Development environment security</a>, <a href=/goto/segregatedata/>data segregation</a>, <a href=/goto/federatedlearning/>federated learning</a><br><br>Producer: <a href=/goto/supplychainmanage/>supply chain management</a> plus:<br><br><a href=/goto/modelensemble/>model ensemble</a></td></tr><tr><td rowspan=3>Training data Confidentiality</td><td rowspan=2>Runtime - Model use</td><td><a href=/goto/disclosureuseoutput/>Data disclosure in model output</a></td><td><a href=/goto/datalimit/>Sensitive data limitation</a> (data minimize, short retain, obfuscate training data) plus:<br><br><a href=/goto/monitoruse/>Monitor</a>, <a href=/goto/ratelimit/>rate limit</a>, <a href=/goto/modelaccesscontrol/>model access control</a> plus:<br><br><a href=/goto/filtersensitivemodeloutput/>Filter sensitive model output</a></td></tr><tr><td><a href=/goto/modelinversionandmembership/>Model inversion / Membership inference</a></td><td><a href=/goto/datalimit/>Sensitive data limitation</a> (data minimize, short retain, obfuscate training data) plus:<br><br><a href=/goto/monitoruse/>Monitor</a>, <a href=/goto/ratelimit/>rate limit</a>, <a href=/goto/modelaccesscontrol/>model access control</a> plus:<br><br><a href=/goto/obscureconfidence/>Obscure confidence</a>, <a href=/goto/smallmodel/>Small model</a></td></tr><tr><td>Development - Engineering environment</td><td><a href=/goto/devdataleak/>Training data leaks</a></td><td><a href=/goto/datalimit/>Sensitive data limitation</a> (data minimize, short retain, obfuscate training data) plus:<br><br><a href=/goto/devsecurity/>Development environment security</a>, <a href=/goto/segregatedata/>data segregation</a>, <a href=/goto/federatedlearning/>federated learning</a></td></tr><tr><td rowspan=3>Model confidentiality</td><td>Runtime - Model use</td><td><a href=/goto/modeltheftuse/>Model theft through use</a> (input-output harvesting)</td><td><a href=/goto/monitoruse/>Monitor</a>, <a href=/goto/ratelimit/>rate limit</a>, <a href=/goto/modelaccesscontrol/>model access control</a></td></tr><tr><td>Runtime - Break into deployed model</td><td><a href=/goto/runtimemodeltheft/>Direct model theft runtime</a></td><td><a href=/goto/runtimemodelconfidentiality/>Runtime model confidentiality</a>, <a href=/goto/modelobfuscation/>Model obfuscation</a></td></tr><tr><td>Development - Engineering environment</td><td><a href=/goto/devmodelleak/>Model theft development-time</a></td><td><a href=/goto/devsecurity/>Development environment security</a>, <a href=/goto/segregatedata/>data segregation</a>, <a href=/goto/federatedlearning/>federated learning</a></td></tr><tr><td>Model behaviour Availability</td><td>Model use</td><td><a href=/goto/denialmodelservice/>Denial of model service</a> (model resource depletion)</td><td><a href=/goto/monitoruse/>Monitor</a>, <a href=/goto/ratelimit/>rate limit</a>, <a href=/goto/modelaccesscontrol/>model access control</a> plus:<br><br><a href=/goto/dosinputvalidation/>Dos input validation</a>, <a href=/goto/limitresources/>limit resources</a></td></tr><tr><td>Model input data Confidentialiy</td><td>Runtime - All IT</td><td><a href=/goto/leakinput/>Model input leak</a></td><td><a href=/goto/modelinputconfidentiality/>Model input confidentiality</a></td></tr><tr><td>Any asset, CIA</td><td>Runtime-All IT</td><td><a href=/goto/insecureoutput/>Model output contains injection</a></td><td><a href=/goto/encodemodeloutput/>Encode model output</a></td></tr><tr><td>Any asset, CIA</td><td>Runtime - All IT</td><td>Conventional runtime security attack on conventional asset</td><td>Conventional runtime security controls</td></tr><tr><td>Any asset, CIA</td><td>Runtime - All IT</td><td>Conventional attack on conventional supply chain</td><td>Conventional supply chain management controls</td></tr></tbody></table><h3>Navigator diagram<span class="absolute -mt-20" id=navigator-diagram></span>
<a href=#navigator-diagram class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/navigator/ target=_blank rel=noopener>https://owaspai.org/goto/navigator/</a></p></blockquote><p>The navigator diagram below shows all threats, controls and how they relate, including risks and the types of controls.<br><div class="overflow-x-auto mt-6 flex rounded-lg border py-2 ltr:pr-4 rtl:pl-4 contrast-more:border-current contrast-more:dark:border-current border-blue-200 bg-blue-100 text-blue-900 dark:border-blue-200/30 dark:bg-blue-900/30 dark:text-blue-200"><div class="ltr:pl-3 ltr:pr-2 rtl:pr-3 rtl:pl-2"><div class="select-none text-xl" style="font-family:apple color emoji,segoe ui emoji,segoe ui symbol">ℹ️</div></div><div class="w-full min-w-0 leading-7"><div class="mt-6 leading-7 first:mt-0">Click on the image to get a PDF with clickable links.</div></div></div><a href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide/raw/main/assets/images/owaspaioverviewpdfv3.pdf target=_blank rel=noopener><img src=/images/owaspaioverviewv2.png alt loading=lazy></a></p><hr><h2>How to select relevant threats and controls? risk analysis<span class="absolute -mt-20" id=how-to-select-relevant-threats-and-controls-risk-analysis></span>
<a href=#how-to-select-relevant-threats-and-controls-risk-analysis class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/riskanalysis/ target=_blank rel=noopener>https://owaspai.org/goto/riskanalysis/</a></p></blockquote><p>There are many threats and controls described in this document. Your situation and how you use AI determines which threats are relevant to you, to what extent, and what controls are who&rsquo;s responsibility. This selection process can be performed through risk analysis (or risk assessment) in light of the use case and architecture.</p><p><strong>Risk management introduction</strong><br>Organizations classify their risks into several key areas: Strategic, Operational, Financial, Compliance, Reputation, Technology, Environmental, Social, and Governance (ESG). A threat becomes a risk when it exploits one or more vulnerabilities. AI threats, as discussed in this resource, can have significant impact across multiple risk domains. For example, adversarial attacks on AI systems can lead to disruptions in operations, distort financial models, and result in compliance issues. See the <a href=/goto/aisecuritymatrix/>AI security matrix</a> for an overview of potential impact.</p><p>General risk management for AI systems is typically driven by AI governance - see <a href=/goto/aiprogram/>AIPROGRAM</a> and includes both risks BY relevant AI systems and risks TO those systems. Security risk assessment is typically driven by the security management system - see <a href=/goto/secprogram>SECPROGRAM</a> as this system is tasked to include AI assets, AI threats, and AI systems into consideration - provided that these have been added to the corresponding repositories.</p><p>Organizations often adopt a Risk Management framework, commonly based on ISO 31000 or similar standards such as ISO 23894. These frameworks guide the process of managing risks through four key steps as outlined below:</p><ol><li><strong>Identifying Risks</strong>: Recognizing potential risks (Threats) that could impact the organization. See “Threat through use” section to identify potential risks (Threats).</li><li><strong>Evaluating Risks by Estimating Likelihood and Impact</strong>: To determine the severity of a risk, it is necessary to assess the probability of the risk occurring and evaluating the potential consequences should the risk materialize. Combining likelihood and impact to gauge the risk&rsquo;s overall severity. This is typically presented in the form of a heatmap. See below for further details.</li><li><strong>Deciding What to Do (Risk Treatment)</strong>: Choosing an appropriate strategy to address the risk. These strategies include: Risk Mitigation, Transfer, Avoidance, or Acceptance. See below for further details.</li><li><strong>Risk Communication and Monitoring</strong>: Regularly sharing risk information with stakeholders to ensure awareness and support for risk management activities. Ensuring effective Risk Treatments are applied. This requires a Risk Register, a comprehensive list of risks and their attributes (e.g. severity, treatment plan, ownership, status, etc). See below for further details.</li></ol><p>Let&rsquo;s go through the risk management steps one by one.</p><h3>1. Identifying Risks<span class="absolute -mt-20" id=1-identifying--risks></span>
<a href=#1-identifying--risks class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>Selecting potential risks (Threats) that could impact the organization requires technical and business assessment of the applicable threats. A method to do this is discussed below, for every type of risk impact:</p><p><strong>Unwanted model behaviour</strong></p><p>Regarding model behaviour, we focus on manipulation by attackers, as the scope of this document is security. Other sources of unwanted behaviour are general inaccuracy (e.g. hallucinations) and/or unwanted bias regarding certain groups (discrimination).</p><p>This will always be an applicable threat, independent of your situation, although the risk level may sometimes be accepted - see below.</p><p>Which means that you always need to have in place:</p><ul><li><a href=/goto/governancecontrols/>General governance controls</a> (e.g. having an inventory of AI use and some control over it)</li><li><a href=/goto/limitunwanted/>Controls to limit effects of unwanted model behaviour</a> (e.g. human oversight)</li></ul><p>Is the model GenAI (e.g. a Large Language Model)?</p><ul><li>Prevent <a href=/goto/directpromptinjection/>prompt injection</a> (mostly done by the model supplier) in case untrusted input goes directly into the model, and it is important that the model follows its policy instructions about how it communicates. Mostly this is the case if model input is from end users and output also goes straight to end users, who could show that the model can misbehave (e.g. be politically incorrect), which can lead to reputation damage.</li><li>Prevent <a href=/goto/indirectpromptinjection/>indirect prompt injection</a>, in case untrusted input goes somehow into the prompt e.g. you retrieve somebody&rsquo;s resume and include it in a prompt.</li></ul><p>Sometimes model training and running the model is deferred to a supplier. For generative AI, training is mostly performed by an external supplier given the cost of typically millions of dollars. Finetuning of generative AI is also not often performed by organizations given the cost of compute and the complexity involved. Some GenAI models can be obtained and run at your own premises. The reasons to do this can be lower cost (if is is an open source model), and the fact that sensitive input information does not have to be sent externally. A reason to use an externally hosted GenAI model can be the quality of the model.</p><p>Who trains/finetunes the model?</p><ul><li>The supplier: you need to prevent <a href=/goto/transferlearningattack/>obtaining a poisoned model</a> by proper supply chain mangement (selecting a proper supplier and making sure you use the actual model), including assuring that: the supplier prevents development-time model poisoning including data poisoning and obtaining poisoned data. If the remaining risk for data poisoning cannot be accepted, performing post-training countermeasures can be an option - see <a href=/goto/poisonrobustmodel/>POISONROBUSTMODEL</a>.</li><li>You: you need to prevent <a href=/goto/modelpoison/>development-time model poisoning</a> which includes model poisoning, data poisoning and obtaining poisoned data</li></ul><p>If you use RAG (Retrieval Augmented Generation using GenAI), then your retrieval repository plays a role in determining the model behaviour. This means:</p><ul><li>You need to prevent <a href=/goto/datapoison/>data poisoning</a> of your retrieval repository, which includes preventing that it contains externally obtained poisoned data.</li></ul><p>Who runs the model?</p><ul><li>The supplier: make sure the supplier prevents <a href=/goto/runtimemodelpoison/>runtime model poisoning</a> just like any supplier who you expect to protect the running application from manipulation</li><li>You: You need to prevent <a href=/goto/runtimemodelpoison/>runtime model poisoning</a></li></ul><p>Is the model predictive AI?</p><ul><li>Prevent an <a href=/goto/evasion/>evasion attack</a> in which a user tries to fool the model into a wrong decision. Here, the level of risk is an important aspect to evaluate - see below. The risk of an evasion attack may be acceptable.</li></ul><p>In order to assess the level of risk for unwanted model behaviour through manipulation, consider what the motivation of an attacker could be. What could an attacker gain by for example sabotaging your model? Just a claim to fame? Could it be a disgruntled employee? Maybe a competitor? What could an attacker gain by a less conspicuous model behaviour attack, like an evasion attack or data poisoning with a trigger? Is there a scenario where an attacker benefits from fooling the model? An example where evasion IS interesting and possible: adding certain words in a spam email so that it is not recognized as such. An example where evasion is not interesting is when a patient gets a skin disease diagnosis based on a picture of the skin. The patient has no interest in a wrong decision, and also the patient typically has no control - well maybe by painting the skin. There are situations in which this CAN be of interest for the patient, for example to be eligible for compensation in case the (faked) skin disease was caused by certain restaurant food. This demonstrates that it all depends on the context whether a theoretical threat is a real threat or not. Depending on the probability and impact of the threats, and on the relevant policies, some threats may be accepted as risk. When not accepted, the level of risk is input to the strength of the controls. For example: if data poisoning can lead to substantial benefit for a group of attackers, then the training data needs to be get a high level of protection.</p><p><strong>Leaking training data</strong></p><p>Do you train/finetune the model yourself?</p><ul><li>Yes: and is the training data sensitive? Then you need to prevent:<ul><li><a href=/goto/disclosureuse/>unwanted disclosure in model output</a></li><li><a href=/goto/modelinversionandmembership/>model inversion</a> (but not for GenAI)</li><li><a href=/goto/devdataleak/>training data leaking from your engineering environment</a>.</li><li><a href=%28/goto/modelinversionandmembership/%29>membership inference</a> - but only if the <strong>fact</strong> that something or somebody was part of the training set is sensitive information. For example when the training set consists of criminals and their history to predict criminal careers: membership of that set gives away the person is a convicted or alleged criminal.</li></ul></li></ul><p>If you use RAG: apply the above to your repository data, as if it was part of the training set: as the repository data feeds into the model and can therefore be part of the output as well.</p><p>If you don&rsquo;t train/finetune the model, then the supplier of the model is responsible for unwanted content in the training data. This can be poisoned data (see above), data that is confidential, or data that is copyrighted. It is important to check licenses, warranties and contracts for these matters, or accept the risk based on your circumstances.</p><p><strong>Model theft</strong></p><p>Do you train/finetune the model yourself?</p><ul><li>Yes, and is the model regarded intellectual poperty? Then you need to prevent:<ul><li><a href=/goto/modeltheftuse/>Model theft through use</a></li><li><a href=/goto/devmodelleak/>Model theft development-time</a></li><li><a href=/goto/devcodeleak/>Source code/configuration leak</a></li><li><a href=/goto/runtimemodeltheft/>Runtime model theft</a></li></ul></li></ul><p><strong>Leaking input data</strong></p><p>Is your input data sensitive?</p><ul><li>Prevent <a href=/goto/leakinput/>leaking input data</a>. Especially if the model is run by a supplier, proper care needs to be taken that this data is transferred or stored in a protected way and as little as possible. Note, that if you use RAG, that the data you retrieve and insert into the prompt is also input data. This typically contains company secrets or personal data.</li></ul><p><strong>Misc.</strong></p><p>Is your model a Large Language Model?</p><ul><li>Prevent <a href=/goto/insecureoutput/>insecure output handling</a>, for example when you display the output of the model on a website and the output contains malicious Javascript.</li></ul><p>Make sure to prevent <a href=/denialmodelservice/>model inavailability by malicious users</a> (e.g. large inputs, many requests). If your model is run by a supplier, then certain countermeasures may already be in place.</p><p>Since AI systems are software systems, they require appropriate conventional application security and operational security, apart from the AI-specific threats and controls mentioned in this section.</p><h3>2. Evaluating Risks by Estimating Likelihood and Impact<span class="absolute -mt-20" id=2-evaluating-risks-by-estimating-likelihood-and-impact></span>
<a href=#2-evaluating-risks-by-estimating-likelihood-and-impact class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>To determine the severity of a risk, it is necessary to assess the probability of the risk occurring and evaluating the potential consequences should the risk materialize.</p><p><strong>Estimating the Likelihood:</strong><br>Estimating the likelihood and impact of an AI risk requires a thorough understanding of both the technical and contextual aspects of the AI system in scope. The likelihood of a risk occurring in an AI system is influenced by several factors, including the complexity of the AI algorithms, the data quality and sources, the conventional security measures in place, and the potential for adversarial attacks. For instance, an AI system that processes public data is more susceptible to data poisoning and inference attacks, thereby increasing the likelihood of such risks. A financial institution&rsquo;s AI system, which assesses loan applications using public credit scores, is exposed to data poisoning attacks. These attacks could manipulate creditworthiness assessments, leading to incorrect loan decisions.</p><p><strong>Evaluating the Impact:</strong>
Evaluating the impact of risks in AI systems involves understanding the potential consequences of threats materializing. This includes both the direct consequences, such as compromised data integrity or system downtime, and the indirect consequences, such as reputational damage or regulatory penalties. The impact is often magnified in AI systems due to their scale and the critical nature of the tasks they perform. For instance, a successful attack on an AI system used in healthcare diagnostics could lead to misdiagnosis, affecting patient health and leading to significant legal, trust, and reputational repercussions for the involved entities.</p><p><strong>Prioritizing risks</strong>
The combination of likelihood and impact assessments forms the basis for prioritizing risks and informs the development of Risk Treatment decisions. Commonly organizations use a risk heat map to visually categorize risks by impact and likelihood. This approach facilitates risk communication and decision-making. It allows the management to focus on risks with highest severity (high likelihood and high impact).</p><h3>3. Risk Treatment<span class="absolute -mt-20" id=3-risk-treatment></span>
<a href=#3-risk-treatment class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>Risk treatment is about deciding what to do with the risks. It involves selecting and implementing measures to mitigate, transfer, avoid, or accept cybersecurity risks associated with AI systems. This process is critical due to the unique vulnerabilities and threats related to AI systems such as data poisoning, model theft, and adversarial attacks. Effective risk treatment is essential to robust, reliable, and trustworthy AI.</p><p>Risk Treatment options are:</p><ol><li><strong>Mitigation</strong>: Implementing controls to reduce the likelihood or impact of a risk. This is often the most common approach for managing AI cybersecurity risks. See the many controls in this resource and the &lsquo;Select controls&rsquo; subsection below.<br>- Example: Enhancing data validation processes to prevent data poisoning attacks, where malicious data is fed into the Model to corrupt its learning process and negatively impact its performance.</li><li><strong>Transfer</strong>: Shifting the risk to a third party, typically through transfer learning, federated learning, insurance or outsourcing certain functions.
- Example: Using third-party cloud services with robust security measures for AI model training, hosting, and data storage, transferring the risk of data breaches and infrastructure attacks.</li><li><strong>Avoidance</strong>: Changing plans or strategies to eliminate the risk altogether. This may involve not using AI in areas where the risk is deemed too high.
- Example: Deciding against deploying an AI system for processing highly sensitive personal data where the risk of data breaches cannot be adequately mitigated.</li><li><strong>Acceptance</strong>: Acknowledging the risk and deciding to bear the potential loss without taking specific actions to mitigate it. This option is chosen when the cost of treating the risk outweighs the potential impact.
- Example: Accepting the minimal risk of model inversion attacks (where an attacker attempts to reconstruct publicly available input data from model outputs) in non-sensitive applications where the impact is considered low.</li></ol><h3>4. Risk Communication & Monitoring<span class="absolute -mt-20" id=4-risk-communication--monitoring></span>
<a href=#4-risk-communication--monitoring class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>Regularly sharing risk information with stakeholders to ensure awareness and support for risk management activities.</p><p>A central tool in this process is the Risk Register, which serves as a comprehensive repository of all identified risks, their attributes (such as severity, treatment plan, ownership, and status), and the controls implemented to mitigate them. Most large organizations already have such a Risk Register. It is important to align AI risks and chosen vocabularies from Enterprise Risk Management to facilitate effective communication of risks throughout the organization.</p><h3>5. Arrange responsibility<span class="absolute -mt-20" id=5-arrange-responsibility></span>
<a href=#5-arrange-responsibility class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>For each selected threat, determine who is responsible to address it. By default, the organization that builds and deploys the AI system is responsible, but building and deploying may be done by different organizations, and some parts of the building and deployment may be deferred to other organizations, e.g. hosting the model, or providing a cloud environment for the application to run. Some aspects are shared responsibilities.</p><p>If components of your AI system are hosted, then you share responsibility regarding all controls for the relevant threats with the hosting provider. This needs to be arranged with the provider, using for example a responsibility matrix. Components can be the model, model extensions, your application, or your infrastructure. See <a href=#threat-model-with-controls---genai-as-is>Threat model of using a model as-is</a>.</p><p>If an external party is not open about how certain risks are mitigated, consider requesting this information and when this remains unclear you are faced with either 1) accept the risk, 2) or provide your own mitigations, or 3)avoid the risk, by not engaging with the third party.</p><h3>6. Verify external responsibilities<span class="absolute -mt-20" id=6-verify-external-responsibilities></span>
<a href=#6-verify-external-responsibilities class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>For the threats that are the responsibility of other organisations: attain assurance whether these organisations take care of it. This would involve the controls that are linked to these threats.</p><p>Example: Regular audits and assessments of third-party security measures.</p><h3>7. Select controls<span class="absolute -mt-20" id=7-select-controls></span>
<a href=#7-select-controls class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>Then, for the threats that are relevant to you and for which you are responsible: consider the various controls listed with that threat (or the parent section of that threat) and the general controls (they always apply). When considering a control, look at its purpose and determine if you think it is important enough to implement it and to what extent. This depends on the cost of implementation compared to how the purpose mitigates the threat, and the level of risk of the threat. These elements also play a role of course in the order you select controls: highest risks first, then starting with the lower cost controls (low hanging fruit).</p><p>Controls typically have quality aspects to them, that need to be fine tuned to the situation and the level of risk. For example: the amount of noise to add to input data, or setting thresholds for anomaly detection. The effectiveness of controls can be tested in a simulation environement to evaluate the performance impact and security improvements to find the optimal balance. Fine tuning controls needs to continuously take place, based on feedback from testing in simulation in in production.</p><h3>8. Residual risk acceptance<span class="absolute -mt-20" id=8-residual-risk-acceptance></span>
<a href=#8-residual-risk-acceptance class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>In the end you need to be able to accept the risks that remain regarding each threat, given the controls that you implemented.</p><h3>9. Further management of the selected controls<span class="absolute -mt-20" id=9-further-management-of-the-selected-controls></span>
<a href=#9-further-management-of-the-selected-controls class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>(see <a href=/goto/secprogram/>SECPROGRAM</a>), which includes continuous monitoring, documentation, reporting, and incident response.</p><h3>10. Continuous risk assessment<span class="absolute -mt-20" id=10-continuous-risk-assessment></span>
<a href=#10-continuous-risk-assessment class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>Implement continuous monitoring to detect and respond to new threats. Update the risk management strategies based on evolving threats and feedback from incident response activities.<br>Example: Regularly reviewing and updating risk treatment plans to adapt to new vulnerabilities.</p><hr><h2>How about &mldr;<span class="absolute -mt-20" id=how-about-></span>
<a href=#how-about- class=subheading-anchor aria-label="Permalink for this section"></a></h2><h3>How about AI outside of machine learning?<span class="absolute -mt-20" id=how-about-ai-outside-of-machine-learning></span>
<a href=#how-about-ai-outside-of-machine-learning class=subheading-anchor aria-label="Permalink for this section"></a></h3><p>A helpful way to look at AI is to see it as consisting of machine learning (the current dominant type of AI) models and <em>heuristic models</em>. A model can be a machine learning model which has learned how to compute based on data, or it can be a heuristic model engineered based on human knowledge, e.g. a rule-based system. Heuristic models still need data for testing, and sometimes to perform analysis for further building and validating the human knowledge.<br>This document focuses on machine learning. Nevertheless, here is a quick summary of the machine learning threats from this document that also apply to heuristic systems:</p><ul><li>Model evasion is also possible for heuristic models, -trying to find a loophole in the rules</li><li>Model theft through use - it is possible to train a machine learning model based on input/output combinations from a heuristic model</li><li>Overreliance in use - heuristic systems can also be relied on too much. The applied knowledge can be false</li><li>Data poisoning and model poisoning is possible by manipulating data that is used to improve knowledge and by manipulating the rules development-time or runtime</li><li>Leaks of data used for analysis or testing can still be an issue</li><li>Knowledge base, source code and configuration can be regarded as sensitive data when it is intellectual property, so it needs protection</li><li>Leak sensitive input data, for example when a heuristic system needs to diagnose a patient</li></ul><h3>How about responsible or trustworthy AI?<span class="absolute -mt-20" id=how-about-responsible-or-trustworthy-ai></span>
<a href=#how-about-responsible-or-trustworthy-ai class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/responsibleai/ target=_blank rel=noopener>https://owaspai.org/goto/responsibleai/</a></p></blockquote><p>There are many aspects of AI when it comes to positive outcome while mitigating risks. This is often referred to as responsible AI or trustworthy AI, where the former emphasises ethics, society, and governance, while the latter emphasises the more technical and operational aspects.</p><p>If your main responsibility is security, then the best strategy is to first focus on AI security and after that learn more about the other AI aspects - if only to help your colleagues with the corresponding responsibility to stay alert. After all, security professionals are typically good at identifying things that can go wrong. Furthermore, some aspects can be a consequence of compromised AI and are therefore helpful to understand, such as <em>safety</em>.</p><p>Let&rsquo;s clarify the aspects of AI and see how they relate to security:</p><ul><li><strong>Accuracy</strong> is about the AI model being sufficiently correct to perform its &lsquo;business function&rsquo;. Being incorrect can lead to harm, including (physical) safety problems (e.g. car trunk opens during driving) or other wrong decisions that are harmful (e.g. wrongfully declined loan). The link with security is that some attacks cause unwanted model behaviour which is by definition an accuracy problem. Nevertheless, the security scope is restricted to mitigating the risks of those attacks - NOT solve the entire problem of creating an accurate model (selecting representative data for the trainset etc.).</li><li><strong>Safety</strong> refers to the condition of being protected from / unlikely to cause harm. Therefore safety of an AI system is about the level of accuracy when there is a risk of harm (typically implying physical harm but not restricted to that) , plus the things that are in place to mitigate those risks (apart from accuracy), which includes security to safeguard accuracy, plus a number of safety measures that are important for the business function of the model. These need to be taken care of and not just for security reasons because the model can make unsafe decisions for other reasons (e.g. bad training data), so they are a shared concern between safety and security:<ul><li><a href=/goto/oversight/>oversight</a> to restrict unsafe behaviour, and connected to that: assigning least privileges to the model,</li><li><a href=/goto/continuousvalidation/>continuous validation</a> to safeguard accuracy,</li><li><a href=/goto/aitransparency/>transparency</a>: see below,</li><li><a href=/goto/continuousvalidation/>explainability</a>: see below.</li></ul></li><li><strong>Transparency</strong>: sharing information about the approach, to warn users and depending systems of accuracy risks, plus in many cases users have the right to know details about a model being used and how it has been created. Therefore it is a shared concern between security, privacy and safety.</li><li><strong>Explainability</strong>: sharing infor,mation to help users validate accuracy by explaining in more detail how a specific result came to be. Apart from validating accuracy this can also support users to get transparency and to understand what needs to change to get a different outcome. Therefore it is a shared concern between security, privacy, safety and business function. A special case is when explainability is required by law separate from privacy, which adds &lsquo;compliance&rsquo; to the list of aspects that share this concern.</li><li><strong>Robustness</strong> is about the ability of maintaining accuracy under expected or unexpected variations in input. The security scope is about when those variations are malicious (<em>adversarial robustness</em>) which often requires different countermeasures than those required against normal variations (_generalization robustness). Just like with accuracy, security is not involved per se in creating a robust model for normal variations. The exception to this is when generalization robustness adversarial malicious robustness , in which case this is a shared concern between safety and security. This depends on a case by case basis.</li><li><strong>Free of discrimination</strong>: without unwanted bias of protected attibutes, meaning: no systematic inaccuracy where the model &lsquo;mistreats&rsquo; certain groups (e.g. gender, ethicity). Discrimination is undesired for legal and ethical reasons. The relation with security is that having detection of unwanted bias can help to identify unwanted model behaviour caused by an attack. For example, a data poisoning attack has inserted malicious data samples in the training set, which at first goes unnoticed, but then is discovered by an unexplained detection of bias in the model. Sometimes the term &lsquo;fairness&rsquo; is used to refer to discrimination issues, but mostly fairness in privacy is a broader term referring to fair treatment of individuals, including transparency, ethical use, and privacy rights.</li><li><strong>Empathy</strong>. The relation of that with security is that the feasible level of security should always be taken into account when validating a certain application of AI. If a sufficient level of security cannot be provided to individuals or organizations, then empathy means invalidating the idea, or takin other precautions.</li><li><strong>Accountability</strong>. The relation of accountability with security is that security measures should be demonstrable, including the process that have led to those measures. In addition, traceability as a security property is important, just like in any IT system, in order to detect, reconstruct and respond to security incidents and provide accountability.</li><li><strong>AI security</strong>. The security aspect of AI is the central topic of the AI Exchange. In short, it can be broken down into:<ul><li><a href=/goto/threatsuse/>Input attacks</a>, that are performed by providing input to the model</li><li><a href=/goto/modelpoison/>Model poisoning</a>, aimed to alter the model&rsquo;s behavior</li><li>Stealing AI assets, such as train data, model input, output, or the model itself, either <a href=/goto/devleak/>development time</a> or runtime (see below)</li><li>Further <a href=/goto/generalappsecthreats/>runtime conventional security attacks</a></li></ul></li></ul><p><a href=/images/aiwayfinder.png><img src=/images/aiwayfinder.png alt loading=lazy></a></p><h3>How about privacy?<span class="absolute -mt-20" id=how-about-privacy></span>
<a href=#how-about-privacy class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/privacy/ target=_blank rel=noopener>https://owaspai.org/goto/privacy/</a></p></blockquote><p>Just like any system that processes data, AI systems can have privacy risks. There are some particual privacy aspects to AI:</p><ul><li>AI systems are data-intensive and typically present additional risks regarding data collection and retention. Personal data may be collected from various sources, each subject to different levels of <strong>sensitivity and regulatory constraints</strong>. Legislation often requires a <strong>legal basis and/or consent</strong> for the collection and use of personal data, and specifies <strong>rights to individuals</strong> to correct, request, and remove their own data.</li><li><strong>Protecting training data</strong> is a challenge, especially because it typically needs to be retained for long periods - as many models need to be retrained. Often, the actual identities of people involved are irrelevant for the model, but privacy risks still remain even if identity data is removed because it might be possible to deduce individual identities from the remaining data. This is where differential privacy becomes crucial: by altering the data to make it sufficiently unrecognizable, it ensures individual privacy while still allowing for valuable insights to be derived from the data. Alteration can be done by for example adding noise or aggregating.</li><li>An additional complication in the protection of training data is that the <strong>training data is accessible in the engineering environment</strong>, which therefore needs more protection than it usually does - since conventional systems normally don&rsquo;t have personal data available to technical teams.</li><li>The nature of machine learning allows for certain <strong>unique strategies</strong> to improve privacy, such as federated learning: splitting up the training set in different separated systems - typically aligning with separated data collection.</li><li>AI systems <strong>make decisions</strong> and if these decisions are about people they may be discriminating regarding certain protected attributes (e.g. gender, race), plus the decisions may result in actions that invade privacy, which may be an ethical or legal concern. Furthermore, legislation may prohibit some types of decisions and sets rules regarding transparancy about how these decisions are made, and about how individuals have the right to object.</li><li>Last but not least: AI models suffer from <strong>model attack risks</strong> that allow attackers to extract training data from the model, e.g. model inversion, memership inference, and disclosing sensitive data in large language models</li></ul><p>AI Privacy can be divided into two parts:</p><ol><li>The threats to AI security and their controls (this document), including:</li></ol><ul><li>Confidentiality and integrity protection of personal data in train/test data, model input or output - which consists of:<ul><li>&lsquo;Conventional&rsquo; security of personal data in transit and in rest</li><li>Protecting against model attacks that try to retrieve personal data (e.g. model inversion)</li><li>personal data minimization / differential privacy, including minimized retention</li></ul></li><li>Integrity protection of the model behaviour if that behaviour can hurt privacy of individuals. This happens for example when individuals are unlawfully discriminated or when the model output leads to actions that invade privacy (e.g. undergoing a fraud investigation).</li></ul><ol start=2><li>Threats and controls that are not about security, but about further rights of the individual, as covered by privacy regulations such as the GDPR, including use limitation, consent, fairness, transparency, data accuracy, right of correction/objection/erasure/request. For an overview, see the <a href=https://owasp.org/www-project-ai-security-and-privacy-guide/ target=_blank rel=noopener>Privacy part of the OWASP AI guide</a></li></ol><h3>How about Generative AI (e.g. LLM)?<span class="absolute -mt-20" id=how-about-generative-ai-eg-llm></span>
<a href=#how-about-generative-ai-eg-llm class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/genai/ target=_blank rel=noopener>https://owaspai.org/goto/genai/</a></p></blockquote><p>Yes, GenAI is leading the current AI revolution and it&rsquo;s the fastest moving subfield of AI security. Nevertheless it is important to realize that other types of algorithms (let&rsquo;s call it <em>predictive AI</em>) will remain to be applied to many important use cases such as credit scoring, fraud detection, medical diagnosis, product recommendation, image recognition, predictive maintenance, process control, etc. Relevant content has been marked with &lsquo;GenAI&rsquo; in this document.</p><p>Important note: from a security threat perspective, GenAI is not that different from other forms of AI (<em>predictive AI</em>). GenAI threats and controls largely overlap and are very similar to AI in general. Nevertheless, some risks are (much) higher. Some are lower. Only a few risks are GenAI-specific. Some of the control categories differ substantially between GenAI and predictive AI - mostly the data science controls (e.g. adding noise to the training set). In many cases, GenAI solutions will use a model as-is and not involve any training by the organization whatsoever, shifting some of the security responsibilities from the organization to the supplier. Nevertheless, if you use a ready-made model, you need still to be aware of those threats.</p><p>What is mainly new to the threat landscape because of LLMs?</p><ul><li>First of all, LLMs pose new threats to security because they may be used to create code with vulnerabilities, or they may be used by attackers to create malware, or they may cause harm otherwiser through hallucinations, but these are out of scope of the AI Exchange, as it focuses on security threats TO AI systems.</li><li>Regarding input:<ul><li>Prompt injection is a completely new threat: attackers manipulating the behaviour of the model with crafted and sometimes hidden instructions.</li><li>Also new is organizations sending huge amounts of data in prompts, with company secrets and personal data.</li></ul></li><li>Regarding output: New is the fact that output can contain injection attacks, or can contain sensitive or copyrighted data (see <a href=/goto/copyright/>Copyright</a>).</li><li>Overreliance is an issue. We let LLMs control and create things and may have too much trust in how correct they are, and also underestimate the risk of them being manipulated. The result is that attacks can have much impact.</li><li>Regarding training: Since the training sets are so large and based on public data, it is easier to perform data poisoning. Poisoned foundation models are also a big supply chain issues.</li></ul><p>GenAI security particularities are:</p><table><thead><tr><th>Nr.</th><th>GenAI security particularities</th><th>OWASP for LLM TOP 10</th></tr></thead><tbody><tr><td>1</td><td>GenAI models are controlled by natural language in prompts, creating the risk of <a href=/goto/promptinjection/>Prompt injection</a>. Direct prompt injection is where the user tries to fool the model to behave in unwanted ways (e.g. offensive language), whereas with indirect prompt injection it is a third party that injects content into the prompt for this purpose (e.g. manipulating a decision).</td><td>(<a href=https://genai.owasp.org/llmrisk/llm01/ target=_blank rel=noopener>OWASP for LLM 01:Prompt injection</a>)</td></tr><tr><td>2</td><td>GenAI models have typically been trained on very large datasets, which makes it more likely to output <a href=/goto/disclosureuseoutput/>sensitive data</a> or <a href=/goto/copyright/>licensed data</a>, for which there is no control of access privileges built into the model. All data will be accessible to the model users. Some mechanisms may be in place in terms of system prompts or output filtering, but those are typically not watertight.</td><td>(<a href=https://genai.owasp.org/llmrisk/llm02/ target=_blank rel=noopener>OWASP for LLM 02: Sensitive Information Disclosure</a>)</td></tr><tr><td>3</td><td><a href=/goto/modelpoison/>Data and model poisoning</a> is an AI-broad problem, and with GenAI the risk is generally higher since training data can be supplied from different sources that may be challenging to control, such as the internet. Attackers could for example hijack domains and place manipulated information.</td><td>(<a href=https://genai.owasp.org/llmrisk/llm04/ target=_blank rel=noopener>OWASP for LLM 04: Data and Model Poisoning</a>)</td></tr><tr><td>4</td><td>GenAI models can be innacurate and hallucinate. This is an AI-broad risk factor, and Large Language Models (GenAI) can make matters worse by coming across very confident and knowledgeable. In essence this is about the risk of underestimating the probability that the model is wrong or the model has been manipulated. This means that it is connected to each and every security control. The strongest link is with <a href=/goto/limitunwanted/>controls that limit the impact of unwanted model behavior</a>, in particular <a href=/goto/leastmodelprivilege/>Least model privilege</a>.</td><td>(<a href=https://genai.owasp.org/llmrisk/llm06/ target=_blank rel=noopener>OWASP for LLM 06: Excessive agency</a>) and (<a href=https://genai.owasp.org/llmrisk/llm09/ target=_blank rel=noopener>OWASP for LLM 09: Misinformation</a>)</td></tr><tr><td>5</td><td><a href=/goto/leakinput/>Leaking input data</a>: GenAI models mostly live in the cloud - often managed by an external party, which may increase the risk of leaking training data and leaking prompts. This issue is not limited to GenAI, but GenAI has 2 particular risks here: 1) model use involves user interaction through prompts, adding user data and corresponding privacy/sensitivity issues, and 2) GenAI model input (prompts) can contain rich context information with sensitive data (e.g. company secrets). The latter issue occurs with <em>in context learning</em> or <em>Retrieval Augmented Generation(RAG)</em> (adding background information to a prompt): for example data from all reports ever written at a consultancy firm. First of all, this information will travel with the prompt to the cloud, and second: the system will likely not respect the original access rights to the information.</td><td>Not covered in LLM top 10</td></tr><tr><td>6</td><td>Pre-trained models may have been manipulated. The concept of pretraining is not limited to GenAI, but the approach is quite common in GenAI, which increases the risk of <a href=/goto/supplymodelpoison/>supply-chain model poisoning</a>.</td><td>(<a href=https://genai.owasp.org/llmrisk/llm03/ target=_blank rel=noopener>OWASP for LLM 03 - Supply chain vulnerabilities</a>)</td></tr><tr><td>7</td><td><a href=/goto/modelinversionandmembership/>Model inversion and membership inference</a> are typically low to zero risks for GenAI</td><td>Not covered in LLM top 10, apart from LLM06 which uses a different approach - see above</td></tr><tr><td>8</td><td>GenAI output may contain elements that perform an <a href=/goto/insecureoutput/>injection attack</a> such as cross-site-scripting.</td><td>(<a href=https://genai.owasp.org/llmrisk/llm05/ target=_blank rel=noopener>OWASP for LLM 05: Improper Output Handling</a>)</td></tr><tr><td>9</td><td><a href=/goto/denialmodelservice/>Denial of service</a> can be an issue for any AI model, but GenAI models typically cost more to run, so overloading them can create unwanted cost.</td><td>(<a href=https://genai.owasp.org/llmrisk/llm10/ target=_blank rel=noopener>OWASP for LLM 10: Unbounded consumption</a>)</td></tr></tbody></table><p>GenAI References:</p><ul><li><a href=https://llmtop10.com/ target=_blank rel=noopener>OWASP LLM top 10</a></li><li><a href=https://blog.kloudzone.co.in/demystifying-the-owasp-top-10-for-large-language-model-applications/ target=_blank rel=noopener>Demystifying the LLM top 10</a></li><li><a href=https://arxiv.org/pdf/2306.13033.pdf target=_blank rel=noopener>Impacts and risks of GenAI</a></li><li><a href=https://llmsecurity.net/ target=_blank rel=noopener>LLMsecurity.net</a></li></ul><h3>How about the NCSC/CISA guidelines?<span class="absolute -mt-20" id=how-about-the-ncsccisa-guidelines></span>
<a href=#how-about-the-ncsccisa-guidelines class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/jointguidelines/ target=_blank rel=noopener>https://owaspai.org/goto/jointguidelines/</a></p></blockquote><p>Mapping of the UK NCSC /CISA <a href=https://www.ncsc.gov.uk/collection/guidelines-secure-ai-system-development target=_blank rel=noopener>Joint Guidelines for secure AI system development</a> to the controls here at the AI Exchange.<br>To see those controls linked to threats, refer to the <a href=/goto/periodictable/>Periodic table of AI security</a>.</p><ol><li>Secure design</li></ol><ul><li>Raise staff awareness of threats and risks:<br>#<a href=/goto/seceducate/>SECURITY EDUCATE</a></li><li>Model the threats to your system:<br>See Risk analysis under #<a href=/goto/secprogram/>SECURITY PROGRAM</a></li><li>Design your system for security as well as functionality and performance:<br>#<a href=/goto/aiprogram/>AI PROGRAM</a>, #<a href=/goto/secprogram/>SECURITY PROGRAM</a>, #<a href=/goto/devprogram/>DEVELOPMENT PROGRAM</a>, #<a href=/goto/secdevprogram/>SECURE DEVELOPMENT PROGRAM</a>, #<a href=/goto/checkcompliance/>CHECK COMPLIANCE</a>, #<a href=/goto/leastmodelprivilege/>LEAST MODEL PRIVILEGE</a>, #<a href=/goto/discrete/>DISCRETE</a>, #<a href=/goto/obscureconfidence/>OBSCURE CONFIDENCE</a>, #<a href=/goto/oversight/>OVERSIGHT</a>, #<a href=/goto/ratelimit/>RATE LIMIT</a>, #<a href=/goto/dosinputvalidation/>DOS INPUT VALIDATION</a>, #<a href=/goto/limitresources/>LIMIT RESOURCES</a>, #<a href=/goto/modelaccesscontrol/>MODEL ACCESS CONTROL</a>, #<a href=/goto/aitransparency>AI TRANSPARENCY</a></li><li>Consider security benefits and trade-offs when selecting your AI model<br>All development-time data science controls (currently 13), #<a href=/goto/explainability/>EXPLAINABILITY</a></li></ul><ol start=2><li>Secure Development</li></ol><ul><li>Secure your supply chain:<br>#<a href=/goto/supplychainmanage/>SUPPLY CHAIN MANAGE</a></li><li>Identify, track and protect your assets:<br>#<a href=/goto/devsecurity/>DEVELOPMENT SECURITY</a>, #<a href=/goto/segregatedata/>SEGREGATE DATA</a>, #<a href=/goto/confcompute/>CONFIDENTIAL COMPUTE</a>, #<a href=/goto/modelinputconfidentiality/>MODEL INPUT CONFIDENTIALITY</a>, #<a href=/goto/runtimemodelconfidentiality/>RUNTIME MODEL CONFIDENTIALITY</a>, #<a href=/goto/dataminimize/>DATA MINIMIZE</a>, #<a href=/goto/alloweddata/>ALLOWED DATA</a>, #<a href=/goto/shortretain/>SHORT RETAIN</a>, #<a href=/goto/obfuscatetrainingdata/>OBFUSCATE TRAINING DATA</a> and part of #<a href=/goto/secprogram/>SECURITY PROGRAM</a></li><li>Document your data, models and prompts:<br>Part of #<a href=/goto/devprogram/>DEVELOPMENT PROGRAM</a></li><li>Manage your technical debt:<br>Part of #<a href=/goto/devprogram/>DEVELOPMENT PROGRAM</a></li></ul><ol start=3><li>Secure deployment</li></ol><ul><li>Secure your infrastructure:<br>Part of #<a href=/goto/secprogram/>SECURITY PROGRAM</a> and see ‘Identify, track and protect your assets’</li><li>Protect your model continuously:<br>#<a href=/goto/inputdistortion/>INPUT DISTORTION</a>, #<a href=/goto/filtersensitivemodeloutput/>FILTER SENSITIVE MODEL OUTPUT</a>, #<a href=/goto/runtimemodeliointegrity/>RUNTIME MODEL IO INTEGRITY</a>, #<a href=/goto/modelinputconfidentiality/>MODEL INPUT CONFIDENTIALITY</a>, #<a href=/goto/promptinputvalidation/>PROMPT INPUT VALIDATION</a>, #<a href=/goto/inputsegregation/>INPUT SEGREGATION</a></li><li>Develop incident management procedures:<br>Part of #<a href=/goto/secprogram/>SECURITY PROGRAM</a></li><li>Release AI responsibly:<br>Part of #<a href=/goto/devprogram/>DEVELOPMENT PROGRAM</a></li><li>Make it easy for users to do the right things:<br>Part of #<a href=/goto/secprogram/>SECURITY PROGRAM</a></li></ul><ol start=4><li>Secure operation and maintenance</li></ol><ul><li>Monitor your system’s behaviour:<br>#<a href=/goto/continuousvalidation/>CONTINUOUS VALIDATION</a>, #<a href=/goto/unwantedbiastesting/>UNWANTED BIAS TESTING</a></li><li>Monitor your system’s inputs:<br>#<a href=/goto/monitoruse/>MONITOR USE</a>, #<a href=/goto/detectoddinput/>DETECT ODD INPUT</a>, #<a href=/goto/detectadversarialinput/>DETECT ADVERSARIAL INPUT</a></li><li>Follow a secure by design approach to updates:<br>Part of #<a href=/goto/secdevprogram/>SECURE DEVELOPMENT PROGRAM</a></li><li>Collect and share lessons learned:<br>Part of #<a href=/goto/secprogram/>SECURITY PROGRAM</a> and #<a href=/goto/secdevprogram/>SECURE DEVELOPMENT PROGRAM</a></li></ul><h3>How about copyright?<span class="absolute -mt-20" id=how-about-copyright></span>
<a href=#how-about-copyright class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: discussion<br>Permalink: <a href=https://owaspai.org/goto/copyright/ target=_blank rel=noopener>https://owaspai.org/goto/copyright/</a></p></blockquote><h4>Introduction<span class="absolute -mt-20" id=introduction></span>
<a href=#introduction class=subheading-anchor aria-label="Permalink for this section"></a></h4><p>AI and copyright are two (of many) areas of law and policy, (both public and
private), that raise complex and often unresolved questions. AI output or generated
content is not yet protected by US copyright laws. Many other jurisdictions have yet
to announce any formal status as to intellectual property protections for such
materials. On the other hand, the human contributor who provides the input
content, text, training data, etc. may own a copyright for such materials. Finally, the
usage of certain copyrighted materials in AI training may be considered <a href=https://en.wikipedia.org/wiki/Fair_use target=_blank rel=noopener>fair use</a>.</p><h4>AI & Copyright Security<span class="absolute -mt-20" id=ai--copyright-security></span>
<a href=#ai--copyright-security class=subheading-anchor aria-label="Permalink for this section"></a></h4><p>In AI, companies face a myriad of security threats that could have far-reaching
implications for intellectual property rights, particularly copyrights. As AI systems,
including large data training models, become more sophisticated, they
inadvertently raise the specter of copyright infringement. This is due in part to the
need for development and training of AI models that process vast amounts of data,
which may contain copyright works. In these instances, if copyright works were
inserted into the training data without the permission of the owner, and without
consent of the AI model operator or provider, such a breach could pose significant
financial and reputational risk of infringement of such copyright and corrupt the
entire data set itself.</p><p>The legal challenges surrounding AI are multifaceted. On one hand, there is the
question of whether the use of copyrighted works to train AI models constitutes
infringement, potentially exposing developers to legal claims. On the other hand,
the majority of the industry grapples with the ownership of AI-generated works and
the use of unlicensed content in training data. This legal ambiguity affects all
stakeholders—developers, content creators, and copyright owners alike.</p><h4>Lawsuits Related to AI & Copyright<span class="absolute -mt-20" id=lawsuits-related-to-ai--copyright></span>
<a href=#lawsuits-related-to-ai--copyright class=subheading-anchor aria-label="Permalink for this section"></a></h4><p>Recent lawsuits (writing is April 2024) highlight the urgency of these issues. For instance, a class
action suit filed against Stability AI, Midjourney, and DeviantArt alleges infringement
on the rights of millions of artists by training their tools on web-scraped images2.<br>Similarly, Getty Images’ lawsuit against Stability AI for using images from its catalog
without permission to train an art-generating AI underscores the potential for
copyright disputes to escalate. Imagine the same scenario where a supplier
provides vast quantities of training data for your systems, that has been
compromised by protected work, data sets, or blocks of materials not licensed or
authorized for such use.</p><h4>Copyright of AI-generated source code<span class="absolute -mt-20" id=copyright-of-ai-generated-source-code></span>
<a href=#copyright-of-ai-generated-source-code class=subheading-anchor aria-label="Permalink for this section"></a></h4><p>Source code constitutes a significant intellectual property (IP) asset of a
software development company, as it embodies the innovation and creativity
of its developers. Therefore, source code is subject to IP protection, through
copyrights, patents, and trade secrets. In most cases, human generated
source code carries copyright status as soon as it is produced.</p><p>However, the emergence of AI systems capable of generating source code
without human input poses new challenges for the IP regime. For instance,
who is the author of the AI-generated source code? Who can claim the IP
rights over it? How can AI-generated source code be licensed and exploited
by third parties?</p><p>These questions are not easily resolved, as the current IP legal and
regulatory framework does not adequately address the IP status of AI-
generated works. Furthermore, the AI-generated source code may not be
entirely novel, as it may be derived from existing code or data
sources. Therefore, it is essential to conduct a thorough analysis of the
origin and the process of the AI-generated source code, to determine its IP
implications and ensure the safeguarding of the company&rsquo;s IP assets. Legal
professionals specializing in the field of IP and technology should be
consulted during the process.</p><p>As an example, a recent case still in adjudication shows the complexities of
source code copyrights and licensing filed against GitHub, OpenAI, and
Microsoft by creators of certain code they claim the three entities violated.
More information is available here: <a href=https://www.theregister.com/2024/01/12/github_copilot_copyright_case_narrowed/ target=_blank rel=noopener>: GitHub Copilot copyright case narrowed
but not neutered • The Register</a></p><h4>Copyright damages indemnification<span class="absolute -mt-20" id=copyright-damages-indemnification></span>
<a href=#copyright-damages-indemnification class=subheading-anchor aria-label="Permalink for this section"></a></h4><p>Note that AI vendors have started to take responsibility for copyright issues of their models, under certain circumstances. Microsoft offers users the so-called <a href=https://www.microsoft.com/en-us/licensing/news/microsoft-copilot-copyright-commitment target=_blank rel=noopener>Copilot Copyright Commitment</a>, which indemnifies users from legal damages regarding copyright of code that Copilot has produced - provided <a href=https://learn.microsoft.com/en-us/legal/cognitive-services/openai/customer-copyright-commitment target=_blank rel=noopener>a number of things</a> including that the client has used content filters and other safety systems in Copilot and uses specific services. Google Cloud offers its <a href=https://cloud.google.com/blog/products/ai-machine-learning/protecting-customers-with-generative-ai-indemnification target=_blank rel=noopener>Generative AI indemnification</a>.<br>Read more at <a href=https://www.theverge.com/2023/9/7/23863349/microsoft-ai-assume-responsibility-copyright-lawsuit target=_blank rel=noopener>The Verge on Microsoft indemnification</a> and <a href=https://www.directionsonmicrosoft.com/blog/why-microsofts-copilot-copyright-commitment-may-not-mean-much-for-customers-yet/ target=_blank rel=noopener>Direction Microsoft on the requirements of the indemnification</a>.</p><h4>Do generative AI models really copy existing work?<span class="absolute -mt-20" id=do-generative-ai-models-really-copy-existing-work></span>
<a href=#do-generative-ai-models-really-copy-existing-work class=subheading-anchor aria-label="Permalink for this section"></a></h4><p>Do generative AI models really lookup existing work that may be copyrighted? In essence: no. A Generative AI model does not have sufficient capacity to store all the examples of code or pictures that were in its training set. Instead, during training it extracts patterns about how things work in the data that it sees, and then later, based on those patterns, it generates new content. Parts of this content may show remnants of existing work, but that is more of a coincidence. In essence, a model doesn&rsquo;t recall exact blocks of code, but uses its &lsquo;understanding&rsquo; of coding to create new code. Just like with human beings, this understanding may result in reproducing parts of something you have seen before, but not per se because this was from exact memory. Having said that, this remains a difficult discussion that we also see in the music industry: did a musician come up with a chord sequence because she learned from many songs that this type of sequence works and then coincidentally created something that already existed, or did she copy it exactly from that existing song?</p><h4>Mitigating Risk<span class="absolute -mt-20" id=mitigating-risk></span>
<a href=#mitigating-risk class=subheading-anchor aria-label="Permalink for this section"></a></h4><p>Organizations have several key strategies to mitigate the risk of copyright
infringement in their AI systems. Implementing them early can be much more cost
effective than fixing at later stages of AI system operations. While each comes with
certain financial and operating costs, the “hard savings” may result in a positive
outcome. These may include:</p><ol><li>Taking measures to mitigate the output of certain training data. The OWASP AI Exchange covers this through the corresponding threat: <a href=/goto/disclosureuseoutput/>data disclosure through model output</a>.</li><li>Comprehensive IP Audits: a thorough audit may be used to identify all
intellectual property related to the AI system as a whole. This does not
necessarily apply only to data sets but overall source code, systems,
applications, interfaces and other tech stacks.</li><li>Clear Legal Framework and Policy: development and enforcement of legal
policies and procedures for AI use, which ensure they align with current IP
laws including copyright.</li><li>Ethics in Data Sourcing: source data ethically, ensuring all date used for
training the AI models is either created in-house, or obtained with all
necessary permissions, or is sourced from public domains which provide
sufficient license for the organization’s intended use.</li><li>Define AI-Generated Content Ownership: clearly defined ownership of the
content generated by AI systems, which should include under what conditions
it be used, shared, disseminated.</li><li>Confidentiality and Trade Secret Protocols: strict protocols will help protect
confidentiality of the materials while preserving and maintaining trade secret
status.</li><li>Training for Employees: training employees on the significance and
importance of the organization’s AI IP policies along with implications on what
IP infringement may be will help be more risk averse.</li><li>Compliance Monitoring Systems: an updated and properly utilized monitoring
system will help check against potential infringements by the AI system.</li><li>Response Planning for IP Infringement: an active plan will help respond
quickly and effectively to any potential infringement claims.</li><li>Additional mitigating factors to consider include seeking licenses and/or warranties
from AI suppliers regarding the organization’s intended use, as well as all future uses by the AI system. With the
help of legal counsel the organization should also consider other contractually
binding obligations on suppliers to cover any potential claims of infringement.</li></ol><h4>Helpful resources regarding AI and copyright:<span class="absolute -mt-20" id=helpful-resources-regarding-ai-and-copyright></span>
<a href=#helpful-resources-regarding-ai-and-copyright class=subheading-anchor aria-label="Permalink for this section"></a></h4><ul><li><a href=https://copyrightalliance.org/education/artificial-intelligence-copyright/ target=_blank rel=noopener>Artificial Intelligence (AI) and Copyright | Copyright Alliance</a></li><li><a href=https://dig.watch/updates/ai-industry-faces-threat-of-copyright-law-in-2024 target=_blank rel=noopener>AI industry faces threat of copyright law in 2024 | Digital Watch Observatory</a></li><li><a href=https://www.weforum.org/agenda/2024/01/cracking-the-code-generative-ai-and-intellectual-property/ target=_blank rel=noopener>Using generative AI and protecting against copyright issues | World<br>Economic Forum -weforum.org</a></li><li><a href=https://bipartisanpolicy.org/blog/legal-challenges-against-generative-ai-key-takeaways/ target=_blank rel=noopener>Legal Challenges Against Generative AI: Key Takeaways | Bipartisan<br>Policy Center</a></li><li><a href=https://hbr.org/2023/04/generative-ai-has-an-intellectual-property-problem target=_blank rel=noopener>Generative AI Has an Intellectual Property Problem - hbr.org</a></li><li><a href=https://www.klgates.com/Recent-Trends-in-Generative-Artificial-Intelligence-Litigation-in-the-United-States-9-5-2023 target=_blank rel=noopener>Recent Trends in Generative Artificial Intelligence Litigation in the<br>United States | HUB | K&amp;L Gates - klgates.com</a></li><li><a href=https://www.popsci.com/technology/generative-ai-lawsuits/ target=_blank rel=noopener>Generative AI could face its biggest legal tests in 2024 | Popular<br>Science - popsci.com</a></li><li><a href=https://termly.io/resources/articles/is-ai-model-training-compliant-with-data-privacy-laws/ target=_blank rel=noopener>Is AI Model Training Compliant With Data Privacy Laws? - termly.io</a></li><li><a href="https://techcrunch.com/2023/01/27/the-current-legal-cases-against-generative-ai-are-just-the-beginning/?guccounter=1" target=_blank rel=noopener>The current legal cases against generative AI are just the beginning |<br>TechCrunch</a></li><li><a href=https://www.mintz.com/insights-center/viewpoints/54731/2024-01-10-unfair-use-copyrighted-works-ai-training-data-ai target=_blank rel=noopener>(Un)fair Use? Copyrighted Works as AI Training Data — AI: The<br>Washington Report | Mintz</a></li><li><a href=https://venturebeat.com/ai/potential-supreme-court-clash-looms-over-copyright-issues-in-generative-ai-training-data/ target=_blank rel=noopener>Potential Supreme Court clash looms over copyright issues in<br>generative AI training data | VentureBeat</a></li><li><a href=https://www.fieldfisher.com/en/insights/ai-related-lawsuits-how-the-stable-diffusion-case target=_blank rel=noopener>AI-Related Lawsuits: How The Stable Diffusion Case Could Set a Legal<br>Precedent | Fieldfisher</a></li></ul></div><div class=mt-16></div><div class="mb-8 flex items-center border-t pt-8 dark:border-neutral-800 contrast-more:border-neutral-400 dark:contrast-more:border-neutral-400 print:hidden"><a href=/docs/1_general_controls/ title="1. General controls" class="flex max-w-[50%] items-center gap-1 py-4 text-base font-medium text-gray-600 transition-colors [word-break:break-word] hover:text-primary-600 dark:text-gray-300 md:text-lg ltr:ml-auto ltr:pl-4 ltr:text-right rtl:mr-auto rtl:pr-4 rtl:text-left">1. General controls<svg class="inline h-5 shrink-0" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/></svg></a></div></main></article></div><footer class="hextra-footer bg-gray-100 pb-[env(safe-area-inset-bottom)] dark:bg-neutral-900 print:bg-transparent"><div class="max-w-screen-xl mx-auto flex justify-center py-12 pl-[max(env(safe-area-inset-left),1.5rem)] pr-[max(env(safe-area-inset-right),1.5rem)] text-gray-600 dark:text-gray-400 md:justify-start"><div class="flex w-full flex-col items-center sm:items-start"><div class=font-semibold><a class="flex text-sm items-center gap-1 text-current" target=_blank rel="noopener noreferrer" title="Hextra GitHub Homepage" href=https://github.com/imfing/hextra><span>Powered by Hextra<svg height="1em" class="inline-block ml-1 align-[-2.5px]" viewBox="0 0 180 180" xmlns="http://www.w3.org/2000/svg" fill="currentcolor"><path fill-rule="evenodd" clip-rule="evenodd" d="m105.50024 22.224647c-9.59169-5.537563-21.40871-5.537563-31.000093.0L39.054693 42.689119C29.463353 48.226675 23.55484 58.460531 23.55484 69.535642v40.928918c0 11.07542 5.908513 21.3092 15.499853 26.84652l35.445453 20.46446c9.591313 5.53732 21.408404 5.53732 31.000094.0l35.44507-20.46446c9.59131-5.53732 15.49985-15.7711 15.49985-26.84652V69.535642c0-11.075111-5.90854-21.308967-15.49985-26.846523zM34.112797 85.737639c-1.384445 2.397827-1.384445 5.352099.0 7.749927l24.781554 42.922974c1.38437 2.39783 3.942853 3.87496 6.711592 3.87496h49.563107c2.76905.0 5.3273-1.47713 6.71144-3.87496l24.78194-42.922974c1.38414-2.397828 1.38414-5.3521.0-7.749927L121.88049 42.814746c-1.38414-2.397828-3.94239-3.874964-6.71144-3.874964H65.605944c-2.768739.0-5.327223 1.477059-6.711592 3.874964z" style="stroke-width:.774993"/></svg></span></a></div></div></div></footer></body><script defer src=/js/main.min.5250a01f9a9cabefdb65e77efc7c04221397882cded9c5c058a5504e730b11b3.js integrity="sha256-UlCgH5qcq+/bZed+/HwEIhOXiCze2cXAWKVQTnMLEbM="></script>
<script defer src=/lib/flexsearch/flexsearch.bundle.min.0425860527cc9968f9f049421c7a56b39327d475e2e3a8f550416be3a9134327.js integrity="sha256-BCWGBSfMmWj58ElCHHpWs5Mn1HXi46j1UEFr46kTQyc="></script>
<script defer src=/en.search.min.9afdc7c586c6f971dd94df10b989f10faaf38e5702571fd8cfc9ff9135c2d495.js integrity="sha256-mv3HxYbG+XHdlN8QuYnxD6rzjlcCVx/Yz8n/kTXC1JU="></script></html>