<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><link rel="icon shortcut" href=/favicon.ico sizes=32x32><link rel=icon href=/favicon.svg type=image/svg+xml><link rel=icon href=/favicon-dark.svg type=image/svg+xml media="(prefers-color-scheme: dark)"><link rel=icon href=/favicon-16x16.png type=image/png sizes=16x16><link rel=icon href=/favicon-32x32.png type=image/png sizes=32x32><link rel=apple-touch-icon href=/apple-touch-icon.png sizes=180x180><link fetchpriority=low href=/site.webmanifest rel=manifest><title>3. Development-time threats – AI Exchange</title><meta name=description content="3.0 Development-time threats - Introduction Category: group of development-time threats
Permalink: https://owaspai.org/goto/developmenttime/
This section discusses the AI security threats during the development of the AI system, which includes the engineering environment and the supply chain as attack surfaces.
Background:
Data science (data engineering and model engineering - for machine learning often referred to as training phase) introduces new elements and therefore new attack surface into the engineering environment. Data engineering (collecting, storing, and preparing data) is typically a large and important part of machine learning engineering."><link rel=canonical href=https://owaspai.org/docs/3_development_time_threats/ itemprop=url><meta property="og:title" content="3. Development-time threats – AI Exchange"><meta property="og:description" content="Comprehensive guidance and alignment on how to protect AI against security threats - by professionals, for professionals."><meta property="og:type" content="article"><meta property="og:url" content="https://owaspai.org/docs/3_development_time_threats/"><meta property="og:image" content="https://owaspai.org/images/aix-og-logo.jpg"><meta property="article:section" content="docs"><meta itemprop=name content="3. Development-time threats"><meta itemprop=description content="3.0 Development-time threats - Introduction Category: group of development-time threats
Permalink: https://owaspai.org/goto/developmenttime/
This section discusses the AI security threats during the development of the AI system, which includes the engineering environment and the supply chain as attack surfaces.
Background:
Data science (data engineering and model engineering - for machine learning often referred to as training phase) introduces new elements and therefore new attack surface into the engineering environment. Data engineering (collecting, storing, and preparing data) is typically a large and important part of machine learning engineering."><meta itemprop=wordCount content="6435"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="3. Development-time threats"><meta name=twitter:description content="3.0 Development-time threats - Introduction Category: group of development-time threats
Permalink: https://owaspai.org/goto/developmenttime/
This section discusses the AI security threats during the development of the AI system, which includes the engineering environment and the supply chain as attack surfaces.
Background:
Data science (data engineering and model engineering - for machine learning often referred to as training phase) introduces new elements and therefore new attack surface into the engineering environment. Data engineering (collecting, storing, and preparing data) is typically a large and important part of machine learning engineering."><link rel=preload href=/css/compiled/main.min.5a06ca26e024c4f511f45ee6c33a2a1faefaebe6be8a38d36e100f40a4c59c06.css as=style integrity="sha256-WgbKJuAkxPUR9F7mwzoqH6766+a+ijjTbhAPQKTFnAY="><link href=/css/compiled/main.min.5a06ca26e024c4f511f45ee6c33a2a1faefaebe6be8a38d36e100f40a4c59c06.css rel=stylesheet integrity="sha256-WgbKJuAkxPUR9F7mwzoqH6766+a+ijjTbhAPQKTFnAY="><link href=/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css rel=stylesheet integrity="sha256-47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU="><link rel=preconnect href=https://www.googletagmanager.com crossorigin><script async src="https://www.googletagmanager.com/gtag/js?id=G-QPGVTTDD3R"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QPGVTTDD3R")</script><script>const defaultTheme="system",setDarkTheme=()=>{document.documentElement.classList.add("dark"),document.documentElement.style.colorScheme="dark"},setLightTheme=()=>{document.documentElement.classList.remove("dark"),document.documentElement.style.colorScheme="light"};"color-theme"in localStorage?localStorage.getItem("color-theme")==="dark"?setDarkTheme():setLightTheme():(defaultTheme==="dark"?setDarkTheme():setLightTheme(),defaultTheme==="system"&&(window.matchMedia("(prefers-color-scheme: dark)").matches?setDarkTheme():setLightTheme()))</script></head><body dir=ltr><div class="nav-container sticky top-0 z-20 w-full bg-transparent print:hidden"><div class="nav-container-blur pointer-events-none absolute z-[-1] h-full w-full bg-white dark:bg-dark shadow-[0_2px_4px_rgba(0,0,0,.02),0_1px_0_rgba(0,0,0,.06)] contrast-more:shadow-[0_0_0_1px_#000] dark:shadow-[0_-1px_0_rgba(255,255,255,.1)_inset] contrast-more:dark:shadow-[0_0_0_1px_#fff]"></div><nav class="mx-auto flex items-center justify-end gap-2 h-16 px-6 max-w-[90rem]"><a class="flex items-center hover:opacity-75 ltr:mr-auto rtl:ml-auto" href=/><img class="block dark:hidden" src=/images/owasp-logo.svg alt="AI Exchange" height=30 width=30>
<img class="hidden dark:block" src=/images/owasp-logo-dark.svg alt="AI Exchange" height=30 width=30>
<span class="mx-2 font-extrabold inline select-none" title="AI Exchange">AI Exchange</span>
</a><a title=Home href=/ class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Home</span>
</a><a title=Overview href=/docs/ai_security_overview class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Overview</span>
</a><a title=Media href=/media class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Media</span>
</a><a title=Meetings href=/meetings class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Meetings</span>
</a><a title=Contribute href=/contribute class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Contribute</span>
</a><a title=Connect href=/connect class="text-sm contrast-more:text-gray-700 contrast-more:dark:text-gray-100 relative -ml-2 hidden whitespace-nowrap p-2 md:inline-block text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200"><span class=text-center>Connect</span></a><div class="search-wrapper relative md:w-64"><div class="relative flex items-center text-gray-900 contrast-more:text-gray-800 dark:text-gray-300 contrast-more:dark:text-gray-300"><input placeholder=Search... class="search-input block w-full appearance-none rounded-lg px-3 py-2 transition-colors text-base leading-tight md:text-sm bg-black/[.05] dark:bg-gray-50/10 focus:bg-white dark:focus:bg-dark placeholder:text-gray-500 dark:placeholder:text-gray-400 contrast-more:border contrast-more:border-current" type=search spellcheck=false>
<kbd class="absolute my-1.5 select-none ltr:right-1.5 rtl:left-1.5 h-5 rounded bg-white px-1.5 font-mono text-[10px] font-medium text-gray-500 border dark:border-gray-100/20 dark:bg-dark/50 contrast-more:border-current contrast-more:text-current contrast-more:dark:border-current items-center gap-1 transition-opacity pointer-events-none hidden sm:flex">CTRL K</kbd></div><div><ul class="search-results hextra-scrollbar hidden border border-gray-200 bg-white text-gray-100 dark:border-neutral-800 dark:bg-neutral-900 absolute top-full z-20 mt-2 overflow-auto overscroll-contain rounded-xl py-2.5 shadow-xl max-h-[min(calc(50vh-11rem-env(safe-area-inset-bottom)),400px)] md:max-h-[min(calc(100vh-5rem-env(safe-area-inset-bottom)),400px)] inset-x-0 ltr:md:left-auto rtl:md:right-auto contrast-more:border contrast-more:border-gray-900 contrast-more:dark:border-gray-50 w-screen min-h-[100px] max-w-[min(calc(100vw-2rem),calc(100%+20rem))]" style="transition:max-height .2s ease 0s"></ul></div></div><a class="p-2 text-current" target=_blank rel=noreferer href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide title=GitHub><svg height="24" fill="currentcolor" viewBox="3 3 18 18"><path d="M12 3C7.0275 3 3 7.12937 3 12.2276c0 4.0833 2.57625 7.5321 6.15374 8.7548C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441 9.77249 20.3249 9.76125 19.5982 9.76125 18.8254 7.5 19.2522 6.915 18.2602 6.735 17.7412 6.63375 17.4759 6.19499 16.6569 5.8125 16.4378 5.4975 16.2647 5.0475 15.838 5.80124 15.8264 6.51 15.8149 7.01625 16.4954 7.18499 16.7723 7.99499 18.1679 9.28875 17.7758 9.80625 17.5335 9.885 16.9337 10.1212 16.53 10.38 16.2993 8.3775 16.0687 6.285 15.2728 6.285 11.7432c0-1.0035.34875-1.834.92249-2.47994C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794c0 0 .753749999999999-.24223 2.47499.94583.72001-.20762 1.48501-.31143 2.25001-.31143C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377c1.7212-1.19959 2.475-.94583 2.475-.94583C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326 17.4113 9.9092 17.76 10.7281 17.76 11.7432c0 3.5411-2.1037 4.3255-4.1063 4.5561C13.98 16.5877 14.2613 17.1414 14.2613 18.0065 14.2613 19.2407 14.25 20.2326 14.25 20.5441 14.25 20.7863 14.4188 21.0746 14.8688 20.9824 16.6554 20.364 18.2079 19.1866 19.3078 17.6162c1.0999-1.5705 1.6917-3.4551 1.6922-5.3886C21 7.12937 16.9725 3 12 3z"/></svg><span class=sr-only>GitHub</span>
</a><button type=button aria-label=Menu class="hamburger-menu -mr-2 rounded p-2 active:bg-gray-400/20 md:hidden"><svg height="24" fill="none" viewBox="0 0 24 24" stroke="currentcolor"><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 8H20"/></g><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16H20"/></g></svg></button></nav></div><div class='mx-auto flex max-w-[90rem]'><div class="mobile-menu-overlay [transition:background-color_1.5s_ease] fixed inset-0 z-10 bg-black/80 dark:bg-black/60 hidden"></div><aside class="sidebar-container flex flex-col print:hidden md:top-16 md:shrink-0 md:w-64 md:self-start max-md:[transform:translate3d(0,-100%,0)] md:sticky"><div class="px-4 pt-4 md:hidden"><div class="search-wrapper relative md:w-64"><div class="relative flex items-center text-gray-900 contrast-more:text-gray-800 dark:text-gray-300 contrast-more:dark:text-gray-300"><input placeholder=Search... class="search-input block w-full appearance-none rounded-lg px-3 py-2 transition-colors text-base leading-tight md:text-sm bg-black/[.05] dark:bg-gray-50/10 focus:bg-white dark:focus:bg-dark placeholder:text-gray-500 dark:placeholder:text-gray-400 contrast-more:border contrast-more:border-current" type=search spellcheck=false>
<kbd class="absolute my-1.5 select-none ltr:right-1.5 rtl:left-1.5 h-5 rounded bg-white px-1.5 font-mono text-[10px] font-medium text-gray-500 border dark:border-gray-100/20 dark:bg-dark/50 contrast-more:border-current contrast-more:text-current contrast-more:dark:border-current items-center gap-1 transition-opacity pointer-events-none hidden sm:flex">CTRL K</kbd></div><div><ul class="search-results hextra-scrollbar hidden border border-gray-200 bg-white text-gray-100 dark:border-neutral-800 dark:bg-neutral-900 absolute top-full z-20 mt-2 overflow-auto overscroll-contain rounded-xl py-2.5 shadow-xl max-h-[min(calc(50vh-11rem-env(safe-area-inset-bottom)),400px)] md:max-h-[min(calc(100vh-5rem-env(safe-area-inset-bottom)),400px)] inset-x-0 ltr:md:left-auto rtl:md:right-auto contrast-more:border contrast-more:border-gray-900 contrast-more:dark:border-gray-50 w-screen min-h-[100px] max-w-[min(calc(100vw-2rem),calc(100%+20rem))]" style="transition:max-height .2s ease 0s"></ul></div></div></div><div class="hextra-scrollbar overflow-y-auto overflow-x-hidden p-4 grow md:h-[calc(100vh-var(--navbar-height)-var(--menu-height))]"><ul class="flex flex-col gap-1 md:hidden"><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/meetings/></a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/charter/>AI Exchange Charter</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/connect/>Connect with us</a></li><li class=open><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/>Content
<span class=hextra-sidebar-collapsible-button><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class='relative flex flex-col gap-1 before:absolute before:inset-y-1 before:w-px before:bg-gray-200 before:content-[""] ltr:ml-3 ltr:pl-3 ltr:before:left-0 rtl:mr-3 rtl:pr-3 rtl:before:right-0 dark:before:bg-neutral-800'><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/ai_security_overview/>0. AI Security Overview</a></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/1_general_controls/>1. General controls</a></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/2_threats_through_use/>2. Threats through use</a></li><li class="flex flex-col open"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
sidebar-active-item bg-primary-100 font-semibold text-primary-800 contrast-more:border contrast-more:border-primary-500 dark:bg-primary-400/10 dark:text-primary-600 contrast-more:dark:border-primary-500" href=/docs/3_development_time_threats/>3. Development-time threats</a><ul class='flex flex-col gap-1 relative before:absolute before:inset-y-1 before:w-px before:bg-gray-200 before:content-[""] dark:before:bg-neutral-800 ltr:pl-3 ltr:before:left-0 rtl:pr-3 rtl:before:right-0 ltr:ml-3 rtl:mr-3'><li><a href=#30-development-time-threats---introduction class="flex rounded px-2 py-1.5 text-sm transition-colors [word-break:break-word] cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:border gap-2 before:opacity-25 before:content-['#'] text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:text-gray-900 contrast-more:dark:text-gray-50 contrast-more:border-transparent contrast-more:hover:border-gray-900 contrast-more:dark:hover:border-gray-50">3.0 Development-time threats - Introduction</a></li><li><a href=#31-broad-model-poisoning-development-time class="flex rounded px-2 py-1.5 text-sm transition-colors [word-break:break-word] cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:border gap-2 before:opacity-25 before:content-['#'] text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:text-gray-900 contrast-more:dark:text-gray-50 contrast-more:border-transparent contrast-more:hover:border-gray-900 contrast-more:dark:hover:border-gray-50">3.1. Broad model poisoning development-time</a></li><li><a href=#32-sensitive-data-leak-development-time class="flex rounded px-2 py-1.5 text-sm transition-colors [word-break:break-word] cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:border gap-2 before:opacity-25 before:content-['#'] text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:text-gray-900 contrast-more:dark:text-gray-50 contrast-more:border-transparent contrast-more:hover:border-gray-900 contrast-more:dark:hover:border-gray-50">3.2. Sensitive data leak development-time</a></li></ul></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/4_runtime_application_security_threats/>4. Runtime application security threats</a></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/5_testing/>5. AI security testing</a></li><li class="flex flex-col"><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/ai_security_references/>AI Security References</a></li></ul></div></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/contribute/>Contribute to the OWASP AI Exchange</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/media/>Media</a></li><li class="[word-break:break-word] mt-5 mb-2 px-2 py-1.5 text-sm font-semibold text-gray-900 first:mt-0 dark:text-gray-100"><span class=cursor-default>More</span></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/>Home</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/connect/>Connect with us</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/contribute/>Contribute</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/media/>Media</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/meetings/>Meetings</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=https://forms.gle/XwEEK52y4iZQChuJ6 target=_blank rel=noreferer>Register</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide/raw/main/assets/images/owaspaioverviewpdfv3.pdf target=_blank rel=noreferer>Navigator</a></li></ul><ul class="flex flex-col gap-1 max-md:hidden"><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/ai_security_overview/>0. AI Security Overview</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/1_general_controls/>1. General controls</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/2_threats_through_use/>2. Threats through use</a></li><li class=open><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
sidebar-active-item bg-primary-100 font-semibold text-primary-800 contrast-more:border contrast-more:border-primary-500 dark:bg-primary-400/10 dark:text-primary-600 contrast-more:dark:border-primary-500" href=/docs/3_development_time_threats/>3. Development-time threats</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/4_runtime_application_security_threats/>4. Runtime application security threats</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/5_testing/>5. AI security testing</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/docs/ai_security_references/>AI Security References</a></li><li class="[word-break:break-word] mt-5 mb-2 px-2 py-1.5 text-sm font-semibold text-gray-900 first:mt-0 dark:text-gray-100"><span class=cursor-default>More</span></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/>Home</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/connect/>Connect with us</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/contribute/>Contribute</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/media/>Media</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=/meetings/>Meetings</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=https://forms.gle/XwEEK52y4iZQChuJ6 target=_blank rel=noreferer>Register</a></li><li><a class="flex items-center justify-between gap-2 cursor-pointer rounded px-2 py-1.5 text-sm transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
text-gray-500 hover:bg-gray-100 hover:text-gray-900 contrast-more:border contrast-more:border-transparent contrast-more:text-gray-900 contrast-more:hover:border-gray-900 dark:text-neutral-400 dark:hover:bg-primary-100/5 dark:hover:text-gray-50 contrast-more:dark:text-gray-50 contrast-more:dark:hover:border-gray-50" href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide/raw/main/assets/images/owaspaioverviewpdfv3.pdf target=_blank rel=noreferer>Navigator</a></li></ul></div><div class="sticky bottom-0 bg-white dark:bg-dark mx-4 py-4 shadow-[0_-12px_16px_#fff] flex items-center gap-2 dark:border-neutral-800 dark:shadow-[0_-12px_16px_#111] contrast-more:border-neutral-400 contrast-more:shadow-none contrast-more:dark:shadow-none border-t" data-toggle-animation=show><div class="flex grow flex-col"><button title="Change theme" data-theme=light class="theme-toggle group h-7 rounded-md px-2 text-left text-xs font-medium text-gray-600 transition-colors dark:text-gray-400 hover:bg-gray-100 hover:text-gray-900 dark:hover:bg-primary-100/5 dark:hover:text-gray-50" type=button aria-label="Change theme"><div class="flex items-center gap-2 capitalize"><svg height="12" class="group-data-[theme=light]:hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span class="group-data-[theme=light]:hidden">Light</span><svg height="12" class="group-data-[theme=dark]:hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg><span class="group-data-[theme=dark]:hidden">Dark</span></div></button></div></div></aside><nav class="hextra-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents"><div class="hextra-scrollbar sticky top-16 overflow-y-auto pr-4 pt-6 text-sm [hyphens:auto] max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] ltr:-mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">On this page</p><ul><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#30-development-time-threats---introduction>3.0 Development-time threats - Introduction</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#devdataprotect>#DEVDATAPROTECT</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#devsecurity>#DEVSECURITY</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#segregatedata>#SEGREGATEDATA</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#confcompute>#CONFCOMPUTE</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#federatedlearning>#FEDERATEDLEARNING</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#supplychainmanage>#SUPPLYCHAINMANAGE</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#31-broad-model-poisoning-development-time>3.1. Broad model poisoning development-time</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#modelensemble>#MODELENSEMBLE</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#311-data-poisoning>3.1.1. Data poisoning</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#moretraindata>#MORETRAINDATA</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#dataqualitycontrol>#DATAQUALITYCONTROL</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#traindatadistortion>#TRAINDATADISTORTION</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#poisonrobustmodel>#POISONROBUSTMODEL</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#trainadversarial>#TRAINADVERSARIAL</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#312-development-environment-model-poisoning>3.1.2. Development-environment model poisoning</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#313-supply-chain-model-poisoning>3.1.3 Supply-chain model poisoning</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#32-sensitive-data-leak-development-time>3.2. Sensitive data leak development-time</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#321-development-time-data-leak>3.2.1. Development-time data leak</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#322-model-theft-through-development-time-model-parameter-leak>3.2.2. Model theft through development-time model parameter leak</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="ltr:pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 contrast-more:text-gray-900 contrast-more:underline contrast-more:dark:text-gray-50 w-full break-words" href=#323-source-codeconfiguration-leak>3.2.3. Source code/configuration leak</a></li></ul><div class="mt-8 border-t bg-white pt-8 shadow-[0_-12px_16px_white] dark:bg-dark dark:shadow-[0_-12px_16px_#111] sticky bottom-0 flex flex-col items-start gap-2 pb-8 dark:border-neutral-800 contrast-more:border-t contrast-more:border-neutral-400 contrast-more:shadow-none contrast-more:dark:border-neutral-400"><a class="text-xs font-medium text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-100 contrast-more:text-gray-800 contrast-more:dark:text-gray-50" href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide/blob/main/content/ai_exchange/content/docs/3_development_time_threats.md target=_blank rel=noreferer>Edit this page on GitHub →</a>
<button aria-hidden=true id=backToTop onclick=scrollUp() class="transition-all transition duration-75 opacity-0 text-xs font-medium text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-100 contrast-more:text-gray-800 contrast-more:dark:text-gray-50">
<span>Scroll to top</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" class="inline ml-1 h-3.5 w-3.5 border rounded-full border-gray-500 hover:border-gray-900 dark:border-gray-400 dark:hover:border-gray-100 contrast-more:border-gray-800 contrast-more:dark:border-gray-50"><path stroke-linecap="round" stroke-linejoin="round" d="M4.5 15.75l7.5-7.5 7.5 7.5"/></svg></button></div></div></nav><article class="w-full break-words flex min-h-[calc(100vh-var(--navbar-height))] min-w-0 justify-center pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12"><div class="mt-1.5 flex items-center gap-1 overflow-hidden text-sm text-gray-500 dark:text-gray-400 contrast-more:text-current"><div class="whitespace-nowrap transition-colors min-w-[24px] overflow-hidden text-ellipsis hover:text-gray-900 dark:hover:text-gray-100"><a href=https://owaspai.org/docs/>Content</a></div><svg class="w-3.5 shrink-0" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/></svg><div class="whitespace-nowrap transition-colors font-medium text-gray-700 contrast-more:font-bold contrast-more:text-current dark:text-gray-100 contrast-more:dark:text-current">3. Development-time threats</div></div><div class=content><h1>3. Development-time threats</h1><h2>3.0 Development-time threats - Introduction<span class="absolute -mt-20" id=30-development-time-threats---introduction></span>
<a href=#30-development-time-threats---introduction class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: group of development-time threats<br>Permalink: <a href=https://owaspai.org/goto/developmenttime/ target=_blank rel=noopener>https://owaspai.org/goto/developmenttime/</a></p></blockquote><p>This section discusses the AI security threats during the development of the AI system, which includes the engineering environment and the supply chain as attack surfaces.</p><p><strong>Background:</strong></p><p>Data science (data engineering and model engineering - for machine learning often referred to as <em>training phase</em>) introduces new elements and therefore new attack surface into the engineering environment. Data engineering (collecting, storing, and preparing data) is typically a large and important part of machine learning engineering. Together with model engineering, it requires appropriate security to protect against data leaks, data poisoning, leaks of intellectual property, and supply chain attacks (see further below). In addition, data quality assurance can help reduce risks of intended and unintended data issues.</p><p><strong>Particularities:</strong></p><ul><li>Particularity 1: the data in the AI development environment is real data that is typically sensitive, because it is needed to train the model and that obviously needs to happen on real data, instead of fake data that you typically see in standard development environment situations (e.g. for testing). Therefore, data protection activities need to be extended from the live system to the development environment.</li><li>Particularity 2: elements in the AI development environment (data, code, configuration & parameters) require extra protection as they are prone to attacks to manipulate model behaviour (called <em>poisoning</em>)</li><li>Particularity 3: source code, configuration, and parameters are typically critical intellectual property in AI</li><li>Particularity 4: the supply chain for AI systems introduces two new elements: data and models</li><li>Particularity 5: external software components may run within the engineering environments, for example to train models, introducing a new threat of malicious components gaining access to assets in that environment (e.g. to poison training data)</li></ul><p>ISO/IEC 42001 B.7.2 briefly mentions development-time data security risks.</p><p><strong>Controls for development-time protection:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a></li><li>The below control(s), each marked with a # and a short name in capitals</li></ul><h4>#DEVDATAPROTECT<span class="absolute -mt-20" id=devdataprotect></span>
<a href=#devdataprotect class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: information security control<br>Permalink: <a href=https://owaspai.org/goto/devdataprotect/ target=_blank rel=noopener>https://owaspai.org/goto/devdataprotect/</a></p></blockquote><p>This control has been integrated with <a href=/goto/devsecurity/>#DEVSECURITY</a>.</p><h4>#DEVSECURITY<span class="absolute -mt-20" id=devsecurity></span>
<a href=#devsecurity class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time information security control<br>Permalink: <a href=https://owaspai.org/goto/devsecurity/ target=_blank rel=noopener>https://owaspai.org/goto/devsecurity/</a></p></blockquote><p>Development security: appropriate security of the AI development infrastructure, also taking into account the sensitive information that is typical to AI: training data, test data, model parameters and technical documentation.</p><p><strong>How:</strong> This can be achieved by adding said assets to the existing security management system. Security involves for example encryption, screening of development personnel, protection of source code/configuration, virus scanning on engineering machines.</p><p><strong>Importance</strong>: In case said assets leak, it hurts confidentiality of intellectual property and/or the confidentiality of train/test data which may contain company secrets, or personal data for example. Also the integrity of this data is important to protect, to prevent data or model poisoning.</p><p><strong>Risks external to the development environment</strong></p><p>Data and models may have been obtained externally, just like software components. Furthermore, software components often run within the AI development environment, introducing new risks, especially given that sensitive data is present in this environment. For details, see <a href=/goto/supplychainmanage/>SUPPLYCHAINMANAGE</a>.</p><p>Training data is in most cases only present during development-time, but there are exceptions:</p><ul><li>A machine learning model may be continuously trained with data collected runtime, which puts (part of the) train data in the runtime environment, where it also needs protection - as covered in this control section</li><li>For GenAI, information can be retrieved from a repository to be added to a prompt, for example to inform a large language model about the context to take into account for an instruction or question. This principle is called <em>in-context learning</em>. For example <a href=https://opencre.org/chatbot target=_blank rel=noopener>OpenCRE-chat</a> uses a repository of requirements from security standards to add to a user question so that the large language model is more informed with background information. In the case of OpenCRE-chat this information is public, but in many cases the application of this so-called Retrieval Augmented Generation (RAG) will have a repository with company secrets or otherwise sensitive data. Organizations can benefit from unlocking their unique data, to be used by themselves, or to be provided as service or product. This is an attractive architecture because the alternative would be to train an LLM or to finetune it, which is expensive and difficult. A RAG approach may suffice. Effectively, this puts the repository data to the same use as training data is used: control the behaviour of the model. Therefore, the security controls that apply to train data, also apply to this run-time repository data.</li></ul><p><strong>Details on the how: protection strategies:</strong></p><ul><li>Encryption of data at rest<br>Useful standards include:<ul><li>ISO 27002 control 5.33 Protection of records. Gap: covers this control fully, with the particularities</li><li><a href=https://www.opencre.org/cre/400-007 target=_blank rel=noopener>OpenCE on encryption of data at rest</a></li></ul></li><li>Technical access control for the data, to limit access following the least privilege principle<br>Useful standards include:<ul><li>ISO 27002 Controls 5.15, 5.16, 5.18, 5.3, 8.3. Gap: covers this control fully, with the particularities</li><li><a href=https://www.opencre.org/cre/724-770 target=_blank rel=noopener>OpenCRE</a></li><li>Centralized access control for the data<br>Useful standards include:</li><li>There is no ISO 27002 control for this</li><li><a href=https://www.opencre.org/cre/117-371 target=_blank rel=noopener>OpenCRE</a></li></ul></li><li>Operational security to protect stored data<br>One control to increase development security is to segregate the environment, see <a href=/goto/segregatedata/>SEGREGATEDATA</a>.<br>Useful standards include:<ul><li>Many ISO 27002 controls cover operational security. Gap: covers this control fully, with the particularities.<ul><li>ISO 27002 control 5.23 Information security for use of cloud services</li><li>ISO 27002 control 5.37 Documented operating procedures</li><li>Many more ISO 27002 controls (See OpenCRE link)</li></ul></li><li><a href=https://www.opencre.org/cre/862-452 target=_blank rel=noopener>OpenCRE</a></li></ul></li><li>Logging and monitoring to detect suspicious manipulation of data, (e.g. outside office hours)<br>Useful standards include:<ul><li>ISO 27002 control 8.16 Monitoring activities. Gap: covers this control fully</li><li><a href=https://www.opencre.org/cre/887-750 target=_blank rel=noopener>OpenCRE on Detect and respond</a></li></ul></li><li>Integrity checking: see section below</li></ul><p><strong>Integrity checking</strong></p><p>Part of development security is checking the integrity of assets. These assets include train/test/validation data, models/model parameters, source code and binairies.</p><p>Integrity checks can be performed at various stages including build, deploy, and supply chain management. The integration of these checks helps mitigate risks associated with tampering: unauthorized modifications and mistakes.</p><p>Integrity Checks - Build Stage<br>During the build stage, it is crucial to validate the integrity of the source code and dependencies to ensure that no unauthorized changes have been introduced. Techniques include:</p><ul><li>Source Code Verification: Implementing code signing and checksums to verify the integrity of the source code. This ensures that the code has not been tampered with.</li><li>Dependency Management: Regularly auditing and updating third-party libraries and dependencies to avoid vulnerabilities. Use tools like Software Composition Analysis (SCA) to automate this process. See <a href=/goto/supplychainmanage/>#SUPPLYCHAINMANAGE</a>.</li><li>Automated Testing: Employing continuous integration (CI) pipelines with automated tests to detect issues early in the development cycle. This includes unit tests, integration tests, and security tests.</li></ul><p>Example: A software company using CI pipelines can integrate automated security tools to scan for vulnerabilities in the codebase and dependencies, ensuring that only secure and verified code progresses through the pipeline.</p><p>Integrity Checks - Deploy Stage<br>The deployment stage requires careful management to ensure that the AI models and supporting infrastructure are securely deployed and configured. Key practices include:</p><ul><li>Environment Configuration: Ensuring that deployment environments are securely configured and consistent with security policies. This includes the use of Infrastructure as Code (IaC) tools to maintain configuration integrity.</li><li>Secure Deployment Practices: Implementing deployment automation to minimize human error and enforce consistency. Use deployment tools that support rollback capabilities to recover from failed deployments.</li><li>Runtime Integrity Monitoring: Continuously monitoring the deployed environment for integrity violations. Tools like runtime application self-protection (RASP) can provide real-time protection and alert on suspicious activities.</li></ul><p>Example: A cloud-based AI service provider can use IaC tools to automate the deployment of secure environments and continuously monitor for configuration drifts or unauthorized changes.</p><p>Supply Chain Management<br>Managing the AI supply chain involves securing the components and processes involved in developing and deploying AI systems. This includes:</p><ul><li>Component Authenticity: Using cryptographic signatures to verify the authenticity and integrity of components received from suppliers. This prevents the introduction of malicious components into the system.</li><li>For more details, see <a href=/goto/supplychainmanage/>#SUPPLYCHAINMANAGE</a></li></ul><p>Example: An organization using pre-trained AI models from external vendors can require those vendors to provide cryptographic signatures for model files and detailed security assessments, ensuring the integrity and security of these models before integration.</p><p>A significant step forward for provable machine learning model provenance is the <strong>cryptographic signing of models</strong>, similar in concept to how we secure HTTP traffic using Secure Socket Layer (SSL) or Portable Executable (PE) files with Authenticode. However, there is one key difference: models encompass a number of associated artifacts of varying file formats rather than a single homogenous file, and so the approach must differ.
As mentioned, models comprise code and data but often require additional information able to execute correctly, such as tokenizers, vocab files, configs, and inference code. These are used to initialize the model so it’s ready to accept data and perform its task. To comprehensively verify a model&rsquo;s integrity, all of these factors must be considered when assessing illicit tampering or manipulation of the model, as any change made to a file that is required for the model to run may introduce a malicious action or degradation of performance to the model. While no standard yet exists to tackle this, there is ongoing work by the OpenSSF Model Signing SIG to define a specification and drive industry adoption. As this is unfolding, there may be interplay with ML-BOM and AI-BOM to be codified into the certificate. Signing and verification will become a major part of the ML ecosystem as it has with many other practices, and guidance will be available following an agreed-upon open-source specification.</p><p>The data a model consumes is the most influential part of the MLOps lifecycle and should be treated as such. Data is more often than not sourced from third parties via the internet or gathered on internal data for later training by the model, but can the integrity of the data be assured?</p><p>Often, datasets may not just be a collection of text or images but may be comprised of pointers to other pieces of data rather than the data itself. One such dataset is the LAOIN-400m, where pointers to images are stored as URLs - however, data stored at a URL is not permanent and may be subject to manipulation or removal of the content. As such having a level of indirection can introduce integrity issues and leave oneself vulnerable to data poisoning, as was shown by Carlini et al in their paper ‘Poisoning Web-Scale Datasets is practical’. For more information, see the <a href=/goto/datapoison/>data poisoning section</a>.
Verification of dataset entries through hashing is of the utmost importance so as to reduce the capacity for tampering, corruption, or potential for data poisoning.</p><p><strong>Useful standards include:</strong></p><ul><li>ISO 27001 Information Security Management System does not cover development-environment security explicitly. Nevertheless, the information security management system is designed to take care of it, provided that the relevant assets and their threats are taken into account. Therefore it is important to add train/test/validation data, model parameters and technical documentation to the existing development environment asset list.</li></ul><h4>#SEGREGATEDATA<span class="absolute -mt-20" id=segregatedata></span>
<a href=#segregatedata class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time information security control<br>Permalink: <a href=https://owaspai.org/goto/segregatedata/ target=_blank rel=noopener>https://owaspai.org/goto/segregatedata/</a></p></blockquote><p>Segregate data: store sensitive development data (training or test data, model parameters, technical documentation) in a separated areas with restricted access. Each separate area can then be hardened accordingly and access granted to only those that need to work with that data directly.</p><p>Examples of areas in which training data can be segregated:</p><ol><li>External - for when training data is obtained externally</li><li>Application development environment: for application engineers that perhaps need to work with the actual training data, but require different access rights (e.g. don&rsquo;t need to change it)</li><li>Data engineering environment: for engineers collecting and processing the data.</li><li>Training environment: for engineers training the model with the processed data. In this area, controls can be applied against risks that involve access to the other less-protected development areas. That way, for example data poisoning can be mitigated.</li><li>Operational environment - for when training data is collected in operation</li></ol><p>For more development environment security, see <a href=/goto/devsecurity/>DEVSECURITY</a>.</p><p>Useful standards include:</p><ul><li>ISO 27002 control 8.31 Separation of development, test and production environments. Gap: covers this control partly - the particularity is that the development environment typically has the sensitive data instead of the production environment - which is typically the other way around in non-AI systems. Therefore it helps to restrict access to that data within the development environment. Even more: within the development environment further segregation can take place to limit access to only those who need the data for their work, as some developers will not be processing data.</li><li>See the &lsquo;How&rsquo; section above for further standard references</li></ul><h4>#CONFCOMPUTE<span class="absolute -mt-20" id=confcompute></span>
<a href=#confcompute class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time information security control<br>Permalink: <a href=https://owaspai.org/goto/confcompute/ target=_blank rel=noopener>https://owaspai.org/goto/confcompute/</a></p></blockquote><p>Confidential compute: If available and possible, use features of the data science execution environment to hide training data and model parameters from model engineers - even while it is in use.</p><p>Useful standards include:</p><ul><li>Not covered yet in ISO/IEC standards</li></ul><h4>#FEDERATEDLEARNING<span class="absolute -mt-20" id=federatedlearning></span>
<a href=#federatedlearning class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time data science control<br>Permalink: <a href=https://owaspai.org/goto/federatedlearning/ target=_blank rel=noopener>https://owaspai.org/goto/federatedlearning/</a></p></blockquote><p>Federated learning can be applied when a training set is distributed over different organizations, preventing that the data needs to be collected in a central place - increasing the risk of leaking.</p><p>Federated Learning is a decentralized Machine Learning architecture wherein a number of clients (e.g. sensor or mobile devices) participate in collaborative, decentralized, asynchronous training, which is orchestrated and aggregated by a controlling central server. Advantages of Federated Learning include reduced central compute, and the potential for preservation of privacy, since training data may remain local to the client.</p><p>Broadly, Federated Learning generally consists of four high-level steps: First, there is a server-to-client broadcast; next, local models are updated on the client; once trained, local models are then returned to the central server; and finally, the central server updates via model aggregation.</p><p><strong>Federated machine learning benefits & use cases</strong><br>Federated machine learning may offer significant benefits for organizations in several domains, including regulatory compliance, enhanced privacy, scalability and bandwidth, and other user/client considerations.</p><ul><li><strong>Regulatory compliance</strong>. In federated machine learning, data collection is decentralized, which may allow for greater ease of regulatory compliance. Decentralization of data may be especially beneficial for international organizations, where data transfer across borders may be unlawful.</li><li><strong>Enhanced confidentiality</strong>. Federated learning can provide enhanced confidentiality, as data does not leave the client, minimizing the potential for exposure of sensitive information.</li><li><strong>Scalability & bandwidth</strong>. Decreased training data transfer between client devices and central server may provide significant benefits for organizations where data transfer costs are high. Similarly, federation may provide advantages in resource-constrained environments where bandwidth considerations might otherwise limit data uptake and/or availability for modeling. Further, because federated learning optimizes network resources, these benefits may on aggregate allow for overall greater capacity & flexible scalability.</li><li><strong>Data diversity</strong>. Because federated learning relies on a plurality of models to aggregate an update to the central model, it may provide benefits in data & model diversity. The ability to operate efficiently in resource-constrained environments may further allow for increases in heterogeneity of client devices, further increasing the diversity of available data.</li></ul><p><strong>Challenges in federated machine learning</strong></p><ul><li><strong>Remaining risk of data disclosure by the model</strong>. Care must be taken to protect against <em>data disclosure by use</em> threats (e.g. membership inference), as sensitive data may still be extracted from the model/models. Therefore, <em>model theft</em> threats also need mitigation, as training data may be disclosed from a stolen model. The federated learning architecture has specific attack surfaces for <em>model theft</em> in the form of transfering the model from client to server and storage of the model at the server. These require protection.</li><li><strong>More attack surface for poisoning</strong>. Security concerns also include attacks via data/model poisoning; with federated systems additionally introducing a vast network of clients, some of which may be malicious.</li><li><strong>Device Heterogeneity</strong>. User- or other devices may vary widely in their computational, storage, transmission, or other capabilities, presenting challenges for federated deployments. These may additionally introduce device-specific security concerns, which practitioners should take into consideration in design phases. While designing for constraints including connectivity, battery life, and compute, it is also critical to consider edge device security.</li><li><strong>Broadcast Latency & Security</strong>. Efficient communication across a federated network introduces additional challenges. While strategies exist to minimize broadcast phase latency, they must also take into consideration potential data security risks. Because models are vulnerable during transmission phases, any communication optimizations must account for data security in transit.</li><li><strong>Querying the data creates a risk</strong>. When collected data is stored on multiple clients, central data queries may be required for analysis work, next to Federated learning. Such queries would need the server to have access to the data at all clients, creating a security risk. In order to analyse the data without collecting it, various Privacy-preserving techniques exist, including cryptographic and information-theoretic strategies, such as Secure Function Evaluation (SFE), also known as Secure Multi-Party Computation (SMC/SMPC). However, all approaches entail tradeoffs between privacy and utility.</li></ul><p>References:</p><ul><li>Yang, Qiang, Yang Liu, Tianjian Chen and Yongxin Tong. “Federated Machine Learning.” ACM Transactions on Intelligent Systems and Technology (TIST) 10 (2019): 1 - 19. <a href=https://dl.acm.org/doi/10.1145/3298981 target=_blank rel=noopener>Link</a> (One of the most highly cited papers on FML. More than 1,800 citations.)</li><li>Wahab, Omar Abdel, Azzam Mourad, Hadi Otrok and Tarik Taleb. “Federated Machine Learning: Survey, Multi-Level Classification, Desirable Criteria and Future Directions in Communication and Networking Systems.” IEEE Communications Surveys & Tutorials 23 (2021): 1342-1397. <a href="https://oulurepo.oulu.fi/bitstream/handle/10024/30908/nbnfi-fe2021090144887.pdf;jsessionid=674F5A465BAAC880DF7621A6772251F8?sequence=1" target=_blank rel=noopener>Link</a></li><li>Sun, Gan, Yang Cong, Jiahua Dong, Qiang Wang and Ji Liu. “Data Poisoning Attacks on Federated Machine Learning.” IEEE Internet of Things Journal 9 (2020): 11365-11375. <a href=https://arxiv.org/pdf/2004.10020.pdf target=_blank rel=noopener>Link</a></li></ul><p>Useful standards include:</p><ul><li>Not covered yet in ISO/IEC standards</li></ul><h4>#SUPPLYCHAINMANAGE<span class="absolute -mt-20" id=supplychainmanage></span>
<a href=#supplychainmanage class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time information security control<br>Permalink: <a href=https://owaspai.org/goto/supplychainmanage/ target=_blank rel=noopener>https://owaspai.org/goto/supplychainmanage/</a></p></blockquote><p>Supply chain management: Managing the supply chain to minimize the security risk from externally obtained elements. In conventional software engineering these elements are source code or software components (e.g. open source). The particularities for AI are:</p><ol><li>supplied elements can also include data and models,</li><li>many of the software components are executed development-time instead of just in production (the runtime of the application),</li><li>as explained in the development-time threats, there are new vulnerable assets during AI development: training data and model parameters - which can fall victim to software components running development-time.</li></ol><p>ad. 1: Security risks in obtained data or models can arise from accidental mistakes or from manipulations - just like with obtained source code or software components.</p><p>ad. 2: Data engineering and model engineering involve operations on data and models for which often external components are used (e.g. tools such as Notebooks, or other MLOps applications). Because AI development has new assets such as the data and model parameters, these components pose a new threat. To make matters worse, data scientists also install dependencies on the Notebooks which makes the data and model engineering environment a dangerous attack vector and the classic supply chain guardrails typically don’t scan it.</p><p><strong>The AI supply chain can be complex</strong>. Just like with obtained source code or software components, data or models may involve multiple suppliers. For example: a model is trained by one vendor and then fine-tuned by another vendor. Or: an AI system contains multiple models, one is a model that has been fine-tuned with data from source X, using a base model from vendor A that claims data is used from sources Y and Z, where the data from source Z was labeled by vendor B.
Because of this supply chain complexity, data and model provenance is a helpful activity. The Software Bill Of Materials (SBOM) becomes the AI Bill Of Materials (AIBOM) or Model Bill of Material (MBOM).</p><p>Standard supply chain management includes:</p><ul><li>Supplier Verification: Ensuring that all third-party components, including data, models, and software libraries, come from trusted sources. Provenance & pedigree are in order. This can be achieved through informed supplier selection, supplier audits and requiring attestations of security practices.</li><li>Traceability and Transparency: Maintaining detailed records of the origin, version, and security posture of all components used in the AI system. This aids in quick identification and remediation of vulnerabilities. This includes the following tactics:<ul><li>Using package repositories for software components</li><li>Using dependency verification tools that identify supplied components and suggest actions</li></ul></li><li>Frequent patching (including data and models)</li><li>Checking integrity of elements (see <a href=/goto/devsecurity/>#DEVSECURITY</a>)</li></ul><p>See <a href=https://atlas.mitre.org/techniques/AML.T0010 target=_blank rel=noopener>MITRE ATLAS - ML Supply chain compromise</a>.</p><p>Useful standards include:</p><ul><li>ISO Controls 5.19, 5.20, 5.21, 5.22, 5.23, 8.30. Gap: covers this control fully, with said particularity, and lacking controls on data provenance.</li><li>ISO/IEC AWI 5181 (Data provenance). Gap: covers the data provenance aspect to complete the coverage together with the ISO 27002 controls - provided that the provenance concerns all sensitive data and is not limited to personal data.</li><li>ISO/IEC 42001 (AI management) briefly mentions data provenance and refers to ISO 5181 in section B.7.5</li><li><a href=https://www.etsi.org/deliver/etsi_gr/SAI/001_099/002/01.01.01_60/gr_SAI002v010101p.pdf target=_blank rel=noopener>ETSI GR SAI 002 V 1.1.1 Securing Artificial Intelligence (SAI) – Data Supply Chain Security</a></li><li><a href=https://www.opencre.org/cre/613-285 target=_blank rel=noopener>OpenCRE</a></li></ul><hr><h2>3.1. Broad model poisoning development-time<span class="absolute -mt-20" id=31-broad-model-poisoning-development-time></span>
<a href=#31-broad-model-poisoning-development-time class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: group of development-time threats<br>Permalink: <a href=https://owaspai.org/goto/modelpoison/ target=_blank rel=noopener>https://owaspai.org/goto/modelpoison/</a></p></blockquote><p>Development-time model poisoning in the broad sense is when an attacker manipulates development elements (the engineering environment and the supply chain), to alter the behavior of the model. There are three types, each covered in a subsection:</p><ol><li><a href=/goto/datapoison/>data poisoning</a>: an attacker manipulates training data, or data used for in-context learning.</li><li><a href=/goto/devmodelpoison/>development-environment model poisoning</a>: an attacker manipulates model parameters, or other engineering elements that take part in creating the model, such as code, configuration or libraries.</li><li><a href=/goto/supplymodelpoison/>supply-chain model poisoning</a>: using a supplied trained model which has been manipulated by an attacker.</li></ol><p>Impact: Integrity of model behaviour is affected, leading to issues from unwanted model output (e.g. failing fraud detection, decisions leading to safety issues, reputation damage, liability).</p><p>Data and model poisoning can occur at various stages, as illustrated in the threat model below.</p><ul><li>Supplied data or a supplied model can have been poisoned</li><li>Poisoning in the development environment can occur in the data preparation domain, or in the training environment. If the training environment is separated security-wise, then it is possible to implement certain controls (including tests) against data poisoning that took place at the supplier or during preparation time.</li><li>In the case that training data is collected runtime, then this data is under poisoning threat.</li><li>Model poisoning alters the model directly, either at the supplier, or development-time, or during runtime.</li></ul><p><img src=/images/poisonthreatmodel2.png alt loading=lazy></p><p><strong>Controls for broad model poisoning:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a>, especially <a href=/goto/limitunwanted/>Limiting the effect of unwanted behaviour</a></li><li>See <a href=/goto/developmenttimeintro/>controls for development-time protection</a></li><li>The controls specific to <a href=/goto/datapoison/>data poisoning</a> and <a href=/goto/devmodelpoison/>development-time model poisoning</a></li><li>The below control(s), each marked with a # and a short name in capitals</li></ul><h4>#MODELENSEMBLE<span class="absolute -mt-20" id=modelensemble></span>
<a href=#modelensemble class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time data science control - including specific runtime implementation
Permalink: <a href=https://owaspai.org/goto/modelensemble/ target=_blank rel=noopener>https://owaspai.org/goto/modelensemble/</a></p></blockquote><p>Model ensemble: deploy the model as an ensemble of models by randomly splitting the trainset to allow detection of poisoning. If one model&rsquo;s output deviates from the others, it can be ignored, as this indicates possible manipulation of the train set.</p><p>Effectiveness: the more the dataset has been poisoned with samples, the less effective this approach is.</p><p>Ensemble learning is a term in machine learning used for using multiple learning algorithms, with the purpose of better predictive performance.</p><p>Useful standards include:</p><ul><li>Not covered yet in ISO/IEC standards</li></ul><h3>3.1.1. Data poisoning<span class="absolute -mt-20" id=311-data-poisoning></span>
<a href=#311-data-poisoning class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: development-time threat<br>Permalink: <a href=https://owaspai.org/goto/datapoison/ target=_blank rel=noopener>https://owaspai.org/goto/datapoison/</a></p></blockquote><p>An attacker manipulates data that the model uses to learn, in order to affect the algorithm&rsquo;s behavior. Also called <em>causative attacks</em>. There are multiple ways to do this (see the attack surface diagram in the <a href=/goto/modelpoison/>broad model poisoning section</a>):</p><ul><li>Changing the data while in storage during development-time (e.g. by hacking the database)</li><li>Changing the data while in transit to the storage (e.g. by hacking into a data transfer)</li><li>Changing the data while at the supplier, before the data is obtained from the supplier</li><li>Changing the data while at the supplier, where a model is trained and then that model is obtained from the supplier</li><li>Manipulating data entry in operation, feeding into training data, for example by creating fake accounts to enter positieve reviews for products, making these products get recommended more often</li></ul><p>The manipulated data can be training data, but also in-context-learning data that is used to augment the input (e.g. a prompt) to a model with information to use.</p><p>Example 1: an attacker breaks into a training set database to add images of houses and labels them as &lsquo;fighter plane&rsquo;, to mislead the camera system of an autonomous missile. The missile is then manipulated to attack houses. With a good test set this unwanted behaviour may be detected. However, the attacker can make the poisoned data represent input that normally doesn&rsquo;t occur and therefore would not be in a testset. The attacker can then create that abnormal input in practice. In the previous example this could be houses with white crosses on the door. See <a href=https://atlas.mitre.org/techniques/AML.T0020 target=_blank rel=noopener>MITRE ATLAS - Poison trainingdata</a></p><p>Example 2: a malicious supplier poisons data that is later obtained by another party to train a model. See <a href=https://atlas.mitre.org/techniques/AML.T0019 target=_blank rel=noopener>MITRE ATLAS - Publish poisoned datasets</a></p><p>Example 3: unwanted information (e.g. false facts) in documents on the internet causes a Large Language Model (GenAI) to output unwanted results (<a href=https://genai.owasp.org/llmrisk/llm04/ target=_blank rel=noopener>OWASP for LLM 04</a>). That unwanted information can be planted by an attacker, but of course also by accident. The latter case is a real GenAI risk, but technically comes down to the issue of having false data in a training set which falls outside of the security scope. Planted unwanted information in GenAI training data falls under the category of Sabotage attack as the intention is to make the model behave in unwanted ways for regular input.</p><p>There are roughly two categories of data poisoning:</p><ul><li>Backdoors - which trigger unwanted responses to specific inputs (e.g. a money transaction is wrongfully marked as NOT fraud because it has a specific amount of money for which the model has been manipulated to ignore). Other name: Trojan attack</li><li>Sabotage: data poisoning leads to unwanted results for regular inputs, leading to e.g. business continuity problems or safety issues.</li></ul><p>Sabotage data poisoning attacks are relatively easy to detect because they occur for regular inputs, but backdoor data posoning only occurs for really specific inputs and is therefore hard to detect: there is no code to review in a model to look for backdoors, the model parameters cannot be reviewed as they make no sense to the human eye, and testing is typically done using normal cases, with blind spots for backdoors. This is the intention of attackers - to bypass regular testing.</p><p>References</p><ul><li><a href=https://zahalka.net/ai_security_blog/2023/09/backdoor-attacks-defense-cvpr-23-how-to-build-and-burn-trojan-horses/ target=_blank rel=noopener>Summary of 15 backdoor papers at CVPR &lsquo;23</a></li><li><a href=https://arxiv.org/abs/1708.06733 target=_blank rel=noopener>Badnets article by Gu et al</a></li><li><a href=https://people.csail.mit.edu/madry/lab/cleanlabel.pdf target=_blank rel=noopener>Clean-label Backdoor attacks by Turner et al</a></li></ul><p><strong>Controls for data poisoning:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a>, especially <a href=/goto/limitunwanted/>Limiting the effect of unwanted behaviour</a></li><li>See <a href=/goto/developmenttimeintro/>controls for development-time protection</a> of primarily the training data</li><li>See controls for <a href=/goto/modelpoison/>broad model poisoning</a></li><li>The below control(s), each marked with a # and a short name in capitals</li></ul><h4>#MORETRAINDATA<span class="absolute -mt-20" id=moretraindata></span>
<a href=#moretraindata class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time data science control - pre-training<br>Permalink: <a href=https://owaspai.org/goto/moretraindata/ target=_blank rel=noopener>https://owaspai.org/goto/moretraindata/</a></p></blockquote><p>More train data: increasing the amount of non-malicious data makes training more robust against poisoned examples - provided that these poisoned examples are small in number. One way to do this is through data augmentation - the creation of artificial training set samples that are small variations of existing samples. The goal is to &lsquo;outnumber&rsquo; the poisoned samples so the model &lsquo;forgets&rsquo; them.</p><p>This control can only be applied during training and therefore not to an already trained model. Nevertheless, a variation can be applied to a trained model: by fine-tuning it with additional non-malicious data - see <a href=/goto/poisonrobustmodel/>POISONROBUSTMODEL</a>.</p><p>Useful standards include:</p><ul><li>Not covered yet in ISO/IEC standards</li></ul><h4>#DATAQUALITYCONTROL<span class="absolute -mt-20" id=dataqualitycontrol></span>
<a href=#dataqualitycontrol class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time data science control - pre-training<br>Permalink: <a href=https://owaspai.org/goto/dataqualitycontrol/ target=_blank rel=noopener>https://owaspai.org/goto/dataqualitycontrol/</a></p></blockquote><p>Data quality control: Perform quality control on data including detecting poisoned samples through integrity checks, statistical deviation or pattern recognition.</p><p>Particularity for AI: Standard data quality checks are not sufficient for AI systems, as data may be maliciously altered to compromise model behavior. This requires different checks than standard checks on quality issues from the source, or that occured by mistake. Nevertheless, standard checks can help somewhat to detect malicious changes. It is essential to implement enhanced security measures to detect these alterations:</p><ul><li>Secure Hash Codes: Safely store hash codes of data elements, such as images, and conduct regular checks for manipulations. See <a href=/goto/devsecurity>DEVSECURITY</a> for more details on integrity checks.</li><li>Statistical deviation detection</li><li>Recognizing specific types of poisoned samples by applying pattern recognition</li></ul><p>When: This control can only be applied during training and cannot be retroactively applied to an already trained model. Implementing it during training ensures that the model learns from clean, high-quality data, thus enhancing its performance and security. This is key to know and implement early on in the training process to ensure adequate training results and long-term success in the overall quality of the data.</p><p>Key Points for Consideration:</p><ul><li>Proactive Approach: Implement data quality controls during the training phase to prevent issues before they arise in production.</li><li>Comprehensive Verification: Combine automated methods with human oversight for critical data, ensuring that anomalies are accurately identified and addressed.</li><li>Continuous Monitoring: Regularly update and audit data quality controls to adapt to evolving threats and maintain the robustness of AI systems.</li><li>Collaboration and Standards: Adhere to international standards like ISO/IEC 5259 and 42001 while recognizing their limitations. Advocate for the development of more comprehensive standards that address the unique challenges of AI data quality.</li></ul><p>References</p><ul><li><a href=https://arxiv.org/abs/1802.03041 target=_blank rel=noopener>&lsquo;Detection of Adversarial Training Examples in Poisoning Attacks through Anomaly Detection&rsquo;</a></li></ul><p>Useful standards include:</p><ul><li>ISO/IEC 5259 series on Data quality for analytics and ML. Gap: covers this control minimally. in light of the particularity - the standard does not mention approaches to detect malicious changes (including detecting statistical deviations). Nevertheless, standard data quality control helps to detect malicious changes that violate data quality rules.</li><li>ISO/iEC 42001 B.7.4 briefly covers data quality for AI. Gap: idem as ISO 5259</li><li>Not further covered yet in ISO/IEC standards</li></ul><h4>#TRAINDATADISTORTION<span class="absolute -mt-20" id=traindatadistortion></span>
<a href=#traindatadistortion class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time data science control - pre-training<br>Permalink: <a href=https://owaspai.org/goto/traindatadistortion/ target=_blank rel=noopener>https://owaspai.org/goto/traindatadistortion/</a></p></blockquote><p>Train data distortion: distorting untrusted training data by smoothing or adding noise, to make poisoned &rsquo;triggers&rsquo; ineffective. Such a trigger has been inserted by an attacker in the training data, together with an unwanted output. Whenever input data is presented that contains a similar &rsquo;trigger&rsquo;, the model can recognize it and output the unwanted value. The idea is to distort the triggers so that they are not recognized anymore by the model.</p><p>A special form of traindata distortion is complete removal of certain input fields. Technically, this is data minimization (see <a href=goto/dataminimize/>DATAMINIMIZE</a>), but its purpose is not protecting the confidentiality of that data per se, but reducing the ability to memorize poisoned samples.</p><p>Data distortion can also be part of differential privacy: to make personal data less recognizable. This means that applying differential privacy can be a countermeasure to data poisoning as well.</p><p>This control can only be applied during training and therefore not to an already trained model.</p><p>Effectiveness:</p><ul><li>The level of effectiveness needs to be tested by experimenting, which will not give conclusive results, as an attacker my find more clever ways to poison the data than the methods used during testing. It is a best practice to keep the original training data, in order to expertiment with the amount or distortion.</li><li>This control has no effect against attackers that have direct access to the training data after it has been distorted. For example, if the distorted training data is stored in a file or database to which the attacker has access, then the poisoned samples can still be injected. In other words: if there is zero trust in protection of the engineering environment, then train data distortion is only effective against data poisoning that took place outside the engineering environment (collected during runtime or obtained through the supply chain). This problem can be reduced by creating a trusted environment in which the model is trained, separated from the rest of the engineering environment. By doing so, controls such as train data distortion can be applied in that trusted environment and thus protect against data poisoning that may have taken place in the rest of the engineering environment.</li></ul><p>See also <a href=/goto/evasionrobustmodel/>EVASIONROBUSTMODEL</a> on adding noise against evasion attacks and <a href=/goto/obfuscatetrainingdata/>OBFUSCATETRAININGDATA</a> to minimize data for confidentiality purposes (e.g. differential privacy).</p><p>Examples:</p><ul><li><a href=https://arxiv.org/pdf/1703.04318.pdf target=_blank rel=noopener>Transferability blocking</a>. The true defense mechanism against closed box attacks is to obstruct the transferability of the adversarial samples. The transferability enables the usage of adversarial samples in different models trained on different datasets. Null labeling is a procedure that blocks transferability, by introducing null labels into the training dataset, and trains the model to discard the adversarial samples as null labeled data.</li><li>DEFENSE-GAN</li><li>Local intrinsic dimensionality</li><li>(weight)Bagging - see Annex C in ENISA 2021</li><li>TRIM algorithm - see Annex C in ENISA 2021</li><li>STRIP technique (after model evaluation) - see Annex C in ENISA 2021</li></ul><p>Link to standards:</p><ul><li>Not covered yet in ISO/IEC standards</li></ul><h4>#POISONROBUSTMODEL<span class="absolute -mt-20" id=poisonrobustmodel></span>
<a href=#poisonrobustmodel class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: development-time data science control - post-training<br>Permalink: <a href=https://owaspai.org/goto/poisonrobustmodel/ target=_blank rel=noopener>https://owaspai.org/goto/poisonrobustmodel/</a></p></blockquote><p>Poison robust model: select a model type and creation approach to reduce sensitivity to poisoned training data.</p><p>This control can be applied to a model that has already been trained, so including models that have been obtained from an external source.</p><p>The general principle of reducing sensitivity to poisoned training data is to make sure that the model does not memorize the specific malicious input pattern (or <em>backdoor trigger</em>). The following two examples represent different strategies, which can also complement each other in an approach called <strong>fine pruning</strong> (See <a href=https://arxiv.org/pdf/1805.12185.pdf target=_blank rel=noopener>paper on fine-pruning</a>):</p><ol><li>Reduce memorization by removing elements of memory using <strong>pruning</strong>. Pruning in essence reduces the size of the model so it does not have the capacity to trigger on backdoor-examples while retaining sufficient accuracy for the intended use case. The approach removes neurons in a neural network that have been identified as non-essential for sufficient accuracy.</li><li>Overwrite memorized malicious patterns using <strong>fine tuning</strong> by retraining a model on a clean dataset(without poisoning).</li></ol><p>Useful standards include:</p><ul><li>Not covered yet in ISO/IEC standards</li></ul><h4>#TRAINADVERSARIAL<span class="absolute -mt-20" id=trainadversarial></span>
<a href=#trainadversarial class=subheading-anchor aria-label="Permalink for this section"></a></h4><p>Training with adversarial examples is used as a control against evasion attacks, but can also be helpful against datapoison trigger attacks that are based on slight alterations of training data, since these triggers are like adversarial samples.</p><p>For example: adding images of stop signs in a training database for a self driving car, labeled as 35 miles an hour, where the stop sign is slightly altered. What this effectively does is to force the model to make a mistake with traffic signs that have been altered in a similar way. This type of data poisoning aims to prevent anomaly detection of the poisoned samples.</p><p>Find the corresponding control section <a href=https://owaspai.org/goto/trainadversarial/ target=_blank rel=noopener>here, with the other controls against Evasion attacks</a>.</p><p>References:</p><ul><li><a href=https://arxiv.org/abs/2102.13624 target=_blank rel=noopener>&lsquo;How to adversarially train against data poisoning&rsquo;</a></li><li><a href="https://openreview.net/forum?id=zKvm1ETDOq" target=_blank rel=noopener>&lsquo;Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning?&rsquo;</a></li></ul><h3>3.1.2. Development-environment model poisoning<span class="absolute -mt-20" id=312-development-environment-model-poisoning></span>
<a href=#312-development-environment-model-poisoning class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: development-time threat<br>Permalink: <a href=https://owaspai.org/goto/devmodelpoison/ target=_blank rel=noopener>https://owaspai.org/goto/devmodelpoison/</a></p></blockquote><p>This threat refers to manipulating behaviour of the model by not poisoning the training data, but instead manipalte elements in the development-environment that lead to the model or represent the model (i.e. model parameters), e.g. by manipulating storage of model parameters. When the model is trained by a supplier in a manipulative way and supplied as-is, then it is <a href=goto/supplymodelpoison/>supply-chain model poisoning</a>.
Training data manipulation is referred to as <a href=/goto/datapoison>data poisoning</a>. See the attack surface diagram in the <a href=/goto/modelpoison/>broad model poisoning section</a>.</p><p><strong>Controls:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a>, especially <a href=/goto/limitunwanted/>Limiting the effect of unwanted behaviour</a></li><li>See <a href=/goto/developmenttimeintro/>controls for development-time protection</a></li><li>See controls for broad model poisoning</li><li>Controls that are aimed to improve the generalization ability of the model - reducing the memorization of any poisoned samples: <a href=/goto/trainadversarial/>training with adversarial samples</a> and <a href=/goto/adversarialrobustdistillation/>adversarial robust distillation</a></li></ul><h3>3.1.3 Supply-chain model poisoning<span class="absolute -mt-20" id=313-supply-chain-model-poisoning></span>
<a href=#313-supply-chain-model-poisoning class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: development-time threat<br>Permalink: <a href=https://owaspai.org/goto/supplymodelpoison/ target=_blank rel=noopener>https://owaspai.org/goto/supplymodelpoison/</a></p></blockquote><p>An attacker manipulates a third-party (pre-)trained model which is then supplied, obtained and unknowingly further used and/or trained/fine tuned, with still having the unwanted behaviour (see the attack surface diagram in the <a href=/goto/modelpoison/>broad model poisoning section</a>). If the supplied model is used for urther training, then the attack is called a <em>transfer learning attack</em>.</p><p>AI models are sometimes obtained elsewhere (e.g. open source) and then further trained or fine-tuned. These models may have been manipulated(poisoned) at the source, or in transit. See <a href=https://genai.owasp.org/llmrisk/llm03/ target=_blank rel=noopener>OWASP for LLM 03: Supply Chain</a>.</p><p>The type of manipulation can be through data poisoning, or by specifically changing the model parameters. Therefore, the same controls apply that help against those attacks. Since changing the model parameters requires protection of the parameters at the moment they are manipulated, this is not in the hands of the one who obtained the model. What remains are the controls against data poisoning, the controls against model poisoning in general (e.g. model ensembles), plus of course good supply chain management.</p><p><strong>Controls:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a>, especially <a href=/goto/limitunwanted/>Limiting the effect of unwanted behaviour</a></li><li>See those controls for <a href=/goto/modelpoison/>data poisoning</a> that work on models that have already been trained (post-training), e.g. <a href=/goto/poisonrobustmodel/>POISONROBUSTMODEL</a></li><li>See #<a href=/goto/supplychainmanage/>SUPPLYCHAINMANAGE</a> to control obtaining a reliable model from a reliable supplier.</li><li>Other controls need to be applied by the supplier of the model:<ul><li>Controls for <a href=/goto/developmenttimeintro/>development-time protection</a>, like for example protecting the training set database against data poisoning</li><li>Controls for <a href=/goto/modelpoison/>broad model poisoning</a></li><li>Controls for <a href=/goto/modelpoison/>data poisoning</a> that work pre-training</li></ul></li></ul><hr><h2>3.2. Sensitive data leak development-time<span class="absolute -mt-20" id=32-sensitive-data-leak-development-time></span>
<a href=#32-sensitive-data-leak-development-time class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: group of development-time threats<br>Permalink: <a href=https://owaspai.org/goto/devleak/ target=_blank rel=noopener>https://owaspai.org/goto/devleak/</a></p></blockquote><h3>3.2.1. Development-time data leak<span class="absolute -mt-20" id=321-development-time-data-leak></span>
<a href=#321-development-time-data-leak class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: development-time threat<br>Permalink: <a href=https://owaspai.org/goto/devdataleak/ target=_blank rel=noopener>https://owaspai.org/goto/devdataleak/</a></p></blockquote><p>Unauthorized access to train or test data through a data leak of the development environment.</p><p>Impact: Confidentiality breach of sensitive train/test data.</p><p>Training data or test data can be confidential because it&rsquo;s sensitive data (e.g. personal data) or intellectual property. An attack or an unintended failure can lead to this training data leaking.<br>Leaking can happen from the development environment, as engineers need to work with real data to train the model.<br>Sometimes training data is collected at runtime, so a live system can become attack surface for this attack.<br>GenAI models are often hosted in the cloud, sometimes managed by an external party. Therefore, if you train or fine tune these models, the training data (e.g. company documents) needs to travel to that cloud.</p><p><strong>Controls:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a>, especially <a href=/goto/dataminimize/>Sensitive data limitation</a></li><li>See <a href=/goto/developmenttimeintro/>controls for development-time protection</a></li></ul><h3>3.2.2. Model theft through development-time model parameter leak<span class="absolute -mt-20" id=322-model-theft-through-development-time-model-parameter-leak></span>
<a href=#322-model-theft-through-development-time-model-parameter-leak class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: development-time threat<br>Permalink: <a href=https://owaspai.org/goto/devmodelleak/ target=_blank rel=noopener>https://owaspai.org/goto/devmodelleak/</a></p></blockquote><p>Unauthorized access to model parameters through a data leak of the development environment.</p><p>Impact: Confidentiality breach of model parameters, which can result in intellectual model theft and/or allowing to perform model attacks on the stolen model that normally would be mitigated by rate limiting, access control, or detection mechanisms.</p><p>Alternative ways of model theft are <a href=/goto/modeltheftuse/>model theft through use</a> and <a href=/goto/runtimemodeltheft/>direct runtime model theft</a>.</p><p><strong>Controls:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a>, especially <a href=/goto/dataminimize/>Sensitive data limitation</a></li><li>See <a href=/goto/developmenttimeintro/>controls for development-time protection</a></li></ul><h3>3.2.3. Source code/configuration leak<span class="absolute -mt-20" id=323-source-codeconfiguration-leak></span>
<a href=#323-source-codeconfiguration-leak class=subheading-anchor aria-label="Permalink for this section"></a></h3><blockquote><p>Category: development-time threat<br>Permalink: <a href=https://owaspai.org/goto/devcodeleak/ target=_blank rel=noopener>https://owaspai.org/goto/devcodeleak/</a></p></blockquote><p>Unauthorized access to code or configuration that leads to the model, through a data leak of the development environment. SUch code or configuration is used to preprocess the training/test data and train the model.</p><p>Impact: Confidentiality breach of model intellectual property.</p><p><strong>Controls:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a>, especially <a href=/goto/dataminimize/>Sensitive data limitation</a></li><li>See <a href=/goto/developmenttimeintro/>controls for development-time protection</a></li></ul></div><div class=mt-16></div><div class="mb-8 flex items-center border-t pt-8 dark:border-neutral-800 contrast-more:border-neutral-400 dark:contrast-more:border-neutral-400 print:hidden"><a href=/docs/2_threats_through_use/ title="2. Threats through use" class="flex max-w-[50%] items-center gap-1 py-4 text-base font-medium text-gray-600 transition-colors [word-break:break-word] hover:text-primary-600 dark:text-gray-300 md:text-lg ltr:pr-4 rtl:pl-4"><svg class="inline h-5 shrink-0 ltr:rotate-180" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/></svg>2. Threats through use</a><a href=/docs/4_runtime_application_security_threats/ title="4. Runtime application security threats" class="flex max-w-[50%] items-center gap-1 py-4 text-base font-medium text-gray-600 transition-colors [word-break:break-word] hover:text-primary-600 dark:text-gray-300 md:text-lg ltr:ml-auto ltr:pl-4 ltr:text-right rtl:mr-auto rtl:pr-4 rtl:text-left">4. Runtime application security threats<svg class="inline h-5 shrink-0" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/></svg></a></div></main></article></div><footer class="hextra-footer bg-gray-100 pb-[env(safe-area-inset-bottom)] dark:bg-neutral-900 print:bg-transparent"><div class="max-w-screen-xl mx-auto flex justify-center py-12 pl-[max(env(safe-area-inset-left),1.5rem)] pr-[max(env(safe-area-inset-right),1.5rem)] text-gray-600 dark:text-gray-400 md:justify-start"><div class="flex w-full flex-col items-center sm:items-start"><div class=font-semibold><a class="flex text-sm items-center gap-1 text-current" target=_blank rel="noopener noreferrer" title="Hextra GitHub Homepage" href=https://github.com/imfing/hextra><span>Powered by Hextra<svg height="1em" class="inline-block ml-1 align-[-2.5px]" viewBox="0 0 180 180" xmlns="http://www.w3.org/2000/svg" fill="currentcolor"><path fill-rule="evenodd" clip-rule="evenodd" d="m105.50024 22.224647c-9.59169-5.537563-21.40871-5.537563-31.000093.0L39.054693 42.689119C29.463353 48.226675 23.55484 58.460531 23.55484 69.535642v40.928918c0 11.07542 5.908513 21.3092 15.499853 26.84652l35.445453 20.46446c9.591313 5.53732 21.408404 5.53732 31.000094.0l35.44507-20.46446c9.59131-5.53732 15.49985-15.7711 15.49985-26.84652V69.535642c0-11.075111-5.90854-21.308967-15.49985-26.846523zM34.112797 85.737639c-1.384445 2.397827-1.384445 5.352099.0 7.749927l24.781554 42.922974c1.38437 2.39783 3.942853 3.87496 6.711592 3.87496h49.563107c2.76905.0 5.3273-1.47713 6.71144-3.87496l24.78194-42.922974c1.38414-2.397828 1.38414-5.3521.0-7.749927L121.88049 42.814746c-1.38414-2.397828-3.94239-3.874964-6.71144-3.874964H65.605944c-2.768739.0-5.327223 1.477059-6.711592 3.874964z" style="stroke-width:.774993"/></svg></span></a></div></div></div></footer></body><script defer src=/js/main.min.5250a01f9a9cabefdb65e77efc7c04221397882cded9c5c058a5504e730b11b3.js integrity="sha256-UlCgH5qcq+/bZed+/HwEIhOXiCze2cXAWKVQTnMLEbM="></script>
<script defer src=/lib/flexsearch/flexsearch.bundle.min.0425860527cc9968f9f049421c7a56b39327d475e2e3a8f550416be3a9134327.js integrity="sha256-BCWGBSfMmWj58ElCHHpWs5Mn1HXi46j1UEFr46kTQyc="></script>
<script defer src=/en.search.min.9afdc7c586c6f971dd94df10b989f10faaf38e5702571fd8cfc9ff9135c2d495.js integrity="sha256-mv3HxYbG+XHdlN8QuYnxD6rzjlcCVx/Yz8n/kTXC1JU="></script></html>