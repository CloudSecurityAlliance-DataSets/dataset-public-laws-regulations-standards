Unnamed: 0,Unnamed: 1,Unnamed: 2,Unnamed: 3,Unnamed: 4,Unnamed: 5,Unnamed: 6,Unnamed: 7,Unnamed: 8
,,,,,,,,
,,,,,,,,
,Repository Version ,Considered ,Excluded ,Included ,,,,
,V2 ,31,18,13,,,,
,V3,12,3,9,,,,
,,,,,,,,
,Title,Authors,Year,URL,Source,Suggested,To be Included,Reason
,The AILuminate Assessment Standard,MLCommons ,2024,https://drive.google.com/file/d/1jVYoSGJHtDo1zQLTzU7QXDkRMZIberdo/view,Alexander Saeri,2025-01-03 00:00:00,No,Duplicate
,"A Collaborative, Human-Centred Taxonomy of AI, Algorithmic, and Automation Harms","Abercrombie, G.; Benbouzid, D.; Giudici, P.; Golpayegani, D.; Hernandez, J.; Noro, P.; Pandit, H.; Paraschou, E.; Pownall, C.; Prajapati, J.; Sayre, M. A.; Sengupta, U.; Suriyawongkul, A.; Thelot, R.; Vei, S.; Waltersdorfer, L. ",2024,https://drive.google.com/file/d/1-kGdaYizobuwjDSgIYKh7H3dhNuP0QzI/view,Charlie Pownall,2024-12-05 00:00:00,Yes,Incl
,Atlas of AI Risks: Enhancing Public Understanding of AI Risks,"Bogucka, E., Šćepanović, S.; Quercia, D.",2024,https://social-dynamics.net/atlas/,Peter Slattery ,2025-01-03 00:00:00,No,Excl - Not an organised framework
,NIST National Vulnerability Database ,NIST ,2024,https://nvd.nist.gov/,Alexander Saeri,2025-01-21 00:00:00,No,Excl - Not an organised framework
,AI Hazard Management: A Framework for the Systematic Management of Root Causes for AI Risks,"Schnitzer, R., Hapfelmeier, A., Gaube, S., & Zillner, S. ",2024,https://link.springer.com/chapter/10.1007/978-981-99-9836-4_27#Tab1,Jessica Graham ,2025-01-31 00:00:00,Yes,Incl
,International AI Safety Report ,"Y. Bengio, S. Mindermann, D. Privitera, T. Besiroglu, R. Bommasani, S. Casper, Y. Choi, P. Fox, B. Garfinkel, D. Goldfarb, H. Heidari, A. Ho, S. Kapoor, L. Khalatbari, S. Longpre, S. Manning, V. Mavroudis, M. Mazeika, J. Michael, J. Newman, K. Y. Ng, C. T. Okolo, D. Raji, G. Sastry, E. Seger, T. Skeadas, T. South, E. Strubell, F. Tramèr, L. Velasco, N. Wheeler, D. Acemoglu, O. Adekanmbi, D. Dalrymple, T. G. Dietterich, P. Fung, P.-O. Gourinchas, F. Heintz, G. Hinton, N. Jennings, A. Krause, S. Leavy, P. Liang, T. Ludermir, V. Marda, H. Margetts, J. McDermid, J. Munga, A. Narayanan, A. Nelson, C. Neppel, A. Oh, G. Ramchurn, S. Russell, M. Schaake, B. Schölkopf, D. Song, A. Soto, L. Tiedrich, G. Varoquaux, E. W. Felten, A. Yao, Y.-Q. Zhang, O. Ajala, F. Albalawi, M. Alserkal, G. Avrin, C. Busch, A. C. P. de L. F. de Carvalho, B. Fox, A. S. Gill, A. H. Hatip, J. Heikkilä, C. Johnson, G. Jolly, Z. Katzir, S. M. Khan, H. Kitano, A. Krüger, K. M. Lee, D. V. Ligot, J. R. López Portillo, D., O. Molchanovskyi, A. Monti, N. Mwamanzi, M. Nemer, N. Oliver, R. Pezoa Rivera, B. Ravindran, H. Riza, C. Rugege, C. Seoighe, H. Sheikh, J. Sheehan, D. Wong, Y. Zeng",2025,https://assets.publishing.service.gov.uk/media/679a0c48a77d250007d313ee/International_AI_Safety_Report_2025_accessible_f.pdf,Peter Slattery ,2025-02-03 00:00:00,Yes,Incl
,A Taxonomy of Systemic Risks from General-Purpose AI ,"Uuk, R., Gutierrez, C.I., Guppy, D., Lauwaert, L., Kasirzadeh, A., Velasco, L., Slattery, P., Prunkl, C.",2025,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5030173,Peter Slattery ,2025-02-19 00:00:00,Yes,Incl
,Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems,"Gipiškis, R., San Joaquin, A., Chin, Z.S., Regenfuß, A., Gil, A., Holtman, K.",2024,https://arxiv.org/abs/2410.23472,Peter Slattery ,2025-02-19 00:00:00,Yes,Incl
,Multi-Agent Risks from Advanced AI ,"Hammond, L., Chan, A., Clifton, J., Hoelscher-Obermaier, J., Khan, A., McLean, E., Smith, C., Barfuss, W., Foerster, J., Gavenčiak, T., Han, T. A., Hughes, E., Kovařík, V., Kulveit, J., Leibo, J. Z., Oesterheld, C., Schroeder de Witt, C., Shah, N., Wellman, M., Bova, P., Cimpeanu, T., Ezell, C., Feuillade-Montixi, Q., Franklin, M., Kran, E., Krawczuk, I., Lamparth, M., Lauffer, N., Meinke, A., Motwani, S., Reuel, A., Conitzer, V., Dennis, M., Gabriel, I., Gleave, A., Hadfield, G., Haghtalab, N., Kasirzadeh, A., Krier, S., Larson, K., Lehman, J., Parkes, D. C., Piliouras, G., Rahwan, I.",2025,https://arxiv.org/abs/2502.14143,Alexander Saeri,2025-02-21 00:00:00,Yes,Incl
,Mapping the Misuse of Generative AI ,"Marchal, N. and Xu, R.",2024,https://deepmind.google/discover/blog/mapping-the-misuse-of-generative-ai/,Jessica Graham ,13/3/2025,Yes,Incl
,AILUMINATE: Introducing v1.0 of the AI Risk and Reliability Benchmark from MLCommons,"Ghosh, S., Frase, H., Williams, A., Luger, S., Röttger, P., Barez, F., McGregor, S., Fricklas, K., Kumar, M., Feuillade–Montixi, Q., Bollacker, K., Friedrich, F., Tsang, R., Vidgen, B., Parrish, A., Knotz, C., Presani, E., Bennion, J., Ferrara Boston, M., Kuniavsky, M., Hutiri, W., Ezick, J., Ben Salem, M., Sahay, R., Goswami, S., Gohar, U., BenHuang, B., Sarin, S., Alhajjar, E., Chen, C., Eng, R., Manjusha, K., Mehta, V., Long, E., Emani, M., Vidra, N., Rukundo, B., Shahbazi, A., Chen, K., Ghosh, R., Thangarasa, V., Peigné, P., Singh, A., MaxBartolo, M., Krishna, S., Akhtar, M., Gold, R., Coleman, C., Oala, L., Tashev, V., Imperial, J., AmyRuss, A., Kunapuli, S., Miailhe, N., Delaunay, J., Radharapu, B., Shinde, R., Tuesday, T., Dutta, D., Grabb, D., Gangavarapu, A., Sahay, S., Gangavarapu, A., Schramowski, P., Singam, S., David, T., Han, X., Mammen, P., Prabhakar, T., Kovatchev, V., Ahmed, A., Manyeki, K., Madireddy, S., Khomh, F., Zhdanov, F., Baumann, J., Vasan, N., Yang, X., Mougn, C., Varghese, J., Chinoy, H., Jitendar, S., Maskey, M., Hardgrove, C., Li, T., Gupta, A., Joswin, E., Mai, Y., Kumar, S., CigdemPatlak, C., Lu, K., Alessi, V., Balija, S., Gu, C., Sullivan, R., Gealy, J., Lavrisa, M., Goel, J., Mattson, P., Liang, P., Vanschoren, J.",2025,https://arxiv.org/pdf/2503.05731,Peter Slattery ,14/3/2025,Yes,Incl
,AI Risk Atlas ,IBM,2025,https://www.ibm.com/docs/en/watsonx/saas?topic=ai-risk-atlas,Alexander Saeri,14/3/2025,Yes,Incl
,,,,,,,,
,Title,Authors,Year,URL,Source,Suggested,To be Included,Reason
,Classifying sources of AI x-risk,"Clarke, S. ",2022,https://forum.effectivealtruism.org/posts/e55QpEExmtkRjw9CD/classifying-sources-of-ai-x-risk,Matthjis Maas ,2024-05-13 00:00:00,No,Excl - Wrong document type 
,Distinguishing AI takeover scenarios,"Clarke, S. and Martin, S.D.",2021,"https://www.alignmentforum.org/posts/qYzqDtoQaZ3eDDyxa/distinguishing-ai-takeover-scenarios#:~:text=We%20define%20AI%20takeover%20to,t%20desirable%20by%20human%20standards.",Matthjis Maas ,2024-05-13 00:00:00,No,Excl - Wrong document type 
,A Survey of the Potential Long-term Impacts of AI,"Clarke, S. and Whittlestone, J. ",2022,https://arxiv.org/abs/2206.11076,Matthjis Maas ,2024-05-13 00:00:00,Yes,Incl
,TASRA: a Taxonomy and Analysis of Societal-Scale Risks,"Critch, A., Russell, S.",2023,https://arxiv.org/abs/2306.06924,Matthjis Maas ,2024-05-13 00:00:00,No,Duplicate
,AI Governance: A Research Agenda,"Dafoe, A. ",2018,https://cdn.governance.ai/GovAI-Research-Agenda.pdf,Matthjis Maas ,2024-05-13 00:00:00,No,Excl - Not an organised framework
,AI Governance Overview and Theoretical Lenses,"Dafoe, A. ",2023,https://academic.oup.com/edited-volume/41989/chapter-abstract/408516484?redirectedFrom=fulltext,Matthjis Maas ,2024-05-13 00:00:00,No,Excl - Wrong document type 
,The Ethics of Advanced AI Assistants,"Gabriel, I., Manzini, A., Keeling, G., Hendricks, L.A., Rieser, V., Iqbal, H., Tomašev, N., Ktena, I., Kenton, Z., Rodriguez, M., El-Sayed, S., Brown, S., Akbulut, C., Trask, A., Hughes, E., Bergman, A.S., Shelby, R., Marchal, N., Griffin, C., Mateos-Garcia, J., Weidinger, L., Street, W., Lange, B., Ingerman, A., Lentz, A., Enger, R., Barakat, A., Krakovna, V., Siy, J.O., Kurth-Nelson, Z., McCroskery, A., Bolina, V., Law, H., Shanahan, M., Alberts, L., Balle, B., de Haas, S., Ibitoye, Y., Dafoe, A., Goldberg, B., Krier, S., Reese, A., Witherspoon, S., Hawkins, W., Rauh, M., Wallace, D., Franklin, M., Goldstein, J.A., Lehman, J., Klenk, M., Vallor, S., Biles, C., Morris, M.R., King, H., Agüera y Arcas, B., Isaac, W., Manyika, J.",2024,https://arxiv.org/abs/2404.16244,Matthjis Maas ,2024-05-13 00:00:00,No,Duplicate
,Ten Hard Problems in Artificial Intelligence We Must Solve,"Leech, G., Garfinkel, S., Yagudin, M., Briand, A., and Zhuralev, A.",2024,https://arxiv.org/pdf/2402.04464,Matthjis Maas ,2024-05-13 00:00:00,Yes,Incl
,Artificial Intelligence Governance Under Change,"Maas, M. ",2021,https://www.researchgate.net/publication/351314988_Artificial_Intelligence_Governance_Under_Change_Foundations_Facets_Frameworks,Matthjis Maas ,2024-05-13 00:00:00,No,Excl - Wrong document type 
,Advanced AI governance: A Literature Review,"Maas, M. ",2023,https://deliverypdf.ssrn.com/delivery.php?ID=997085004006090124125126088098106125026064002040052074078088066090103093026103100092121022038118114014116086118090087004018021028020004053048009024127071084029093103002028001115090012015114031091120007126001086127092101110005066074115004067066114090116&EXT=pdf&INDEX=TRUE,Matthjis Maas ,2024-05-13 00:00:00,Yes,Incl
,Governing General Purpose AI: A Comprehensive Map,"Maham, P. and Küspert, S. ",2023,https://www.stiftung-nv.de/sites/default/files/snv_governing_general_purpose_ai_pdf.pdf,Matthjis Maas ,2024-05-13 00:00:00,Yes,Incl
,Evaluating Frontier Models for Dangerous Capabilities,"Phuong, M., Aitchison, M., Catt, E., Cogan, S., Kaskasoli, A., Krakovna, V., Lindner, D., Rahtz, M., Assael, Y., Hodkinson, S., Howard, H., Lieberum, T., Kumar, R., Raad, M.A., Webson, A., Ho, L., Lin, S., Farquhar, S., Hutter, M., Deletang, G., Ruoss, A., El-Sayed, S., Brown, S., Dragan, A., Shah, R., Dafoe, A., Shevlane, T.",2024,https://arxiv.org/pdf/2403.13793,Matthjis Maas ,2024-05-13 00:00:00,No,Excl - Not an organised framework
,AGI Safety Literature Review ,"Everitt, T., Lea, G., and Hutter, M. ",2018,https://arxiv.org/abs/1805.01109,Alexander Saeri,2024-05-27 00:00:00,Yes,Incl
,International Scientific Report on the Safety of Advanced AI,"Yohsua, Bengio, et al.",2024,https://www.gov.uk/government/publications/international-scientific-report-on-the-safety-of-advanced-ai,Stephen Casper,2024-06-16 00:00:00,Yes,Incl
,AI Risk Categorization Decoded (AIR 2024): From Government Regulations to Corporate Policies,"Yi Zeng, Kevin Klyman, Andy Zhou, Yu Yang, Minzhou Pan, Ruoxi Jia, Dawn Song, Percy Liang and Bo Li",2024,https://arxiv.org/html/2406.17864v1,Michael Aird/Matthjis Maas ,2024-06-30 00:00:00,Yes,Incl
,Future Risks of Frontier AI,Uk Government Office For Science,2023,https://assets.publishing.service.gov.uk/media/653bc393d10f3500139a6ac5/future-risks-of-frontier-ai-annex-a.pdf,Shahar Avin,2024-07-02 00:00:00,Yes,Incl
,Safety by Design for Generative AI: Preventing Child Sexual Abuse,"AWS AI, Civitai, Hugging Face, Inflection, Metaphysic, Stability AI, Teleperformance",2024,https://info.thorn.org/hubfs/thorn-safety-by-design-for-generative-AI.pdf,No name provided ,2024-08-14 00:00:00,No,Excl - not cross-cutting 
,Generative ML and CSAM: Implications and Mitigations ,"Thiel, D., Stoebel, M. and Portnoff, R. ",2023,https://stacks.stanford.edu/file/druid:jv206yg3793/20230624-sio-cg-csam-report.pdf,No name provided ,2024-08-14 00:00:00,No,Excl - Not an organised framework
,"Artificial Intelligence Alignment, Accountability, and Interpretability Commons Repository",NA ,n.d. ,https://www.aiaaic.org/aiaaic-repository,No name provided ,2024-08-14 00:00:00,No,Excl - Not an organised framework
,Machine Learning Risk and Control Framework ,"Blumenthal, R., Erdmann, N., Heitmann, M., Lemettinen, A., and Stockton, B. ",2024,https://ispe.org/pharmaceutical-engineering/january-february-2024/machine-learning-risk-and-control-framework,Brandi M. Stockton ,2024-08-14 00:00:00,No,Excl - Not an organised framework
,Saihub Harms Register ,Lily Innovation ,2023,https://saihub.info,Maury Shenk,2024-08-14 00:00:00,No,Excl - Not an organised framework
,MITRE ATLAS ,MITRE ,2021-2024 ,https://atlas.mitre.org/,Christina Liaghati,2024-08-15 00:00:00,No,Excl - Not an organised framework
,AI Risk Database ,NA ,NA ,https://airisk.io/,Christina Liaghati,2024-08-15 00:00:00,No,Excl - Not an organised framework
,AI Incident Database ,NA ,NA ,incidentdatabase.ai,No name provided ,2024-08-15 00:00:00,No,Excl - Not an organised framework
,Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile,National Institute of Standards and Technology,2024,https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf,Audrey Kittock ,2024-08-15 00:00:00,Yes,Incl
,Regulating under Uncertainty: Governance Options for Generative AI,Florence G'sell ,2024,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4918704,Peter Slattery,2024-08-28 00:00:00,Yes,Incl
,Responsible AI Question Bank: A Comprehensive Tool for AI Risk Assessment ,"Lee, S. U., Perera, H., Liu, Y., Xia, B., Lu, Q., & Zhu, L.",2024,https://arxiv.org/abs/2408.11820,Peter Slattery,2024-08-28 00:00:00,No,Excl - Not an organised framework
,GenAI against humanity: nefarious applications of generative artificial intelligence and large language models,"Ferrera, E. ",2024,https://link.springer.com/article/10.1007/s42001-024-00250-1,Emilio Ferrara,2024-08-29 00:00:00,Yes,Incl
,Framework Convention on Global AI Challenges ,"Lee, S. U., Perera, H., Liu, Y., Xia, B., Lu, Q., & Zhu, L.",2024,https://www.cigionline.org/static/documents/AI-challenges.pdf,Bruce Tsai,2024-08-30 00:00:00,No,Excl - Not an organised framework
,Implementing the UK’s AI Regulatory Principles  ,"Department for Science, Innovation and Technology",2024,https://assets.publishing.service.gov.uk/media/65c0b6bd63a23d0013c821a0/implementing_the_uk_ai_regulatory_principles_guidance_for_regulators.pdf',Josh Philliban ,2024-08-19 00:00:00,No,Excl - Not an organised framework
,AI Safety Governance Framework,National Technical Committee 260 on Cybersecurity of SAC 2024.9,2024,https://www.tc260.org.cn/upload/2024-09-09/1725849192841090989.pdf,Peter Slattery ,2024-09-19 00:00:00,Yes,Incl
,Harm to Nonhuman Animals from AI: A Systematic Account and Framework ,"Coghlan, S., Parker, C. ",2023,https://link.springer.com/article/10.1007/s13347-023-00627-6,Zachary Brown ,2024-09-30 00:00:00,Yes,Incl
,,,,,,,,
,,,,,,,,
,📧 Email: pslat[at]mit.edu,,,,,,,
