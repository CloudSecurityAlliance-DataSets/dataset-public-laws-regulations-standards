|----------------|-------------------------------------------------|------------------------------------------------|------------------------------------------------|------------------------------------------------|
| Domain         | Category                                        | Control Name                                   | Control Requirements                           |                                                |
| ID             |                                                 |                                                |                                                |                                                |
| AI Governance, | AI Governance                                   | Gov 1.1                                        | Policies, Processes,                           | Establish an internal AI governance structure, |
| Risk, &        | Program                                         | & Procedures                                   | policies and mechanism to direct, monitor and  |                                                |
| Compliance     | Established                                     | control AI systems development and             |                                                |                                                |
|                | deployment.                                     |                                                |                                                |                                                |
| Gov 1.2        | AI Roles &                                      | Senior management assigns authority and        |                                                |                                                |
|                | Responsibilities                                | holds people accountable for adhering to an    |                                                |                                                |
|                | Structure                                       | organization's AI policies, processes and      |                                                |                                                |
|                | objectives.                                     |                                                |                                                |                                                |
| Gov 1.3        | AI Program                                      | Ongoing monitoring and periodic review of the  |                                                |                                                |
|                | Effectiveness and                               | risk management process and its outcomes are   |                                                |                                                |
|                | Risk Monitored                                  | planned including determining the frequency of |                                                |                                                |
|                | periodic review.                                |                                                |                                                |                                                |
| Gov 1.4        | AI Training                                     | The organization's personnel and partners      |                                                |                                                |
|                | Program                                         | receive AI risk management training to enable  |                                                |                                                |
|                | them to perform their duties and                |                                                |                                                |                                                |
|                | responsibilities consistent with related        |                                                |                                                |                                                |
|                | policies, procedures, and agreements.           |                                                |                                                |                                                |
| AI Risk        | Gov 2.1                                         | Risk Management                                | Risk management process and its outcomes       |                                                |
| Management     | Processes                                       | are established through transparent policies,  |                                                |                                                |
|                | procedures, and other controls based on         |                                                |                                                |                                                |
|                | organizational risk priorities.                 |                                                |                                                |                                                |
| Gov 2.2        | Risk Assessment                                 | Senior management identifies the AI system     |                                                |                                                |
|                | and Tolerances                                  | needs and uses the collected information to    |                                                |                                                |
|                | establish risk thresholds, provide resources to |                                                |                                                |                                                |
|                | ensure that staff are familiar with AI policies |                                                |                                                |                                                |
|                | and procedures.                                 |                                                |                                                |                                                |
| Gov 2.3        | Gen AI Program                                  | Mechanisms are in place to inventory AI        |                                                |                                                |
|                | Inventory                                       | systems and are resourced according to         |                                                |                                                |
|                | organizational risk priorities.                 |                                                |                                                |                                                |
| AI Regulatory  | Gov 3.1                                         | Ongoing                                        | Legal and regulatory requirements involving AI |                                                |
| Compliance     | Compliance &                                    | are understood, managed, and documented.       |                                                |                                                |
|                | Regulatory Watch                                |                                                |                                                |                                                |
| Gov 3.2        | Report Identified                               | Document and report incidents and related      |                                                |                                                |
|                | Incidents                                       | information on incident control actions with   |                                                |                                                |
|                | designated authorities.                         |                                                |                                                |                                                |
| Supply Chain   | Gov 4.1                                         | Supplier Risk                                  | AI risks and benefits from third-party         |                                                |
| Security       | Management                                      | resources are regularly monitored, and risk    |                                                |                                                |
|                | controls are applied and documented.            |                                                |                                                |                                                |

| Domain          | Category                                        | Control ID                                       | Control Name                                    | Control Requirements                         |
|-----------------|-------------------------------------------------|--------------------------------------------------|-------------------------------------------------|----------------------------------------------|
| AI App Controls | AI App Safety                                   | App 1.1                                          | Document AI                                     | Document and report AI systems capabilities, |
| & Management    | System                                          | limitations, acceptable and unacceptable         |                                                 |                                              |
|                 | Capabilities,                                   | usage. Include technical documentation and       |                                                 |                                              |
|                 | Limitations, and                                | instructions for usage of AI models, as          |                                                 |                                              |
|                 | Acceptable Usages                               | applicable.                                      |                                                 |                                              |
| App 1.2         | Document                                        | Document and report evaluations conducted        |                                                 |                                              |
|                 | Trustworthy AI                                  | for safety, security, bias, explainability of AI |                                                 |                                              |
|                 | Efforts                                         | applications                                     |                                                 |                                              |
| AI App          | App 2.1                                         | App Lifecycle                                    | Define and deploy secure development            |                                              |
| Lifecycle       | Completeness                                    | practices for generative AI applications,        |                                                 |                                              |
|                 | throughout the AI lifecycle, for cybersecurity, |                                                  |                                                 |                                              |
|                 | physical security, and insider threats.         |                                                  |                                                 |                                              |
| App 2.2         | App Code                                        | Mechanisms are established to enable AI          |                                                 |                                              |
|                 | Maintainability                                 | stakeholders to regularly incorporate            |                                                 |                                              |
|                 | adjudicated feedback from relevant AI actors    |                                                  |                                                 |                                              |
|                 | into AI Application design and implementation.  |                                                  |                                                 |                                              |
| AI App          | App 3.1                                         | AI App Posture                                   | Implement monitoring and logging                |                                              |
| Compliance      | Management &                                    | mechanisms to track AI application               |                                                 |                                              |
|                 | Compliance                                      | performance, usage, and compliance with          |                                                 |                                              |
|                 | relevant regulations and ethical guidelines.    |                                                  |                                                 |                                              |
| App 3.2         | Conduct                                         | Deploy testing measures, including testing,      |                                                 |                                              |
|                 | Trustworthy AI                                  | throughout the AI application life cycle.        |                                                 |                                              |
|                 | System Testing                                  |                                                  |                                                 |                                              |
| App Interaction | App 4.1                                         | Input                                            | Detect and block adversarial inputs or atypical |                                              |
| Safety &        | manipulation &                                  | queries to AI applications that deviate from     |                                                 |                                              |
| Security        | prompt injection                                | known benign behavior, exhibit behavior          |                                                 |                                              |
|                 | Protection                                      | patterns observed in previous attacks (e.g.      |                                                 |                                              |
|                 | similar to SQL Injection attacks in Web Apps,   |                                                  |                                                 |                                              |
|                 | prompt injection attacks can exploit AI app     |                                                  |                                                 |                                              |
|                 | capabilities)                                   |                                                  |                                                 |                                              |
| App 4.2         | Prevent inference                               | Regulate the amount and fidelity of potentially  |                                                 |                                              |
|                 | attacks / Minimize                              | sensitive information in, prompts and API        |                                                 |                                              |
|                 | Query Response                                  | queries to limit the amount of information an    |                                                 |                                              |
|                 | attacker can learn.                             |                                                  |                                                 |                                              |
| App 4.3         | Denial of gen AI                                | Detect and block adversarial inputs or atypical  |                                                 |                                              |
|                 | service Prevention                              | queries that deviate from known benign           |                                                 |                                              |
|                 | / Restrict                                      | behavior, exhibit behavior patterns observed in  |                                                 |                                              |
|                 | Excessive Queries                               | previous attacks.                                |                                                 |                                              |
| App 4.4         | Prevent Toxic                                   | Detect and block outputs with hateful, abusive,  |                                                 |                                              |
|                 | Results                                         | or toxic content; hallucinations; malicious      |                                                 |                                              |
|                 | outputs (i.e. generating harmful code);         |                                                  |                                                 |                                              |
|                 | sensitive model or data information leakage     |                                                  |                                                 |                                              |
| AI App          | App 5.1                                         | AI App Access                                    | Establish access controls AI applications       |                                              |
| Protection      | Controls                                        | through UI (including chat interface), and APIs  |                                                 |                                              |
|                 | which in turn leverage AI systems and data as   |                                                  |                                                 |                                              |
|                 | backend systems.                                |                                                  |                                                 |                                              |
| App 5.2         | Assess Security of                              | Identify security measures to protect against    |                                                 |                                              |
|                 | AI Application                                  | data breaches, and malicious attacks  (security  |                                                 |                                              |
|                 | & risk assessments, attack surface              |                                                  |                                                 |                                              |
|                 | assessments, threat assessments, etc.)          |                                                  |                                                 |                                              |

| Domain     | Category                                          | Control ID                                    | Control Name                               | Control Requirements                    |
|------------|---------------------------------------------------|-----------------------------------------------|--------------------------------------------|-----------------------------------------|
| AI Model   | AI Model                                          | Mod 1.1                                       | Document Model                             | Document and report model capabilities, |
| Controls & | Explainability                                    | Capabilities,                                 | limitations, acceptable and unacceptable   |                                         |
| Management | Limitations, and                                  | usage. Include technical documentation and    |                                            |                                         |
|            | Usages                                            | instructions for usage of AI models, as       |                                            |                                         |
|            | applicable.                                       |                                               |                                            |                                         |
| Mod 1.2    | Bias Detection and                                | Implement algorithms and tools designed to    |                                            |                                         |
|            | Evaluation                                        | detect and evaluate potential biases in the   |                                            |                                         |
|            | training data, algorithms, or outputs of the AI   |                                               |                                            |                                         |
|            | system.                                           |                                               |                                            |                                         |
|            | Diversity in                                      | Ensure that the training data used for the AI |                                            |                                         |
| Mod 1.3    | Training Data                                     | system is diverse, representative, and free   |                                            |                                         |
|            | from discriminatory patterns.                     |                                               |                                            |                                         |
| AI Model   | Mod 2.1                                           | Model Lifecycle                               | Define and deploy secure development       |                                         |
|            | practices for generative AI models, throughout    |                                               |                                            |                                         |
| Lifecycle  | Completeness                                      | the AI lifecycle, for cybersecurity, physical |                                            |                                         |
|            | security and insider threats.                     |                                               |                                            |                                         |
| Mod 2.2    | Model Lifecycle                                   | Document AI model details including model     |                                            |                                         |
|            | Documented                                        | type (e.g., convolutional neural network,     |                                            |                                         |
|            | reinforcement learning, decision tree, random     |                                               |                                            |                                         |
|            | forest, etc.) data features, training algorithms, |                                               |                                            |                                         |
|            | proposed uses, decision thresholds, training      |                                               |                                            |                                         |
|            | data, evaluation data, and ethical                |                                               |                                            |                                         |
|            | considerations.                                   |                                               |                                            |                                         |
| Mod 2.3    | Model Code                                        | Mechanisms are established to enable AI       |                                            |                                         |
|            | Maintainability                                   | actors to regularly incorporate adjudicated   |                                            |                                         |
|            | feedback from relevant sources into system        |                                               |                                            |                                         |
|            | design and implementation.                        |                                               |                                            |                                         |
| Mod 2.4    | Assess Model                                      | Identify security measures to protect against |                                            |                                         |
|            | Security                                          | unauthorized access, data breaches, and       |                                            |                                         |
|            | malicious attacks (security & risk assessments,   |                                               |                                            |                                         |
|            | attack surface assessments, threat                |                                               |                                            |                                         |
|            | assessments, etc.) to AI models.                  |                                               |                                            |                                         |
| AI Model   | Mod 3.1                                           | Model Drift                                   | Regularly monitor AI Model performance and |                                         |
| Compliance | Tracking                                          | trustworthiness to enhance ability to detect  |                                            |                                         |

| AI App Threat   | App 6.1                                      | AI App Security                                  | Deploy testing measures, including red   |
|-----------------|----------------------------------------------|--------------------------------------------------|------------------------------------------|
| Management &    | Testing                                      | teaming for adversarial testing, throughout the  |                                          |
| Resilience      | AI Application life cycle.                   |                                                  |                                          |
| App 6.2         | AI App                                       | Identify and mitigate vulnerabilities, incidents |                                          |
|                 | Vulnerability                                | and patterns of misuse, including third party    |                                          |
|                 | Mitigation                                   | vulnerabilities.                                 |                                          |
| App 6.3         | AI App Threat                                | Implement comprehensive monitoring and           |                                          |
|                 | Detection &                                  | logging mechanisms to track AI application       |                                          |
|                 | Response                                     | performance, usage, and compliance with          |                                          |
|                 | relevant regulations and ethical guidelines. |                                                  |                                          |
| App 6.4         | Establish Resilient                          | Design and implement AI applications and         |                                          |
|                 | Gen AI                                       | systems with robustness, ensuring they can       |                                          |
|                 | Applications &                               | withstand various types of failures, attacks,    |                                          |
|                 | Systems                                      | and unexpected inputs.                           |                                          |

|                    | and respond to drift.  Processes and            |                                                  |                                               |
|--------------------|-------------------------------------------------|--------------------------------------------------|-----------------------------------------------|
|                    | mechanisms for regular monitoring model         |                                                  |                                               |
|                    | functionality and behavior - as well as impacts |                                                  |                                               |
|                    | and alignment with the values and norms         |                                                  |                                               |
|                    | within the specific context of use.             |                                                  |                                               |
| Mod 3.2            | Model Posture                                   | Implement monitoring and logging                 |                                               |
| Management &       | mechanisms to track AI models' secure           |                                                  |                                               |
| Compliance         | configurations, performance, usage, and         |                                                  |                                               |
|                    | compliance with relevant regulations and        |                                                  |                                               |
|                    | ethical guidelines.                             |                                                  |                                               |
| Mod 3.3            | Model Monitoring                                | Regularly track the AI model(s) to ensure that   |                                               |
| and Tracking       | they do not lead to inaccurate / harmful        |                                                  |                                               |
|                    | results.                                        |                                                  |                                               |
| Prompt Safety      | Mod 4.1                                         | Input manipulation                               | Detect and block adversarial inputs, prompts, |
| & Security         | & prompt injection                              | or atypical queries that deviate from known      |                                               |
| Protection         | benign behavior, exhibit behavior patterns      |                                                  |                                               |
|                    | observed in previous attacks.                   |                                                  |                                               |
| Mod 4.2            | Prevent inference                               | Regulate the amount and fidelity of potentially  |                                               |
| attacks / Minimize | sensitive information in, prompts and API       |                                                  |                                               |
| Query Response     | queries to limit the amount of information an   |                                                  |                                               |
|                    | attacker can learn.                             |                                                  |                                               |
| Mod 4.3            | Prevent Toxic                                   | Prevent models from responding with hateful,     |                                               |
| Results            | abusive, or toxic content; hallucinations;      |                                                  |                                               |
|                    | malicious outputs (i.e. generating harmful      |                                                  |                                               |
|                    | code); sensitive model or data information      |                                                  |                                               |
|                    | leakage.                                        |                                                  |                                               |
| AI Model           | Mod 5.1                                         | Model Access                                     | Establish access controls around models that  |
| Access             | Controls                                        | are exposed for enterprise usage, including for  |                                               |
|                    | AI applications; secure internal model          |                                                  |                                               |
|                    | registries and limit internal access to         |                                                  |                                               |
|                    | production models. Such access controls         |                                                  |                                               |
|                    | should include contextual policies that factor  |                                                  |                                               |
|                    | in who, what, when, and from where.             |                                                  |                                               |
| AI System and      | Mod 6.1                                         | Model Security                                   | Deploy testing measures, including red        |
| Model Threat       | Testing                                         | teaming for adversarial testing, throughout the  |                                               |
| Detection          | AI lifecycle.                                   |                                                  |                                               |
| Mod 6.2            | Model                                           | Identify and mitigate vulnerabilities, incidents |                                               |
| Vulnerability      | and patterns of misuse, including third party   |                                                  |                                               |
| Mitigation         | vulnerabilities.                                |                                                  |                                               |
| Mod 6.3            | Establish Resilient                             | Design and implement AI models with              |                                               |
| AI Models          | robustness, ensuring they can withstand         |                                                  |                                               |
|                    | various types of failures, attacks, and         |                                                  |                                               |
|                    | unexpected inputs.                              |                                                  |                                               |

12

| Domain           | Category                                       | Control ID                                      | Control Name                                  | Control Requirements                     |
|------------------|------------------------------------------------|-------------------------------------------------|-----------------------------------------------|------------------------------------------|
| AI Data Controls | Data                                           | Dat 1.1                                         | Data Source                                   | Document assumptions made and techniques |
| & Management     | Classification                                 | Determination                                   | used in data selection, curation, preparation |                                          |
| and Lineage      | and analysis, including: identification of     |                                                 |                                               |                                          |
|                  | constructs and development of indices -        |                                                 |                                               |                                          |
|                  | especially those operationalizing concepts     |                                                 |                                               |                                          |
|                  | that are inherently unobservable (e.g.         |                                                 |                                               |                                          |
|                  | "hireability," "criminality." "lendability")   |                                                 |                                               |                                          |
| Dat 1.2          | Implement Data                                 | Implement robust data classification            |                                               |                                          |
|                  | Classification                                 | mechanisms to accurately categorize and         |                                               |                                          |
|                  | Schema                                         | label data according to its sensitivity,        |                                               |                                          |
|                  | ensuring appropriate handling and protection   |                                                 |                                               |                                          |
|                  | based on the classification.                   |                                                 |                                               |                                          |
| Dat 1.3          | Data Bias Mitigation                           | Map adherence to policies that address data     |                                               |                                          |
|                  | / Transparency                                 | and construct validity, fairness, bias, and     |                                               |                                          |
|                  | Enablement                                     | explainability for AI systems and verify        |                                               |                                          |
|                  | documentation, oversight, and processes.       |                                                 |                                               |                                          |
| Dat 1.4          | Data                                           | Enforce data transformation activities risk     |                                               |                                          |
|                  | mitigation identified in risk assessment.      |                                                 |                                               |                                          |
|                  | Transformation                                 |                                                 |                                               |                                          |
| Dat 1.5          | Data Labeling /                                | Develop and deploy mechanism to                 |                                               |                                          |
|                  | Attribution                                    | authenticate and label AI generated content     |                                               |                                          |
|                  | for users' awareness.                          |                                                 |                                               |                                          |
| Dat 1.6          | Data Usage                                     | Ensure legal right to leverage data for         |                                               |                                          |
|                  | Permission / Data                              | training, inference, and usage                  |                                               |                                          |
|                  | Owner Consent                                  |                                                 |                                               |                                          |
| Data Quality &   | Dat 2.1                                        | Sanitize Input Data                             | Implement safeguards for protecting input     |                                          |
| Integrity        | data to train AI systems, including protection |                                                 |                                               |                                          |
|                  | of personal data and intellectual property.    |                                                 |                                               |                                          |
| Dat 2.2          | Verify Data Integrity                          | Verify that all machine learning data artifacts |                                               |                                          |
|                  | and files have not been modified by            |                                                 |                                               |                                          |
|                  | unauthorized individuals.                      |                                                 |                                               |                                          |
| Data             | Dat 3.1                                        | Data residency and                              | Ensure enterprise requirements based on risk  |                                          |
| Compliance       | location                                       | and compliance around data residency and        |                                               |                                          |
|                  | location are met. Based on data residency      |                                                 |                                               |                                          |
|                  | and sovereignty requirements, there is         |                                                 |                                               |                                          |
|                  | increased need to restrict where data is       |                                                 |                                               |                                          |
|                  | stored.                                        |                                                 |                                               |                                          |
| Data Privacy &   | Dat 4.1                                        | Privacy Protections                             | Implement safeguards for protecting input     |                                          |
| Confidentiality  | data, including protection of personal data    |                                                 |                                               |                                          |
|                  | and intellectual property.                     |                                                 |                                               |                                          |
|                  | Sensitive Data                                 | Develop and implement data confidentiality      |                                               |                                          |
| Dat 4.2          | Security /Data                                 | mechanisms to ensure that data architecture     |                                               |                                          |
|                  | Confidentiality                                | has factored in security practices, so that AI  |                                               |                                          |
|                  | systems or data layers do not divulge          |                                                 |                                               |                                          |
|                  | sensitive or confidential information to       |                                                 |                                               |                                          |
|                  | unauthorized access. Also protect contextual   |                                                 |                                               |                                          |
|                  | data that is used with AI systems in           |                                                 |                                               |                                          |
|                  | inferencing and other use cases.               |                                                 |                                               |                                          |
| Data Access      | Dat 5.1                                        | Detect & respond to                             | Monitor data activity and access. Detect      |                                          |
| Controls         | unauthorized and                               | malicious and/or unauthorized access.           |                                               |                                          |
|                  | malicious access                               |                                                 |                                               |                                          |
